{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5odNmmqT_xaL"},"outputs":[],"source":["!git clone https://github.com/sithu31296/semantic-segmentation\n","%cd semantic-segmentation\n","%pip install -e ."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5vQ0kHSCTjj","executionInfo":{"status":"ok","timestamp":1683895991583,"user_tz":-120,"elapsed":20250,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"23efe3f6-6fdf-4f53-c603-055bad14ad5f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kytW-DGR_xaS","executionInfo":{"status":"ok","timestamp":1683897299395,"user_tz":-120,"elapsed":7077,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}}},"outputs":[],"source":["import torch\n","from torchvision import io\n","from torchvision import transforms as T\n","from PIL import Image\n","import pickle\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdqe-die_xaU"},"outputs":[],"source":["from semseg import show_models\n","\n","show_models()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRuUZ0H7_xaW"},"outputs":[],"source":["%pip install -U gdown"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"kpWQa9du_xaX","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1683896035735,"user_tz":-120,"elapsed":4467,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"c6d93c35-aafd-49ab-b6e2-31c69ebec571"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (uriginal): https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT\n","From (redirected): https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT&confirm=t&uuid=eb7062f4-72c6-44aa-bd0f-b7f389efa1b3\n","To: /content/semantic-segmentation/checkpoints/pretrained/segformer/segformer.b3.ade.pth\n","100%|██████████| 190M/190M [00:03<00:00, 57.2MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'./checkpoints/pretrained/segformer/segformer.b3.ade.pth'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["import gdown\n","from pathlib import Path\n","\n","ckpt = Path('./checkpoints/pretrained/segformer')\n","ckpt.mkdir(exist_ok=True, parents=True)\n","\n","url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n","output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n","\n","gdown.download(url, output, quiet=False)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"bglipAaW_xaY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683897355848,"user_tz":-120,"elapsed":1563,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"488da8f0-0807-41a1-bbaa-6faaf46e711d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Download a pretrained model's weights from the result table.\n","Loaded Model\n"]}],"source":["from semseg.models import *\n","\n","model = eval('SegFormer')(\n","    backbone='MiT-B3',\n","    num_classes=150\n",")\n","\n","try:\n","    model.load_state_dict(torch.load('checkpoints/pretrained/segformer/segformer.b3.ade.pth', map_location='cpu'))\n","except:\n","    print(\"Download a pretrained model's weights from the result table.\")\n","model.eval()\n","\n","print('Loaded Model')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"AujMSfML_xaa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683897360195,"user_tz":-120,"elapsed":271,"user":{"displayName":"Leonardo Colosi","userId":"10241973221821838785"}},"outputId":"e56883f9-c11d-4d2d-940b-597e93804a36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SegFormer(\n","  (backbone): MiT(\n","    (patch_embed1): PatchEmbed(\n","      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n","      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (patch_embed2): PatchEmbed(\n","      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (patch_embed3): PatchEmbed(\n","      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (patch_embed4): PatchEmbed(\n","      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (block1): ModuleList(\n","      (0): Block(\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (q): Linear(in_features=64, out_features=64, bias=True)\n","          (kv): Linear(in_features=64, out_features=128, bias=True)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (drop_path): Identity()\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (dwconv): DWConv(\n","            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","          )\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","        )\n","      )\n","      (1-2): 2 x Block(\n","        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (q): Linear(in_features=64, out_features=64, bias=True)\n","          (kv): Linear(in_features=64, out_features=128, bias=True)\n","          (proj): Linear(in_features=64, out_features=64, bias=True)\n","          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (fc1): Linear(in_features=64, out_features=256, bias=True)\n","          (dwconv): DWConv(\n","            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","          )\n","          (fc2): Linear(in_features=256, out_features=64, bias=True)\n","        )\n","      )\n","    )\n","    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (block2): ModuleList(\n","      (0-3): 4 x Block(\n","        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (q): Linear(in_features=128, out_features=128, bias=True)\n","          (kv): Linear(in_features=128, out_features=256, bias=True)\n","          (proj): Linear(in_features=128, out_features=128, bias=True)\n","          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (fc1): Linear(in_features=128, out_features=512, bias=True)\n","          (dwconv): DWConv(\n","            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","          )\n","          (fc2): Linear(in_features=512, out_features=128, bias=True)\n","        )\n","      )\n","    )\n","    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    (block3): ModuleList(\n","      (0-17): 18 x Block(\n","        (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (q): Linear(in_features=320, out_features=320, bias=True)\n","          (kv): Linear(in_features=320, out_features=640, bias=True)\n","          (proj): Linear(in_features=320, out_features=320, bias=True)\n","          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n","          (dwconv): DWConv(\n","            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","          )\n","          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n","        )\n","      )\n","    )\n","    (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n","    (block4): ModuleList(\n","      (0-2): 3 x Block(\n","        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (q): Linear(in_features=512, out_features=512, bias=True)\n","          (kv): Linear(in_features=512, out_features=1024, bias=True)\n","          (proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (drop_path): DropPath()\n","        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (dwconv): DWConv(\n","            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","          )\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","      )\n","    )\n","    (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (decode_head): SegFormerHead(\n","    (linear_c1): MLP(\n","      (proj): Linear(in_features=64, out_features=768, bias=True)\n","    )\n","    (linear_c2): MLP(\n","      (proj): Linear(in_features=128, out_features=768, bias=True)\n","    )\n","    (linear_c3): MLP(\n","      (proj): Linear(in_features=320, out_features=768, bias=True)\n","    )\n","    (linear_c4): MLP(\n","      (proj): Linear(in_features=512, out_features=768, bias=True)\n","    )\n","    (linear_fuse): ConvModule(\n","      (conv): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","    (linear_pred): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","  )\n",")"]},"metadata":{},"execution_count":4}],"source":["model.eval()"]},{"cell_type":"code","source":["# Load the data loader from the pickle file\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","with open('/content/drive/MyDrive/Dataset/data_loader.pkl', 'rb') as f:\n","    data_loader = pickle.load(f)\n","\n","\n","items = data_loader.dataset.__getitem__(1)\n","\n","\n","plt.imshow(items[0])\n","plt.show()"],"metadata":{"id":"OyfFqmJaFc2p"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airoprojects/visiope/blob/main/dataloader/load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "C_I9uEV0uwCV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pickle #used to save dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsEy-Hdr-2o4",
        "outputId": "20ea6979-ec08-4e20-889c-3dc2898d4f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# set up dataset directory path\n",
        "ckpt = Path('/content/drive/MyDrive/Dataset/')\n",
        "ckpt.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk1x19hGj87p"
      },
      "outputs": [],
      "source": [
        "\"\"\" if you already have the daset in your local drive, \n",
        "place it in a Dataset directory and unzip it from there \"\"\"\n",
        "\n",
        "# unzip dataset\n",
        "!unzip \"/content/drive/MyDrive/Dataset/ai4mars-dataset-merged-0.1.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE1VfEkQkAmg"
      },
      "outputs": [],
      "source": [
        "\"\"\" else download und unzip the dataset from here \"\"\"\n",
        "\n",
        "import gdown\n",
        "\n",
        "# get url of zipped dataset\n",
        "url = 'https://drive.google.com/uc?id=1eW9Ah9DDEY02CTHCrRYLGPmiGZvCTKK4'\n",
        "\n",
        "# set up zip download location and start download\n",
        "output = '/content/ai4mars-dataset-merged-0.1.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "# unzip dataset\n",
        "!unzip \"/content/ai4mars-dataset-merged-0.1.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HjFSoKGUmVf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "aX9Zlp8HM9wH",
        "outputId": "32087118-aab6-4881-e0be-e4ac51191702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 1024, 1024, 3) (200, 1, 1024, 1024)\n",
            "[[[4 4 4 ... 4 4 4]\n",
            "  [4 4 4 ... 4 4 4]\n",
            "  [4 4 4 ... 4 4 4]\n",
            "  ...\n",
            "  [4 4 4 ... 4 4 4]\n",
            "  [4 4 4 ... 4 4 4]\n",
            "  [4 4 4 ... 4 4 4]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nvalidation set parametrized to decide if you want only 1, 2, oe togheter\\nparametrized \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#Path\n",
        "images = \"ai4mars-dataset-merged-0.1/msl/images\"\n",
        "label_train = \"ai4mars-dataset-merged-0.1/msl/labels/train\"\n",
        "label_test_1ag = \"ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min1-100agree\"\n",
        "label_test_2ag = \"ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min2-100agree\"\n",
        "label_test_3ag = \"ai4mars-dataset-merged-0.1/msl/labels/test/masked-gold-min3-100agree\"\n",
        "edr = images + \"/edr\"\n",
        "mxy = images + \"/mxy\" \n",
        "rng = images + \"/rng-30m\"\n",
        "\n",
        "\n",
        "edr_files = os.listdir(edr)\n",
        "label_train_files = os.listdir(label_train)\n",
        "label_test_files_1 = os.listdir(label_test_1ag)\n",
        "label_test_files_2 = os.listdir(label_test_2ag)\n",
        "label_test_files_3 = os.listdir(label_test_3ag)\n",
        "\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "y1 = []\n",
        "y2 = []\n",
        "y3 = []\n",
        "\n",
        "c = 0\n",
        "size = 224\n",
        "\n",
        "\n",
        "\n",
        "for label in label_test_files_1:\n",
        "    path_label = os.path.join(label_test_1ag, label)\n",
        "\n",
        "    img_arr = cv2.imread(path_label,0) #read image\n",
        "    #img_arr = cv2.resize(img_arr, dsize=(size, size),interpolation=cv2.INTER_NEAREST) #resize\n",
        "    y1.append(img_arr)\n",
        "\n",
        "for label in label_test_files_2:\n",
        "    path_label = os.path.join(label_test_1ag, label)\n",
        "\n",
        "    img_arr = cv2.imread(path_label,0) #read image\n",
        "    #img_arr = cv2.resize(img_arr, dsize=(size, size),interpolation=cv2.INTER_NEAREST) #resize\n",
        "    y2.append(img_arr)\n",
        "\n",
        "for label in label_test_files_3:\n",
        "    path_label = os.path.join(label_test_1ag, label)\n",
        "\n",
        "    img_arr = cv2.imread(path_label,0) #read image\n",
        "    #img_arr = cv2.resize(img_arr, dsize=(size, size),interpolation=cv2.INTER_NEAREST) #resize\n",
        "    y3.append(img_arr)\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "for label in label_train_files:\n",
        "\n",
        "\n",
        " \n",
        "    img_name = label[:-4] + \".JPG\" #Names of images match names of labels, except for the extension (JPG, png)\n",
        "\n",
        "    if img_name in edr_files:\n",
        "\n",
        "        img_path = os.path.join(edr, img_name) #get the full path\n",
        "        \n",
        "        # this is ugly, to change!\n",
        "        img_arr = cv2.imread(img_path) #read image\n",
        "        #img_arr = cv2.resize(img_arr, dsize=(size, size)) #resize\n",
        "\n",
        "\n",
        "        label_path = os.path.join(label_train, label)\n",
        "        lab_arr = cv2.imread(label_path,0) #0 mean read as greyscale image\n",
        "        #lab_arr = cv2.resize(lab_arr, (size,size), interpolation = cv2.INTER_NEAREST)\n",
        "\n",
        "        X.append(img_arr)\n",
        "        print(label_path)\n",
        "        y.append(lab_arr[np.newaxis, :, :])\n",
        "\n",
        "        #this control how much images you want\n",
        "        c+=1\n",
        "        if c==200: break\n",
        "\n",
        "\n",
        "X = np.asanyarray(X, dtype= np.float32) / 255\n",
        "y = np.array(y, dtype= np.int64)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 0 - soil --> 0 \n",
        "# 1 - bedrock --> 1\n",
        "# 2 - sand --> 2\n",
        "# 3 - big rock --> 3\n",
        "# 255 -> 4 - NULL (no label)\n",
        "\n",
        "\n",
        "y[y==255] = 4\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(y[1])\n",
        "\n",
        "\n",
        "#from numpy array to torch\n",
        "\n",
        "Xt = torch.from_numpy(X)\n",
        "yt = torch.from_numpy(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "plt.imshow(X[0])\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "validation set parametrized to decide if you want only 1, 2, oe togheter\n",
        "parametrized \n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBd6yHWuUSnP",
        "outputId": "fc6ba42b-34d1-44eb-f7d9-aede4bdd796d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([200, 1024, 1024, 3])\n",
            "torch.Size([200, 1, 1024, 1024])\n"
          ]
        }
      ],
      "source": [
        "print(Xt.shape)\n",
        "print(yt.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "696Zf_e7TgT5",
        "outputId": "d1788c11-599e-4a73-dd02-cd04fa3940e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([200, 224, 672, 3])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X_rgb = torch.cat((Xt,Xt,Xt), dim=2)\n",
        "X_rgb.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otUTgv6v8Is7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#This class rappresents the dataset \n",
        "class Ai4MarsData(Dataset):\n",
        "    #X tensor (torch) -> images\n",
        "    #y tensor (torch) -> labels\n",
        "\n",
        "    def __init__(self, X, y,transform=None):\n",
        "        self.X = X.permute(0,3,1,2)\n",
        "        self.y = y\n",
        "\n",
        "        self.transform = transform\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.y[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "    \n",
        "\n",
        "    '''\n",
        "    TO DO\n",
        "  \n",
        "    def resize(self,resize,interp=None):\n",
        "        if interp:\n",
        "            k = interp\n",
        "        else:\n",
        "            k = cv2.INTER_NEAREST\n",
        "        for image in self.X:\n",
        "            image = \n",
        "        self.X = cv2.resize(img_arr, dsize=(size, size),interpolation=k)\n",
        "        self.y = cv2.resize(img_arr, dsize=(size, size),interpolation=k)\n",
        "\n",
        "    '''\n",
        "    \n",
        "    def setPermuteX(self,perm):   \n",
        "        print(type(self.X)) \n",
        "        self.X = self.X.permute(perm[0],perm[1],perm[2],perm[3])\n",
        "    \n",
        "    def setPermuteY(self,perm):    \n",
        "        self.y = self.y.permute(perm[0],perm[1],perm[2],perm[3])\n",
        "\n",
        "    \n",
        "    def setDevice(self,device,which):\n",
        "        if which==0:\n",
        "            self.X = X.to(device)\n",
        "        else:\n",
        "            self.y = y.to(device)\n",
        "\n",
        "    def convertion(self,what):\n",
        "        if(what==0):\n",
        "            self.y = self.y.type(torch.DoubleTensor)\n",
        "        else:\n",
        "            self.X = self.X.type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "    def resize(self,resize,interp=None):\n",
        "        '''\n",
        "        if interp:\n",
        "            k = interp\n",
        "        else:\n",
        "            k = torchvision.transforms.InterpolationMode\n",
        "        '''\n",
        "        transform = transforms.Resize(resize,antialias=True)\n",
        "        self.X = transform(self.X)\n",
        "        self.y = transform(self.y)\n",
        "        \n",
        "    \n",
        "    #this function return 3 dataloader (train,test,validation) splitted from self \n",
        "    #percentage -> give percentage of train size, the rest of percentage is given divided the residual part\n",
        "    #sizeBatch -> determine the size of batch\n",
        "    def splitLoader(self,percentage,sizeBatch):\n",
        "        dataset = self\n",
        "        ratio = percentage/100\n",
        "\n",
        "        #setup variables\n",
        "        d_size = len(self)\n",
        "        train_size = int(ratio*d_size)\n",
        "        test_size = int((d_size - train_size)/2)\n",
        "        validation_size = test_size\n",
        "\n",
        "        #split\n",
        "        train_dataset, test_dataset, validation_dataset = random_split(dataset,[train_size,test_size,validation_size])\n",
        "\n",
        "\n",
        "\n",
        "       \n",
        "        \n",
        "\n",
        "        print(type(train_dataset))\n",
        "\n",
        "        #create other loaders\n",
        "        train_loader = DataLoader(train_dataset,batch_size=sizeBatch)\n",
        "        test_loader = DataLoader(test_dataset,batch_size=sizeBatch)\n",
        "        validation_loader = DataLoader(validation_dataset,batch_size=sizeBatch)\n",
        "\n",
        "\n",
        "\n",
        "        return train_loader,test_loader,validation_loader\n",
        "    \n",
        "\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "\n",
        "##TEST -> TO DELETE\n",
        "#create a dataset\n",
        "\n",
        "\n",
        "dataset = Ai4MarsData(Xt,yt)\n",
        "print(dataset.__getitem__(0)[0].size())\n",
        "dataset2 = Ai4MarsData(Xt,yt)\n",
        "\n",
        "dataset.resize((64,64))\n",
        "print(dataset.__getitem__(0)[0].size())\n",
        "print(dataset.__getitem__(0)[1].size())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4APcisefdAi"
      },
      "outputs": [],
      "source": [
        "# Save the data loader as a pickle file\n",
        "with open('/content/drive/MyDrive/Dataset/data_loader.pkl', 'wb') as f:\n",
        "    pickle.dump(data_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVu4dFD8fdAj"
      },
      "outputs": [],
      "source": [
        "# Save the data loader as a pickle file local\n",
        "with open('data_loader.pkl', 'wb') as f:\n",
        "    pickle.dump(data_dict, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
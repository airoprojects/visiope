{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airoprojects/visiope/blob/main/experiments/test_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ai4MarsExperiments"
      ],
      "metadata": {
        "id": "e67Qc0pXfZGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Packages not included in colab"
      ],
      "metadata": {
        "id": "4MnHYhk_ff0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchmetrics\n",
        "%pip install ipywidgets\n",
        "%pip install -e .\n",
        "%pip install -U gdown"
      ],
      "metadata": {
        "id": "lRsCKyRLfHuD",
        "outputId": "91e4dfa1-33c1-49cd-9728-93e56c0d3b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.7.0->torchmetrics) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.8)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.8)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.6)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA344_H5pmEP"
      },
      "source": [
        "## General imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iiTAPAa9elhO"
      },
      "outputs": [],
      "source": [
        "# General imports\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics as metrics\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lygw33bMprOM"
      },
      "source": [
        "## Custom Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9ywxl7By7Pv3",
        "outputId": "d706a450-6d62-4e61-8b4d-3eba450496a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/visiope'...\n",
            "remote: Enumerating objects: 1440, done.\u001b[K\n",
            "remote: Counting objects: 100% (449/449), done.\u001b[K\n",
            "remote: Compressing objects: 100% (249/249), done.\u001b[K\n",
            "remote: Total 1440 (delta 217), reused 356 (delta 174), pack-reused 991\u001b[K\n",
            "Receiving objects: 100% (1440/1440), 223.66 MiB | 14.28 MiB/s, done.\n",
            "Resolving deltas: 100% (752/752), done.\n",
            "/content/visiope\n",
            "Branch 'tests' set up to track remote branch 'tests' from 'origin'.\n",
            "Switched to a new branch 'tests'\n",
            "  main\u001b[m\n",
            "* \u001b[32mtests\u001b[m\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Custom Imports\n",
        "import sys\n",
        "\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "LOCAL = not COLAB\n",
        "\n",
        "if COLAB:\n",
        "\n",
        "    # Clone visiope repo on runtime env\n",
        "    !git clone https://github.com/airoprojects/visiope.git /content/visiope/\n",
        "    %cd ./visiope/\n",
        "    !git checkout main\n",
        "    !git branch\n",
        "    %cd ../\n",
        "\n",
        "    # Get the root directory of the Git project\n",
        "    root_dir = '/content/visiope'\n",
        "\n",
        "    # Add custom modules to path\n",
        "    custom_modules_path = root_dir + '/tools/'\n",
        "    sys.path.insert(0, custom_modules_path)\n",
        "\n",
        "elif LOCAL:\n",
        "\n",
        "    from git import Repo\n",
        "\n",
        "    # Initialize the Git repository object\n",
        "    repo = Repo(\".\", search_parent_directories=True)\n",
        "\n",
        "    # Get the root directory of the Git project\n",
        "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
        "\n",
        "    # Add custom modules to path\n",
        "    custom_modules_path = root_dir  + '/tools/'\n",
        "    sys.path.insert(0, custom_modules_path)\n",
        "\n",
        "\n",
        "# Import Loader\n",
        "from data.utils import Ai4MarsDownload, Ai4MarsImporter, Ai4MarsSplitter, Ai4MarsDataLoader\n",
        "\n",
        "# Import Loss\n",
        "from loss.loss import Ai4MarsCrossEntropy, Ai4MarsDiceLoss\n",
        "\n",
        "# Import Trainer\n",
        "from trainer.trainer import Ai4MarsTrainer\n",
        "\n",
        "# Import Tester\n",
        "from tester.tester import Ai4MarsTester\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRMqpowGpvoQ"
      },
      "source": [
        "## Obtain dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qe47EV7tZ_R"
      },
      "source": [
        "#### Selecter functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fTO2wZubthnU"
      },
      "outputs": [],
      "source": [
        "# get the whole dataset\n",
        "def get_d(b):\n",
        "\n",
        "    global num_images\n",
        "    global data_path\n",
        "    global selector\n",
        "    global X\n",
        "    global y\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not selector:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "    selector = False\n",
        "\n",
        "    # Insert here your local path to the dataset (temporary)\n",
        "    data_path = input(\"Path to Dataset: \")\n",
        "\n",
        "    # Insert here the number of images you want to download\n",
        "    num_images = int(input(\"Number of images (max 1000): \"))\n",
        "\n",
        "    # Import data as Ai4MarsDataset\n",
        "    Ai4MarsDownload()(PATH=data_path)\n",
        "    importer = Ai4MarsImporter()\n",
        "    X, y, _ = importer(PATH=data_path, NUM_IMAGES=num_images, SIZE=128)\n",
        "\n",
        "    pass\n",
        "\n",
        "# Enable loading chunk of data\n",
        "def enable_chunk(b):\n",
        "\n",
        "    global selector\n",
        "    global CHUNK\n",
        "    global current_chunk\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not selector:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "    selector = False\n",
        "\n",
        "    CHUNK = True\n",
        "    current_chunk = 0\n",
        "\n",
        "    # Download options\n",
        "    d300 = widgets.Button(description=\"Dataset 300\")\n",
        "    d500 = widgets.Button(description=\"Dataset 500\")\n",
        "    d1k = widgets.Button(description=\"Dataset 1000\")\n",
        "\n",
        "    # Actions\n",
        "    display(d300, d500, d1k)\n",
        "    d300.on_click(get_d300)\n",
        "    d500.on_click(get_d500)\n",
        "    d1k.on_click(get_d1k)\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cmnA4w0Gv-m"
      },
      "source": [
        "#### Data download funtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lp_QfZkaG1XJ"
      },
      "outputs": [],
      "source": [
        "# ge the dataset in chncks of size 300\n",
        "def get_d300(b):\n",
        "\n",
        "    global COLAB\n",
        "    global CHUNK\n",
        "    global current_chunk\n",
        "    global chunk_size\n",
        "    global total_size\n",
        "    global X\n",
        "    global y\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not CHUNK:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "\n",
        "    chunk_size = 300\n",
        "    total_size = 3000\n",
        "\n",
        "    # update current chunk\n",
        "    current_chunk += chunk_size\n",
        "\n",
        "    print(f\"Loading cunck {current_chunk // chunk_size}\")\n",
        "\n",
        "    if COLAB:\n",
        "\n",
        "        if not(os.path.exists('/content/dataset/')):\n",
        "\n",
        "            import gdown\n",
        "\n",
        "            # get url of torch dataset (temporarerly my drive)\n",
        "            drive = 'https://drive.google.com/uc?id='\n",
        "            url = 'https://drive.google.com/drive/folders/1WaQKmnty99798t6b-GMh15GVy9ZxCkGP?usp=drive_link'\n",
        "\n",
        "            !gdown --folder {url} -O /content/\n",
        "\n",
        "            load_data = '/content/small-chunk-dataset/'\n",
        "\n",
        "    elif LOCAL:\n",
        "        load_data = root_dir + '/datasetup/small-chunk-dataset/'\n",
        "\n",
        "    X, y = torch.load(load_data + str(current_chunk // chunk_size) + 'dataset.pt')\n",
        "\n",
        "    print(\"Done\")\n",
        "\n",
        "    pass\n",
        "\n",
        "# ge the dataset in chncks of size 500\n",
        "def get_d500(b):\n",
        "\n",
        "    global COLAB\n",
        "    global CHUNK\n",
        "    global current_chunk\n",
        "    global chunk_size\n",
        "    global total_size\n",
        "    global X\n",
        "    global y\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not CHUNK:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "\n",
        "    chunk_size = 500\n",
        "    total_size = 5000\n",
        "\n",
        "    # update current chunk\n",
        "    current_chunk += chunk_size\n",
        "\n",
        "    print(f\"Loading cunck {current_chunk // chunk_size}\")\n",
        "\n",
        "    if COLAB:\n",
        "\n",
        "        if not(os.path.exists('/content/dataset/')):\n",
        "\n",
        "            import gdown\n",
        "\n",
        "            # get url of torch dataset (temporarerly my drive)\n",
        "            drive = 'https://drive.google.com/uc?id='\n",
        "            url = 'https://drive.google.com/drive/folders/1u4imSO8MerdZEW0V1lkEb6PWQmZgT5Ft?usp=sharing'\n",
        "\n",
        "            !gdown --folder {url} -O /content/\n",
        "\n",
        "            load_data = '/content/medium-chunk-dataset/'\n",
        "\n",
        "    elif LOCAL:\n",
        "        load_data = root_dir + '/datasetup/medium-chunk-dataset/'\n",
        "\n",
        "    X, y = torch.load(load_data + str(current_chunk // chunk_size) + 'dataset.pt')\n",
        "\n",
        "    print(\"Done\")\n",
        "    pass\n",
        "\n",
        "# ge the dataset in chncks of size 1k\n",
        "def get_d1k(b):\n",
        "\n",
        "    global COLAB\n",
        "    global CHUNK\n",
        "    global current_chunk\n",
        "    global chunk_size\n",
        "    global total_size\n",
        "    global X\n",
        "    global y\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not CHUNK:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "\n",
        "    chunk_size = 1000\n",
        "    total_size = 10000\n",
        "\n",
        "    print(f\"Loading cunck {current_chunk // chunk_size}\")\n",
        "\n",
        "    # update current chunk\n",
        "    current_chunk += chunk_size\n",
        "\n",
        "    if COLAB:\n",
        "\n",
        "        if not(os.path.exists('/content/dataset/')):\n",
        "\n",
        "            import gdown\n",
        "\n",
        "            # get url of torch dataset (temporarerly my drive)\n",
        "            drive = 'https://drive.google.com/uc?id='\n",
        "            url = 'https://drive.google.com/drive/folders/1BhL0nLbQt930l_ISDgUS8ZJRWGjH4eUU?usp=sharing'\n",
        "\n",
        "            !gdown --folder {url} -O /content/\n",
        "\n",
        "            load_data = '/content/chunk-dataset/'\n",
        "\n",
        "    elif LOCAL:\n",
        "        load_data = root_dir + '/datasetup/chunk-dataset/'\n",
        "\n",
        "    X, y = torch.load(load_data + 'dataset_' + str(current_chunk) + '.pt')\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR-6RoS3t1IX"
      },
      "source": [
        "#### Selector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6wXNW5yp4Zh"
      },
      "outputs": [],
      "source": [
        "# Select import mode\n",
        "\n",
        "# ENV VARIABLE INITIALIZATION DO NOT CHANGE\n",
        "CHUNK = False\n",
        "current_chunk = 0\n",
        "chunk_size = 0\n",
        "total_size = 0\n",
        "X = 0\n",
        "y = 0\n",
        "\n",
        "# Allow to select only one option\n",
        "if 'selector' not in globals():\n",
        "    selector  = True\n",
        "\n",
        "# Selection buttons\n",
        "d = widgets.Button(description=\"Load whole Dataset\")\n",
        "chunk = widgets.Button(description=\"Load chunk of data\")\n",
        "\n",
        "\n",
        "# actions\n",
        "display(d, chunk)\n",
        "d.on_click(get_d)\n",
        "chunk.on_click(enable_chunk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ_P7ml_fEZk"
      },
      "outputs": [],
      "source": [
        "# HARD RESET\n",
        "# selector = True\n",
        "# CHUNK = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0827HU01q6nH"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca-BSlVTq_Ew"
      },
      "outputs": [],
      "source": [
        "transform = None\n",
        "# Uncomment the following lines to apply transformations to the dataset\n",
        "'''\n",
        "transform = transforms.RandomChoice([\n",
        "    transforms.RandomRotation(90)])\n",
        "'''\n",
        "\n",
        "# Split the dataset\n",
        "splitter = Ai4MarsSplitter()\n",
        "percentages = [0.7, 0.2, 0.1]\n",
        "train_set, test_set, val_set = splitter(X, y, percentages, transform=transform)\n",
        "\n",
        "# Load info\n",
        "load_info = './.info.pt'\n",
        "info = torch.load(load_info)\n",
        "\n",
        "# Build Ai4MarsDataloader\n",
        "loader = Ai4MarsDataLoader()\n",
        "batch_sizes = [32, 16, 16]\n",
        "datasets = [train_set, test_set, val_set]\n",
        "train_loader, test_loader, val_loader = loader(datasets, batch_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpXj7Ow-wrL5"
      },
      "outputs": [],
      "source": [
        "# Just to check that different chunks contains different images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f'Len of train set: {len(train_set)}')\n",
        "print(f'Len of test set: {len(test_set)}')\n",
        "print(f'Len of validation set: {len(val_set)}')\n",
        "\n",
        "image, label = X[0], y[0]\n",
        "\n",
        "print(f'image shape: {image.permute(1,0,2).permute(0,2,1).shape}')\n",
        "plt.imshow(image.permute(1,0,2).permute(0,2,1).detach().numpy(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f'image shape: {label.permute(1,0,2).permute(0,2,1).shape}')\n",
        "plt.imshow(label.permute(1,0,2).permute(0,2,1).detach().numpy(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Free up mem\n",
        "del X\n",
        "del y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYPFyV05rDWE"
      },
      "source": [
        "## Model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FCQvjMbelhL"
      },
      "outputs": [],
      "source": [
        "# Clone remote repo with existing models\n",
        "\n",
        "if COLAB:\n",
        "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
        "    %cd semantic-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf3AWmRO_2CJ"
      },
      "outputs": [],
      "source": [
        "from semseg import show_models\n",
        "\n",
        "show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCa6tmRlelhW"
      },
      "outputs": [],
      "source": [
        "#  Import segformer\n",
        "\n",
        "from semseg.models import *\n",
        "\n",
        "model = eval('SegFormer')(\n",
        "    backbone='MiT-B1',\n",
        "    num_classes=5\n",
        ")\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load('checkpoints/pretrained/segformer/segformer.b3.ade.pth',\n",
        "                                     map_location=device))\n",
        "    print(\"Pretrained model's weights downloaded\")\n",
        "except:\n",
        "    print(\"Download a pretrained model's weights from the result table.\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print('Loaded Model')\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTK2tqpgrILQ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi6ZGOtk3EXa"
      },
      "source": [
        "#### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSxW3mFNelhl"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "\n",
        "loss_fn = Ai4MarsDiceLoss().to(device)\n",
        "#loss_fn = Ai4MarsCrossEntropy().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "transform = None\n",
        "# transform = transforms.RandomChoice([\n",
        "#      transforms.RandomRotation(90)])\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "trainer = Ai4MarsTrainer(loss_fn, optimizer, train_loader, val_loader,\n",
        "                         transform=transform, device=device, info=info, model_name='MiT-B1', dump=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6p6LYs2R0fF"
      },
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "# Check if the variable has been defined\n",
        "if 'run_once' not in globals():\n",
        "    run_once = True\n",
        "    trainer.param_hist(model, label='before')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBpzmtnRfEZn"
      },
      "source": [
        "#### Regular training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSkhk_Rl2gX0"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "trainer.train_multiple_epoch(model, EPOCHS=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U92PUhBW2-lv"
      },
      "source": [
        "#### Chunk training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6LW1nfz3MpV"
      },
      "outputs": [],
      "source": [
        "if not CHUNK:\n",
        "    print(\"You are not allowd to perform chunk training proceede with regular traiing\")\n",
        "\n",
        "else:\n",
        "\n",
        "    print(\"You are allowd to perform chunk training proceede with regular traiing\")\n",
        "    print(\"Please pay attention that you are using the same splitting parameters\")\n",
        "    CHUNK = False\n",
        "\n",
        "    for i in range(0, total_size, chunk_size):\n",
        "\n",
        "        if i == 0 :\n",
        "            trainer.train_multiple_epoch(model, EPOCHS=epochs)\n",
        "\n",
        "        else:\n",
        "\n",
        "            # update current chunk\n",
        "            current_chunk += chunk_size\n",
        "\n",
        "            print(f\"Loading cunck {current_chunk // chunk_size}\")\n",
        "\n",
        "            if COLAB: load_data = '/content/chunk-dataset/'\n",
        "            elif LOCAL: load_data = root_dir + '/datasetup/dataset/'\n",
        "\n",
        "            X, y = torch.load(load_data + 'dataset_' + str(current_chunk) + '.pt')\n",
        "\n",
        "            # Build dataset\n",
        "            splitter = Ai4MarsSplitter()\n",
        "            train_set, test_set, val_set = splitter(X, y, percentages)\n",
        "\n",
        "            # Build Ai4MarsDataloader\n",
        "            loader = Ai4MarsDataLoader()\n",
        "            train_loader, test_loader, val_loader = loader(\n",
        "                [train_set, test_set, val_set], batch_sizes)\n",
        "\n",
        "            print(info)\n",
        "            trainer.train_multiple_epoch(model, EPOCHS=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRpG5qJqfEZo"
      },
      "source": [
        "#### Plot loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6HCej-k7w6R"
      },
      "outputs": [],
      "source": [
        "# Plot loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainer.plot_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vQYontwr3W8"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydweI29r18jr"
      },
      "outputs": [],
      "source": [
        "# Testing and evaluation Metrics\n",
        "\n",
        "metric = metrics.JaccardIndex(task=\"multiclass\", num_classes=5).to(device)\n",
        "tester = Ai4MarsTester(loss_fn, metric, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ZyzuJW61Rs"
      },
      "outputs": [],
      "source": [
        "# Start testing\n",
        "\n",
        "tester.test_one_epoch(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_v2Q1AV73W"
      },
      "outputs": [],
      "source": [
        "# Module Parameters\n",
        "trainer.param_hist(model, label='after')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewE16aoK_2CX"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "for i, batch in enumerate(test_loader):\n",
        "  image, label = batch\n",
        "  print(image.shape)\n",
        "  pred = model(image.to(device))\n",
        "  tester.show_images(image, trainer.results_path, index=i)\n",
        "  tester.show_seg(label, trainer.results_path, index=i)\n",
        "  tester.show_seg(pred.cpu(), trainer.results_path, index=i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airoprojects/visiope/blob/main/experiments/test_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiTAPAa9elhO"
      },
      "outputs": [],
      "source": [
        "# General imports\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics as metrics\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ywxl7By7Pv3"
      },
      "outputs": [],
      "source": [
        "# Custom Imports\n",
        "\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "LOCAL = not COLAB\n",
        "\n",
        "if COLAB:\n",
        "\n",
        "    # Clone visiope repo on runtime env\n",
        "    !git clone https://github.com/airoprojects/visiope.git /content/visiope/\n",
        "    %cd ./visiope/\n",
        "    !git checkout tests\n",
        "    !git branch\n",
        "    %cd ../\n",
        "\n",
        "    # Get the root directory of the Git project\n",
        "    root_dir = '/content/visiope'\n",
        "\n",
        "    # Add custom modules to path\n",
        "    custom_modules_path = root_dir + '/tools/'\n",
        "    sys.path.insert(0, custom_modules_path)\n",
        "\n",
        "elif LOCAL:\n",
        "\n",
        "    from git import Repo\n",
        "\n",
        "    # Initialize the Git repository object\n",
        "    repo = Repo(\".\", search_parent_directories=True)\n",
        "\n",
        "    # Get the root directory of the Git project\n",
        "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
        "\n",
        "    # Add custom modules to path\n",
        "    custom_modules_path = root_dir  + '/tools/'\n",
        "    sys.path.insert(0, custom_modules_path)\n",
        "\n",
        "\n",
        "# Import Loader\n",
        "from data.utils import Ai4MarsDownload, Ai4MarsImporter, Ai4MarsSplitter, Ai4MarsDataLoader\n",
        "\n",
        "# Import Loss\n",
        "from loss.loss import Ai4MarsCrossEntropy, Ai4MarsDiceLoss\n",
        "\n",
        "# Import Trainer\n",
        "from trainer.trainer import Ai4MarsTrainer\n",
        "\n",
        "# Import Tester\n",
        "from tester.tester import Ai4MarsTester\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set LOAD_CUNK to True and run this cell multiple times to load different chunk of the dataset\n",
        "# Attention: you have to rerun this chell to load new data\n",
        "LOAD_CHUNK = False\n",
        "\n",
        "if LOAD_CHUNK:\n",
        "\n",
        "    # Check if the variable has been defined\n",
        "    if 'current_chunk' not in globals():\n",
        "        current_chunk  = 0\n",
        "\n",
        "    if COLAB:\n",
        "\n",
        "        if not(os.path.exists('/content/dataset/')):\n",
        "\n",
        "            import gdown\n",
        "\n",
        "            # get url of torch dataset (temporarerly my drive)\n",
        "            drive = 'https://drive.google.com/uc?id='\n",
        "            url = 'https://drive.google.com/drive/folders/104YvO3LcU76euuVe-_62eS_Rld-tOZeh?usp=drive_link'\n",
        "\n",
        "            !gdown --folder {url} -O /content/\n",
        "\n",
        "            load_data = '/content/chunk-dataset/'\n",
        "\n",
        "    elif LOCAL: \n",
        "        load_data = root_dir + '/datasetup/chunk-dataset/'\n",
        "\n",
        "\n",
        "    # update current chunk    \n",
        "    current_chunk += 1000\n",
        "    \n",
        "    if current_chunk > 10000: raise Exception('Chunk out of range')\n",
        "\n",
        "    print(f\"Loading cunck {current_chunk//1000}\")\n",
        "\n",
        "    X, y = torch.load(load_data + 'dataset_' + str(current_chunk) + '.pt')\n",
        "\n",
        "    # Build dataset\n",
        "    splitter = Ai4MarsSplitter()\n",
        "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1])\n",
        "\n",
        "    # Load dataset info\n",
        "    load_info = './.info.pt'\n",
        "    info = torch.load(load_info)\n",
        "\n",
        "    # Build Ai4MarsDataloader\n",
        "    loader = Ai4MarsDataLoader()\n",
        "    train_loader, test_loader, val_loader = loader(\n",
        "        [train_set, test_set, val_set], [32, 16, 16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmRVji71wGJc"
      },
      "outputs": [],
      "source": [
        "# Dataloader\n",
        "\n",
        "# Set this to True if you wnat to load directly the dataloader\n",
        "# this can be done only on colab and it is useful to avoid runtime crash\n",
        "LOAD = False\n",
        "\n",
        "if LOAD and not LOAD_CHUNK:\n",
        "\n",
        "    if COLAB:\n",
        "\n",
        "        if not(os.path.exists('/content/dataset/')):\n",
        "\n",
        "            import gdown\n",
        "\n",
        "            # get url of torch dataset (temporarerly my drive)\n",
        "            drive = 'https://drive.google.com/uc?id='\n",
        "            url = 'https://drive.google.com/drive/folders/104YvO3LcU76euuVe-_62eS_Rld-tOZeh?usp=drive_link'\n",
        "\n",
        "            !gdown --folder {url} -O /content/\n",
        "\n",
        "            load_data = '/content/dataset/dataset1000.pt'\n",
        "\n",
        "    elif LOCAL: \n",
        "        load_data = root_dir + '/datasetup/dataset/dataset1000.pt'\n",
        "\n",
        "    X, y = torch.load(load_data)\n",
        "\n",
        "    # Build dataset\n",
        "    splitter = Ai4MarsSplitter()\n",
        "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1])\n",
        "\n",
        "    # Load dataset info\n",
        "    load_info = './.info.pt'\n",
        "    info = torch.load(load_info)\n",
        "\n",
        "    # Build Ai4MarsDataloader\n",
        "    loader = Ai4MarsDataLoader()\n",
        "    train_loader, test_loader, val_loader = loader(\n",
        "        [train_set, test_set, val_set], [32, 16, 16])\n",
        "\n",
        "\n",
        "elif not LOAD and not LOAD_CHUNK:\n",
        "\n",
        "    # Insert here your local path to the dataset (temporary)\n",
        "    data_path ='/home/leeoos/Desktop/' #input(\"Path to Dataset: \")\n",
        "\n",
        "    # Insert here the number of images you want to download\n",
        "    num_images = 200 #int(input(\"Number of images (max 1000): \"))\n",
        "\n",
        "    save_path = None\n",
        "    # Uncomment the following line to the dataset on a local path\n",
        "    #save_path = root_dir + '/datasetup/dataset/'\n",
        "\n",
        "    if num_images > 1000 : raise Exception(\"Trying to import too many images\")\n",
        "\n",
        "    # Import data as Ai4MarsDataset\n",
        "    Ai4MarsDownload()(PATH=data_path)\n",
        "    importer = Ai4MarsImporter()\n",
        "    X, y, _ = importer(PATH=data_path, NUM_IMAGES=num_images, SAVE_PATH=save_path, SIZE=128)\n",
        "\n",
        "    transform = None\n",
        "    # Uncomment the following lines to apply transformations to the dataset\n",
        "    '''\n",
        "    transform = transforms.RandomChoice([\n",
        "     transforms.RandomRotation(90)])\n",
        "    '''\n",
        "\n",
        "    # Load info\n",
        "    load_info = './.info.pt'\n",
        "    info = torch.load(load_info)\n",
        "    \n",
        "    # Split the dataset\n",
        "    splitter = Ai4MarsSplitter()\n",
        "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1], transform=transform,\n",
        "                                            SAVE_PATH=save_path)\n",
        "\n",
        "    # Build Ai4MarsDataloader\n",
        "    loader = Ai4MarsDataLoader()\n",
        "    train_loader, test_loader, val_loader = loader([train_set, test_set, val_set], [32, 16, 16],\n",
        "                                                   SAVE_PATH=save_path)\n",
        "\n",
        "else:\n",
        "    print(\"Nothing to do\")\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpXj7Ow-wrL5"
      },
      "outputs": [],
      "source": [
        "# Just to check that different chunks contains different images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f'Len of train set: {len(train_set)}')\n",
        "print(f'Len of test set: {len(test_set)}')\n",
        "print(f'Len of validation set: {len(val_set)}')\n",
        "\n",
        "image, label = X[0], y[0]\n",
        "\n",
        "print(f'image shape: {image.permute(1,0,2).permute(0,2,1).shape}')\n",
        "plt.imshow(image.permute(1,0,2).permute(0,2,1).detach().numpy(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f'image shape: {label.permute(1,0,2).permute(0,2,1).shape}')\n",
        "plt.imshow(label.permute(1,0,2).permute(0,2,1).detach().numpy(), cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FCQvjMbelhL"
      },
      "outputs": [],
      "source": [
        "# Clone remote repo with existing models\n",
        "\n",
        "if COLAB:\n",
        "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
        "    %cd semantic-segmentation\n",
        "    %pip install -e .\n",
        "    %pip install -U gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from semseg import show_models\n",
        "\n",
        "show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCa6tmRlelhW"
      },
      "outputs": [],
      "source": [
        "#  Import segformer\n",
        "\n",
        "from semseg.models import *\n",
        "\n",
        "model = eval('SegFormer')(\n",
        "    backbone='MiT-B1',\n",
        "    num_classes=5\n",
        ")\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load('checkpoints/pretrained/segformer/segformer.b3.ade.pth',\n",
        "                                     map_location=device))\n",
        "    print(\"Pretrained model's weights downloaded\")\n",
        "except:\n",
        "    print(\"Download a pretrained model's weights from the result table.\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print('Loaded Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSxW3mFNelhl"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "\n",
        "loss_fn = Ai4MarsDiceLoss().to(device)\n",
        "#loss_fn = Ai4MarsCrossEntropy().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "transform = transforms.RandomChoice([\n",
        "     transforms.RandomRotation(90)])\n",
        "\n",
        "trainer = Ai4MarsTrainer(loss_fn, optimizer, train_loader, val_loader, \n",
        "                         transform=transform, device=device, info=info, model_name='MiT-B1', dump=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6p6LYs2R0fF"
      },
      "outputs": [],
      "source": [
        "# Module Parameters\n",
        "trainer.param_hist(model, SAVE_PATH=root_dir+'/experiments', label='before')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSkhk_Rl2gX0"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "trainer.train_multiple_epoch(model, EPOCHS=5, SAVE_PATH=root_dir+'/experiments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6HCej-k7w6R"
      },
      "outputs": [],
      "source": [
        "# Plot loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainer.plot_loss(model=model, SAVE_PATH=root_dir+'/experiments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydweI29r18jr"
      },
      "outputs": [],
      "source": [
        "# Testing and evaluation Metrics\n",
        "\n",
        "metric = metrics.JaccardIndex(task=\"multiclass\", num_classes=5).to(device)\n",
        "tester = Ai4MarsTester(loss_fn, metric, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ZyzuJW61Rs"
      },
      "outputs": [],
      "source": [
        "# Start testing\n",
        "\n",
        "tester.test_one_epoch(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_v2Q1AV73W"
      },
      "outputs": [],
      "source": [
        "# Module Parameters\n",
        "trainer.param_hist(model, SAVE_PATH=root_dir+'/experiments', label='after')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "for i, batch in enumerate(test_loader): \n",
        "  image, label = batch\n",
        "  print(image.shape)\n",
        "  pred = model(image.to(device))\n",
        "  tester.show_images(image, trainer.results_path, index=i)\n",
        "  tester.show_seg(label, trainer.results_path, index=i)\n",
        "  tester.show_seg(pred, trainer.results_path, index=i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

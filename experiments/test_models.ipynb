{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airoprojects/visiope/blob/tests/experiments/test_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General imports"
      ],
      "metadata": {
        "id": "NA344_H5pmEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiTAPAa9elhO"
      },
      "outputs": [],
      "source": [
        "# General imports\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "!pip install torchmetrics\n",
        "import torchmetrics as metrics\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "!pip install ipywidgets\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Imports"
      ],
      "metadata": {
        "id": "lygw33bMprOM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ywxl7By7Pv3"
      },
      "outputs": [],
      "source": [
        "# Custom Imports\n",
        "\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "LOCAL = not COLAB\n",
        "\n",
        "if COLAB:\n",
        "\n",
        "    # Clone visiope repo on runtime env\n",
        "    !git clone https://github.com/airoprojects/visiope.git /content/visiope/\n",
        "    %cd ./visiope/\n",
        "    !git checkout tests\n",
        "    !git branch\n",
        "    %cd ../\n",
        "\n",
        "    # Get the root directory of the Git project\n",
        "    root_dir = '/content/visiope'\n",
        "\n",
        "    # Add custom modules to path\n",
        "    custom_modules_path = root_dir + '/tools/'\n",
        "    sys.path.insert(0, custom_modules_path)\n",
        "\n",
        "elif LOCAL:\n",
        "\n",
        "    from git import Repo\n",
        "\n",
        "    # Initialize the Git repository object\n",
        "    repo = Repo(\".\", search_parent_directories=True)\n",
        "\n",
        "    # Get the root directory of the Git project\n",
        "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
        "\n",
        "    # Add custom modules to path\n",
        "    custom_modules_path = root_dir  + '/tools/'\n",
        "    sys.path.insert(0, custom_modules_path)\n",
        "\n",
        "\n",
        "# Import Loader\n",
        "from data.utils import Ai4MarsDownload, Ai4MarsImporter, Ai4MarsSplitter, Ai4MarsDataLoader\n",
        "\n",
        "# Import Loss\n",
        "from loss.loss import Ai4MarsCrossEntropy, Ai4MarsDiceLoss\n",
        "\n",
        "# Import Trainer\n",
        "from trainer.trainer import Ai4MarsTrainer\n",
        "\n",
        "# Import Tester\n",
        "from tester.tester import Ai4MarsTester\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain dataset"
      ],
      "metadata": {
        "id": "WRMqpowGpvoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selecter functions"
      ],
      "metadata": {
        "id": "9qe47EV7tZ_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the whole dataset\n",
        "def get_d(b):\n",
        "\n",
        "    global num_images\n",
        "    global data_path\n",
        "    global selector\n",
        "    global X\n",
        "    global y\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not selector:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "    selector = False\n",
        "\n",
        "    # Insert here your local path to the dataset (temporary)\n",
        "    data_path = input(\"Path to Dataset: \")\n",
        "\n",
        "    # Insert here the number of images you want to download\n",
        "    num_images = int(input(\"Number of images (max 1000): \"))\n",
        "\n",
        "    # Import data as Ai4MarsDataset\n",
        "    Ai4MarsDownload()(PATH=data_path)\n",
        "    importer = Ai4MarsImporter()\n",
        "    X, y, _ = importer(PATH=data_path, NUM_IMAGES=num_images, SIZE=128)\n",
        "\n",
        "    pass\n",
        "\n",
        "# Enable loading chunk of data\n",
        "def enable_chunk(b):\n",
        "\n",
        "    global selector\n",
        "    global CHUNK\n",
        "    global current_chunk\n",
        "\n",
        "    # Cannot select anymore\n",
        "    if not selector:\n",
        "        print(\"Cannot select multiple options\")\n",
        "        return\n",
        "    selector = False\n",
        "\n",
        "    CHUNK = True\n",
        "    current_chunk = 0\n",
        "\n",
        "    # Download options\n",
        "    d300 = widgets.Button(description=\"Dataset 300\")\n",
        "    d500 = widgets.Button(description=\"Dataset 500\")\n",
        "    d1k = widgets.Button(description=\"Dataset 1000\")\n",
        "\n",
        "    # Actions\n",
        "    display(d300, d500, d1k)\n",
        "    d300.on_click(get_d300)\n",
        "    d500.on_click(get_d500)\n",
        "    d1k.on_click(get_d1k)\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "fTO2wZubthnU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data download funtions"
      ],
      "metadata": {
        "id": "_cmnA4w0Gv-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ge the dataset in chncks of size 300\n",
        "def get_d300(b):\n",
        "    print(\"Ciao 300\")\n",
        "    pass\n",
        "\n",
        "# ge the dataset in chncks of size 500\n",
        "def get_d500(b):\n",
        "    print(\"Ciao 500\")\n",
        "    pass\n",
        "\n",
        "# ge the dataset in chncks of size 1k\n",
        "def get_d1k(b):\n",
        "\n",
        "    global COLAB\n",
        "    global current_chunk\n",
        "    global chunk_size\n",
        "    global X\n",
        "    global y\n",
        "\n",
        "    chunk_size = 1000\n",
        "\n",
        "    print(f\"Loading cunck {current_chunk//1000}\")\n",
        "\n",
        "    # update current chunk\n",
        "    current_chunk += 1000\n",
        "\n",
        "    if COLAB:\n",
        "\n",
        "        if not(os.path.exists('/content/dataset/')):\n",
        "\n",
        "            import gdown\n",
        "\n",
        "            # get url of torch dataset (temporarerly my drive)\n",
        "            drive = 'https://drive.google.com/uc?id='\n",
        "            url = 'https://drive.google.com/drive/folders/1BhL0nLbQt930l_ISDgUS8ZJRWGjH4eUU?usp=sharing'\n",
        "\n",
        "            !gdown --folder {url} -O /content/\n",
        "\n",
        "            load_data = '/content/chunk-dataset/'\n",
        "\n",
        "    elif LOCAL:\n",
        "        load_data = root_dir + '/datasetup/chunk-dataset/'\n",
        "\n",
        "    X, y = torch.load(load_data + 'dataset_' + str(current_chunk) + '.pt')\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "lp_QfZkaG1XJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Selector"
      ],
      "metadata": {
        "id": "CR-6RoS3t1IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select import mode\n",
        "\n",
        "# ENV VARIABLE DO NOT CHANGE\n",
        "CHUNK = False\n",
        "X = 0\n",
        "y = 0\n",
        "\n",
        "# Allow to select only one option\n",
        "if 'selector' not in globals():\n",
        "    selector  = True\n",
        "\n",
        "# Selection buttons\n",
        "d = widgets.Button(description=\"Load whole Dataset\")\n",
        "chunk = widgets.Button(description=\"Load chunk of data\")\n",
        "\n",
        "\n",
        "# actions\n",
        "display(d, chunk)\n",
        "d.on_click(get_d)\n",
        "chunk.on_click(enable_chunk)\n"
      ],
      "metadata": {
        "id": "-6wXNW5yp4Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "0827HU01q6nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = None\n",
        "# Uncomment the following lines to apply transformations to the dataset\n",
        "'''\n",
        "transform = transforms.RandomChoice([\n",
        "    transforms.RandomRotation(90)])\n",
        "'''\n",
        "\n",
        "# Split the dataset\n",
        "splitter = Ai4MarsSplitter()\n",
        "percentages = [0.7, 0.2, 0.1]\n",
        "train_set, test_set, val_set = splitter(X, y, percentages, transform=transform)\n",
        "\n",
        "# Load info\n",
        "load_info = './.info.pt'\n",
        "info = torch.load(load_info)\n",
        "\n",
        "# Build Ai4MarsDataloader\n",
        "loader = Ai4MarsDataLoader()\n",
        "batch_sizes = [32, 16, 16]\n",
        "datasets = [train_set, test_set, val_set]\n",
        "train_loader, test_loader, val_loader = loader(datasets, batch_sizes)\n",
        "\n",
        "# Free up mem\n",
        "del X\n",
        "del y"
      ],
      "metadata": {
        "id": "ca-BSlVTq_Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpXj7Ow-wrL5"
      },
      "outputs": [],
      "source": [
        "# Just to check that different chunks contains different images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f'Len of train set: {len(train_set)}')\n",
        "print(f'Len of test set: {len(test_set)}')\n",
        "print(f'Len of validation set: {len(val_set)}')\n",
        "\n",
        "image, label = X[0], y[0]\n",
        "\n",
        "print(f'image shape: {image.permute(1,0,2).permute(0,2,1).shape}')\n",
        "plt.imshow(image.permute(1,0,2).permute(0,2,1).detach().numpy(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f'image shape: {label.permute(1,0,2).permute(0,2,1).shape}')\n",
        "plt.imshow(label.permute(1,0,2).permute(0,2,1).detach().numpy(), cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model setup"
      ],
      "metadata": {
        "id": "pYPFyV05rDWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FCQvjMbelhL"
      },
      "outputs": [],
      "source": [
        "# Clone remote repo with existing models\n",
        "\n",
        "if COLAB:\n",
        "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
        "    %cd semantic-segmentation\n",
        "    %pip install -e .\n",
        "    %pip install -U gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gf3AWmRO_2CJ"
      },
      "outputs": [],
      "source": [
        "from semseg import show_models\n",
        "\n",
        "show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCa6tmRlelhW"
      },
      "outputs": [],
      "source": [
        "#  Import segformer\n",
        "\n",
        "from semseg.models import *\n",
        "\n",
        "model = eval('SegFormer')(\n",
        "    backbone='MiT-B1',\n",
        "    num_classes=5\n",
        ")\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load('checkpoints/pretrained/segformer/segformer.b3.ade.pth',\n",
        "                                     map_location=device))\n",
        "    print(\"Pretrained model's weights downloaded\")\n",
        "except:\n",
        "    print(\"Download a pretrained model's weights from the result table.\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "print('Loaded Model')\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "sTK2tqpgrILQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Regular training"
      ],
      "metadata": {
        "id": "vi6ZGOtk3EXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSxW3mFNelhl"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "\n",
        "loss_fn = Ai4MarsDiceLoss().to(device)\n",
        "#loss_fn = Ai4MarsCrossEntropy().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "transform = transforms.RandomChoice([\n",
        "     transforms.RandomRotation(90)])\n",
        "\n",
        "trainer = Ai4MarsTrainer(loss_fn, optimizer, train_loader, val_loader,\n",
        "                         transform=transform, device=device, info=info, model_name='MiT-B1', dump=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6p6LYs2R0fF"
      },
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "# Check if the variable has been defined\n",
        "if 'run_once' not in globals():\n",
        "    run_once = True\n",
        "    trainer.param_hist(model, SAVE_PATH=root_dir+'/experiments', label='before')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSkhk_Rl2gX0"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "trainer.train_multiple_epoch(model, EPOCHS=5, SAVE_PATH=root_dir+'/experiments')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6HCej-k7w6R"
      },
      "outputs": [],
      "source": [
        "# Plot loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainer.plot_loss(model=model, SAVE_PATH=root_dir+'/experiments')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chunk training"
      ],
      "metadata": {
        "id": "U92PUhBW2-lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not CHUNK:\n",
        "    print(\"You are not allowd to perform chunk training proceede with regular traiing\")\n",
        "\n",
        "else:\n",
        "\n",
        "    print(\"You are allowd to perform chunk training proceede with regular traiing\")\n",
        "    print(\"Please pay attention that you are using the same splitting parameters\")\n",
        "\n",
        "    # update current chunk\n",
        "    current_chunk += 1000\n",
        "\n",
        "    if current_chunk > 10000: raise Exception('Chunk out of range')\n",
        "\n",
        "    print(f\"Loading cunck {current_chunk//1000}\")\n",
        "\n",
        "    X, y = torch.load(load_data + 'dataset_' + str(current_chunk) + '.pt')\n",
        "\n",
        "    # Build dataset\n",
        "    splitter = Ai4MarsSplitter()\n",
        "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1])\n",
        "\n",
        "    # Load dataset info\n",
        "    if current_chunk <= 10000:\n",
        "        load_info = './.info.pt'\n",
        "        info = torch.load(load_info)\n",
        "\n",
        "    # Build Ai4MarsDataloader\n",
        "    loader = Ai4MarsDataLoader()\n",
        "    train_loader, test_loader, val_loader = loader(\n",
        "        [train_set, test_set, val_set], [32, 16, 16])"
      ],
      "metadata": {
        "id": "N6LW1nfz3MpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "8vQYontwr3W8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydweI29r18jr"
      },
      "outputs": [],
      "source": [
        "# Testing and evaluation Metrics\n",
        "\n",
        "metric = metrics.JaccardIndex(task=\"multiclass\", num_classes=5).to(device)\n",
        "tester = Ai4MarsTester(loss_fn, metric, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ZyzuJW61Rs"
      },
      "outputs": [],
      "source": [
        "# Start testing\n",
        "\n",
        "tester.test_one_epoch(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_v2Q1AV73W"
      },
      "outputs": [],
      "source": [
        "# Module Parameters\n",
        "trainer.param_hist(model, SAVE_PATH=root_dir+'/experiments', label='after')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewE16aoK_2CX"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "for i, batch in enumerate(test_loader):\n",
        "  image, label = batch\n",
        "  print(image.shape)\n",
        "  pred = model(image.to(device))\n",
        "  tester.show_images(image, trainer.results_path, index=i)\n",
        "  tester.show_seg(label, trainer.results_path, index=i)\n",
        "  tester.show_seg(pred.cpu(), trainer.results_path, index=i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3551,
     "status": "ok",
     "timestamp": 1689164151821,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kytW-DGR_xaS",
    "outputId": "e2d0b3eb-5cdd-45d6-af7e-00fb52eb82f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/semantic-segmentation/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import io\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import gc\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "    \n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Set up path for custom importer modules\n",
    "    # Data Loader\n",
    "    importer_module = root_dir + '/dataloader/'\n",
    "    sys.path.insert(0, importer_module)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Loss\n",
    "\n",
    "    loss_module = root_dir + '/trainer/loss/'\n",
    "    sys.path.insert(0, loss_module)\n",
    "    import loss\n",
    "\n",
    "    # Trainer\n",
    "    trainer_module = root_dir + '/trainer/'\n",
    "    sys.path.insert(0, trainer_module)\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    data_path = data_path = input(\"Path to Dataset: \") #'/home/leeoos/Desktop/'\n",
    "\n",
    "else: # IN_COLAB\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # On Colab the path to the module ti fixed once you have\n",
    "    # corretly set up the project with gitsetup.ipynb\n",
    "\n",
    "    # Import Loader\n",
    "    fixed_path_loader = '/content/drive/MyDrive/Github/visiope/dataloader/'\n",
    "    sys.path.insert(0, fixed_path_loader)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Import Trainer\n",
    "    fixed_path_trainer = '/content/drive/MyDrive/Github/visiope/trainer/'\n",
    "    sys.path.insert(0,fixed_path_trainer )\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Import Loss\n",
    "    fixed_path_loss = '/content/drive/MyDrive/Github/visiope/trainer/loss/'\n",
    "    sys.path.insert(0, fixed_path_loss)\n",
    "    import loss\n",
    "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
    "    %pip install -U gdown\n",
    "    %pip install -e .\n",
    "    %pip install einops\n",
    "    import gdown\n",
    "    from pathlib import Path\n",
    "\n",
    "    ckpt = Path('./checkpoints/pretrained/segformer')\n",
    "    ckpt.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n",
    "    output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n",
    "\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1689164151824,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kwVFZJKgXULT"
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "if test:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nc):\n",
    "            self.nc = nc\n",
    "            super(Generator, self).__init__()\n",
    "\n",
    "\n",
    "        def forward(self, embeds):\n",
    "            ngf = 64\n",
    "            nz = [[None] *6]*4\n",
    "\n",
    "            j = 0\n",
    "            for embed in embeds:\n",
    "                nz[j][0] = embed.size()[1]\n",
    "                for i in range(1,6):\n",
    "                    if i < 4:\n",
    "                        nz[j][i] = nz[i-1]//2\n",
    "                    else:\n",
    "                        nz[j][i] = nz[i-1]//4\n",
    "                j = j+1\n",
    "                print(nz)\n",
    "            self.main = nn.Sequential(\n",
    "                #reduction of dimensionality To Be Changed in conv... maybe\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d( nz[6], ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, self.nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(nc) x 64 x 64``\n",
    "            )\n",
    "\n",
    "            return self.main(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1689164151825,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "1n9BBXOOn-Cl"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 64\n",
    "        nc = 1\n",
    "        print(nz)\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1689172253886,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "JQZWxsQIe5z0",
    "outputId": "7a82fbd2-e89f-4939-85ff-9cbdacb1196f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "T: tensor([[0., 0., 1., 2., 3., 4., 4., 3., 2., 5., 6., 5.],\n",
      "        [0., 0., 0., 3., 4., 1., 0., 3., 4., 1., 6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Python program to join tensors in PyTorch\n",
    "# import necessary library\n",
    "import torch\n",
    "\n",
    "# create tensors\n",
    "\n",
    "T1 = torch.zeros((2,2))\n",
    "T2 = torch.Tensor([[1,2,3,4],[0,3,4,1]])\n",
    "T3 = torch.Tensor([[4,3,2,5,6,5], [0,3,4,1,6,8]])\n",
    "\n",
    "print(T1)\n",
    "\n",
    "# join (concatenate) above tensors using torch.cat()\n",
    "T = torch.cat((T1,T2,T3), dim=1)\n",
    "# print final tensor after concatenation\n",
    "print(\"T:\",T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151827,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ZD2IYalLn-Co"
   },
   "outputs": [],
   "source": [
    "test1 = True\n",
    "if test1:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nz):\n",
    "            super(Generator, self).__init__()\n",
    "            ngf = 64\n",
    "            nc = 5\n",
    "            self.main = nn.Sequential()\n",
    "            self.main = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                #in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, ngf//2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf//2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf/2) x 64 x 64``\n",
    "                nn.ConvTranspose2d( ngf//2, nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(ngc) x 128 x 128``\n",
    "                # state size. ``(ngf/4) x 128 x 128``\n",
    "                #nn.BatchNorm2d(ngf),\n",
    "                #nn.ReLU(True),\n",
    "                #nn.ConvTranspose2d( ngf/4, nc, 4, 2, 1, bias=False),\n",
    "                #nn.Tanh()\n",
    "                # state size. ``(nc) x 256 x 256``\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151829,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "PyC-nI41XULT"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class SegFormerHead(nn.Module):\n",
    "    def __init__(self, dims: list, embed_dim: int = 256, num_classes: int = 19):\n",
    "        super().__init__()\n",
    "        for i, dim in enumerate(dims):\n",
    "            self.add_module(f\"linear_c{i+1}\", MLP(dim, embed_dim))\n",
    "\n",
    "        self.linear_fuse = ConvModule(embed_dim*4, embed_dim)\n",
    "        self.linear_pred = nn.Conv2d(embed_dim, num_classes, 1)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        B, _, H, W = features[0].shape\n",
    "        outs = [self.linear_c1(features[0]).permute(0, 2, 1).reshape(B, -1, *features[0].shape[-2:])]\n",
    "\n",
    "        for i, feature in enumerate(features[1:]):\n",
    "            cf = eval(f\"self.linear_c{i+2}\")(feature).permute(0, 2, 1).reshape(B, -1, *feature.shape[-2:])\n",
    "            outs.append(F.interpolate(cf, size=(H, W), mode='bilinear', align_corners=False))\n",
    "\n",
    "        seg = self.linear_fuse(torch.cat(outs[::-1], dim=1))\n",
    "        seg = self.linear_pred(self.dropout(seg))\n",
    "        return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1689164151831,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "MCJtu7Y_n-Cr"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, 1, -1)\n",
    "\n",
    "class FlattenFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, -1, 1, 1)\n",
    "\n",
    "class Conv2DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv1DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class downsample(nn.Module):\n",
    "    def __init__(self, C, H, W):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Sequential()\n",
    "        i = 0\n",
    "        alt = True\n",
    "        if H*W > 128:\n",
    "            while(C>4):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "\n",
    "        else:\n",
    "            while(C>16):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "        self.downsample.append(FlattenFinal())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.downsample(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1689164151833,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ipHImK80n-Ct"
   },
   "outputs": [],
   "source": [
    "class SegFormerHeadGen(nn.Module):\n",
    "\n",
    "    def __init__(self, num_img):\n",
    "      self.num_img = num_img\n",
    "      super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "      x = features[self.num_img]\n",
    "      downsampler = downsample(x.shape[1],x.shape[2],x.shape[3]).to(device)\n",
    "\n",
    "\n",
    "      downsampler(x).size()\n",
    "      self.G = Generator(downsampler(x).size()[1]).to(device)\n",
    "      image = self.G(downsampler(x))\n",
    "\n",
    "\n",
    "      return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1689164151835,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "cZsudwlzXULU"
   },
   "outputs": [],
   "source": [
    "from semseg.models.base import BaseModel\n",
    "from semseg.models.heads import SegFormerHead\n",
    "#from resDecode import ResDecode\n",
    "\n",
    "\n",
    "class SegFormerpp(BaseModel):\n",
    "    def __init__(self, backbone: str = 'MiT-B0', num_classes: int = 19, head: str = 'B0', num_img: int = -1) -> None:\n",
    "        super().__init__(backbone, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.head = head\n",
    "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
    "        self.newDecode = SegFormerHeadGen(num_img)\n",
    "        self.newDecode.to(device)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        #y = self.decode(y)\n",
    "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        #embeds = []\n",
    "        y = self.newDecode(y)\n",
    "        '''\n",
    "        y = self.decode(y)\n",
    "        self.upsample = nn.Sequential(\n",
    "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
    "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),\n",
    "                                )\n",
    "        y = self.upsample(y).to(device)\n",
    "        '''\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1689164378457,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "bglipAaW_xaY",
    "outputId": "3e943d2f-8865-402a-df70-ec5bc156817f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download a pretrained model's weights from the result table.\n",
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "from semseg.models import *\n",
    "#from segFormerpp import SegFormerpp\n",
    "\n",
    "model = eval('SegFormerpp')(\n",
    "    backbone='MiT-B4',\n",
    "    num_classes=5,\n",
    "    num_img = 0\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('checkpointcheckpoints/pretrained/segformer/segformer.b3.ade.pth'))\n",
    "except:\n",
    "    print(\"Download a pretrained model's weights from the result table.\")\n",
    "model.eval()\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1689164151839,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "L2H1x10FXULW"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "  %cd ../../dataloader/\n",
    "  from load import Ai4MarsData\n",
    "  %cd ../models/semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28194,
     "status": "ok",
     "timestamp": 1689164179977,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "stv4_1XZXULW",
    "outputId": "ba951ed3-d81a-44e2-cae6-fecb989a9cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'visiope'...\n",
      "remote: Enumerating objects: 954, done.\u001b[K\n",
      "remote: Counting objects: 100% (358/358), done.\u001b[K\n",
      "remote: Compressing objects: 100% (212/212), done.\u001b[K\n",
      "remote: Total 954 (delta 197), reused 262 (delta 140), pack-reused 596\u001b[K\n",
      "Receiving objects: 100% (954/954), 71.42 MiB | 13.95 MiB/s, done.\n",
      "Resolving deltas: 100% (510/510), done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1HLAQgjZbGa3lMzdyIvgykCiUJ6P4OaEX\n",
      "From (redirected): https://drive.google.com/uc?id=1HLAQgjZbGa3lMzdyIvgykCiUJ6P4OaEX&confirm=t&uuid=07c0d5b9-ab3e-4868-add1-9d73cd904df6\n",
      "To: /content/dataset/X_200.npy\n",
      "100%|██████████| 629M/629M [00:05<00:00, 117MB/s]\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1Ue74LEe0WlEnFxRcIl19WyvXR1EyYIsS\n",
      "From (redirected): https://drive.google.com/uc?id=1Ue74LEe0WlEnFxRcIl19WyvXR1EyYIsS&confirm=t&uuid=4477ef1a-5a6b-4628-9039-cae00c54af6c\n",
      "To: /content/dataset/y_200.npy\n",
      "100%|██████████| 210M/210M [00:01<00:00, 107MB/s]\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB  :\n",
    "    #!git clone https://github.com/airoprojects/visiope\n",
    "    # %cd visiope/dataloader/\n",
    "    # from load import Ai4MarsData\n",
    "    # %cd ../..\n",
    "    # with open('/content/drive/MyDrive/Dataset/data_loader.pkl', 'rb') as f:\n",
    "    #     data_loader = pickle.load(f)\n",
    "\n",
    "\n",
    "    # data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\n",
    "    # data_loader['dataloader'].dataset.setDevice(device,0)\n",
    "    # data_loader['dataloader'].dataset.setDevice(device,1)\n",
    "    # #data_loader['dataloader'].dataset.setdevice(device)\n",
    "\n",
    "    # train_loader, test_loader, validation_loader = data_loader['dataloader'].dataset.splitLoader(80,1)\n",
    "\n",
    "\n",
    "    if not(os.path.exists('/content/dataset/X_200') and\n",
    "        os.path.exists('/content/dataset/y_200')):\n",
    "\n",
    "        import gdown\n",
    "\n",
    "        # # get url of np dataset (temporarerly my drive)\n",
    "        # url_X = 'https://drive.google.com/uc?id=1HLAQgjZbGa3lMzdyIvgykCiUJ6P4OaEX'\n",
    "        # url_y = 'https://drive.google.com/uc?id=1Ue74LEe0WlEnFxRcIl19WyvXR1EyYIsS'\n",
    "\n",
    "        # # download np dataset on runtime env\n",
    "        # data_path = '/content/dataset/'\n",
    "        # gdown.download(url_X, data_path, quiet=False)\n",
    "        # gdown.download(url_y, data_path, quiet=False)\n",
    "\n",
    "        # get url of np dataset (temporarerly my drive)\n",
    "        url_X_200 = 'https://drive.google.com/uc?id=1HLAQgjZbGa3lMzdyIvgykCiUJ6P4OaEX'\n",
    "        url_y_200 = 'https://drive.google.com/uc?id=1Ue74LEe0WlEnFxRcIl19WyvXR1EyYIsS'\n",
    "\n",
    "        url_X_1000 = 'https://drive.google.com/uc?id=1zvXKK1qc2PNbAMyq0XWfqrhAWB5kO3yO'\n",
    "        url_y_1000 = 'https://drive.google.com/uc?id=1gmnWAGjZJYt-VIpWRK_cEOXQfFfuFAwe'\n",
    "\n",
    "        # download np dataset on runtime env\n",
    "        data_path = '/content/dataset/'\n",
    "        gdown.download(url_X_200, data_path, quiet=False)\n",
    "        gdown.download(url_y_200, data_path, quiet=False)\n",
    "\n",
    "\n",
    "    X = np.load('/content/dataset/X_200.npy')\n",
    "    y = np.load('/content/dataset/y_200.npy')\n",
    "\n",
    "    processor = Ai4MarsProcessor()\n",
    "    train_set, test_set, val_set = processor(X, y, [0.60, 0.20, 0.20])\n",
    "\n",
    "    train_set.resize(128)\n",
    "    test_set.resize(128)\n",
    "    val_set.resize(128)\n",
    "\n",
    "    train_set.conversion('f')\n",
    "    test_set.conversion('f')\n",
    "    val_set.conversion('f')\n",
    "\n",
    "    train_set.set_grad()\n",
    "    test_set.set_grad()\n",
    "    val_set.set_grad()\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1689164179979,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kUgDMrCLXULW"
   },
   "outputs": [],
   "source": [
    "#local\n",
    "if not IN_COLAB:\n",
    "\n",
    "    with open('../../dataloader/data_loader.pkl', 'rb') as f:\n",
    "        data_loader = pickle.load(f)\n",
    "\n",
    "    data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\n",
    "    data_loader['dataloader'].dataset.resize(128)\n",
    "    #data_loader['dataloader'].dataset.convertion(0)\n",
    "    data_loader['dataloader'].dataset.setDevice(device,0)\n",
    "    data_loader['dataloader'].dataset.setDevice(device,1)\n",
    "    #data_loader['dataloader'].dataset.setdevice(device)\n",
    "\n",
    "    train_loader, test_loader, validation_loader = data_loader['dataloader'].dataset.splitLoader(80,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1689164179981,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "O3ytN-ugjHcW",
    "outputId": "29fe6dcc-1983-4c1b-a1e5-eabff10ea398"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n  print(img.device)\\n  print(img.shape)\\n  if (img.device != 'cpu'):\\n    img.to('cpu')\\n    print('test')\\n  print(img.device)\\n  plt.imshow(img)\\n  plt.show()\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show_image(imgs):\n",
    "    imgs = imgs.permute(2,0,1)\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "'''\n",
    "  print(img.device)\n",
    "  print(img.shape)\n",
    "  if (img.device != 'cpu'):\n",
    "    img.to('cpu')\n",
    "    print('test')\n",
    "  print(img.device)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1689164179982,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "bCdsw7j2XULX"
   },
   "outputs": [],
   "source": [
    "#local\n",
    "if not IN_COLAB:\n",
    "  %cd ../../loss/\n",
    "  from trainer_module import trainer\n",
    "  %cd ../models/semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1689164179983,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "CLayxBcAr68t",
    "outputId": "1713d260-a587-4b8d-8463-7ca8462ca146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1689164179984,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "Bqlb9HnBYe54",
    "outputId": "a52bdc32-ab8f-4497-be9b-8e26567082bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nif IN_COLAB  :\\n    %cd visiope/loss/\\n    from trainer_module import trainer\\n    %cd ../..\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if IN_COLAB  :\n",
    "    %cd visiope/loss/\n",
    "    from trainer_module import trainer\n",
    "    %cd ../..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1689164179986,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "3lU21D6nXULX"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer module for MER-Segmentation \"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "\n",
    "# Main trainer function\n",
    "def trainer(parameters, multiple_epochs=False, epoch_index=0, tb_writer=0):\n",
    "    model = parameters['model']\n",
    "    device = parameters['device']\n",
    "    model.to(device)\n",
    "    if multiple_epochs:\n",
    "        train_multiple_epoch(parameters,  model, EPOCHS=100)\n",
    "\n",
    "    else:\n",
    "        train_one_epoch(parameters, epoch_index, tb_writer, model)\n",
    "\n",
    "# IMPORTANT: FIND OUT ABOUT TB_WRITER\n",
    "def train_one_epoch(parameters, epoch_index, tb_writer, model):\n",
    "\n",
    "    # Initialization of training parameters\n",
    "\n",
    "    loss_fn = parameters['loss']\n",
    "    optimizer = parameters['optimizer']\n",
    "    training_set = parameters['training']\n",
    "    device = parameters['device']\n",
    "\n",
    "    # To keep track of the last loss when the function is executed through multiple epochs\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_set):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        #inputs = inputs.permute(0,3,1,2).to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels.long()\n",
    "\n",
    "        labels = labels.squeeze()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        #print(labels.type())\n",
    "\n",
    "\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # IMPORTANT: UNCOMMENT THIS PART AFTER FINDING OUT ABOUT TB_WRITER\n",
    "        '''\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_set) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "        '''\n",
    "        inputs.detach()\n",
    "        labels.detach()\n",
    "        del inputs\n",
    "        del labels\n",
    "\n",
    "    last_loss = running_loss/(i+1)\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "def train_multiple_epoch(parameters, model, EPOCHS=100):\n",
    "\n",
    "    # Initialization of training parameters\n",
    "    loss_fn = parameters['loss']\n",
    "    #optimizer = parameters['optimizer']\n",
    "    #training_set = parameters['training']\n",
    "    validation_set = parameters['validation']\n",
    "\n",
    "    # Initialization of report parameters\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = 0 #SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "    epoch_number = 0 # just a counter\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        avg_loss = train_one_epoch(parameters, epoch_number, writer, model)\n",
    "\n",
    "        end = time.time()\n",
    "        print(\"epoch time: \"+str(end-start)+\"s\")\n",
    "\n",
    "        # We don't need gradients on to do reporting\n",
    "        model.train(False)\n",
    "\n",
    "        # Validation loss\n",
    "        running_vloss = 0.0\n",
    "        for i, vdata in enumerate(validation_set):\n",
    "            vinputs, vlabels = vdata\n",
    "\n",
    "            vlabels = vlabels.squeeze()\n",
    "            vlabels = vlabels.long()\n",
    "\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "\n",
    "            voutputs = model(vinputs)\n",
    "\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        # IMPORTANT: UNCOMMENT THIS PART AFTER FINDING OUT ABOUT TB_WRITER\n",
    "        '''\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        '''\n",
    "        #torch.cuda.memory_summary()\n",
    "        vinputs.detach()\n",
    "        vlabels.detach()\n",
    "        del vinputs\n",
    "        del vlabels\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        #torch.cuda.memory_summary()\n",
    "\n",
    "        epoch_number += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # This variable needs to be initialized with dummy values/data to test loss integration\n",
    "    '''\n",
    "    model = 0\n",
    "    optimizer = 0\n",
    "    loss_fn = 0\n",
    "    training_set = 0\n",
    "    validation_set = 0\n",
    "\n",
    "    parameters = {\n",
    "                    'model' : model,\n",
    "                    'loss' : loss_fn,\n",
    "                    'optimizer' : optimizer,\n",
    "                    'training' : training_set,\n",
    "                    'validation': validation_set\n",
    "    }\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nPp5CAvn-Qf"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVll-qRSXULY",
    "outputId": "e125181d-a822-4c69-f272-ea55ec43af18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "epoch time: 1.701798677444458s\n",
      "LOSS train 1.675107091665268 valid 1.6850411891937256\n",
      "EPOCH 2:\n",
      "epoch time: 1.5604867935180664s\n",
      "LOSS train 1.6485661268234253 valid 1.6498510837554932\n",
      "EPOCH 3:\n",
      "epoch time: 1.3964083194732666s\n",
      "LOSS train 1.6778640151023865 valid 1.710861086845398\n",
      "EPOCH 4:\n",
      "epoch time: 1.3540217876434326s\n",
      "LOSS train 1.6554960310459137 valid 1.6965243816375732\n",
      "EPOCH 5:\n",
      "epoch time: 1.3792519569396973s\n",
      "LOSS train 1.6761048436164856 valid 1.6738336086273193\n",
      "EPOCH 6:\n",
      "epoch time: 1.3901605606079102s\n",
      "LOSS train 1.6646405160427094 valid 1.6377824544906616\n",
      "EPOCH 7:\n",
      "epoch time: 1.4117755889892578s\n",
      "LOSS train 1.6803098022937775 valid 1.6948928833007812\n",
      "EPOCH 8:\n",
      "epoch time: 1.6654863357543945s\n",
      "LOSS train 1.647966355085373 valid 1.6606907844543457\n",
      "EPOCH 9:\n",
      "epoch time: 1.5083017349243164s\n",
      "LOSS train 1.7042682766914368 valid 1.6818288564682007\n",
      "EPOCH 10:\n",
      "epoch time: 1.420896291732788s\n",
      "LOSS train 1.654944896697998 valid 1.6639127731323242\n",
      "EPOCH 11:\n",
      "epoch time: 1.4395742416381836s\n",
      "LOSS train 1.6658083498477936 valid 1.685899257659912\n",
      "EPOCH 12:\n",
      "epoch time: 1.3558416366577148s\n",
      "LOSS train 1.6512114703655243 valid 1.6689529418945312\n",
      "EPOCH 13:\n",
      "epoch time: 1.4605927467346191s\n",
      "LOSS train 1.6560589671134949 valid 1.7006735801696777\n",
      "EPOCH 14:\n",
      "epoch time: 1.5491366386413574s\n",
      "LOSS train 1.6644881069660187 valid 1.664924144744873\n",
      "EPOCH 15:\n",
      "epoch time: 1.6641111373901367s\n",
      "LOSS train 1.6562680006027222 valid 1.634775161743164\n",
      "EPOCH 16:\n",
      "epoch time: 1.4305062294006348s\n",
      "LOSS train 1.6469858884811401 valid 1.696425437927246\n",
      "EPOCH 17:\n",
      "epoch time: 1.3684988021850586s\n",
      "LOSS train 1.6728558838367462 valid 1.6830718517303467\n",
      "EPOCH 18:\n",
      "epoch time: 1.425968885421753s\n",
      "LOSS train 1.6708632409572601 valid 1.6970157623291016\n",
      "EPOCH 19:\n",
      "epoch time: 1.4223144054412842s\n",
      "LOSS train 1.627616971731186 valid 1.6855456829071045\n",
      "EPOCH 20:\n",
      "epoch time: 1.358372688293457s\n",
      "LOSS train 1.6724992096424103 valid 1.6870355606079102\n",
      "EPOCH 21:\n",
      "epoch time: 1.567927360534668s\n",
      "LOSS train 1.6771351993083954 valid 1.6598620414733887\n",
      "EPOCH 22:\n",
      "epoch time: 1.64459228515625s\n",
      "LOSS train 1.6722641587257385 valid 1.6829890012741089\n",
      "EPOCH 23:\n",
      "epoch time: 1.435455322265625s\n",
      "LOSS train 1.714375227689743 valid 1.6505622863769531\n",
      "EPOCH 24:\n",
      "epoch time: 1.358227252960205s\n",
      "LOSS train 1.6578931212425232 valid 1.742828607559204\n",
      "EPOCH 25:\n",
      "epoch time: 1.4237887859344482s\n",
      "LOSS train 1.6907321512699127 valid 1.6738519668579102\n",
      "EPOCH 26:\n",
      "epoch time: 1.4107873439788818s\n",
      "LOSS train 1.679694503545761 valid 1.6865770816802979\n",
      "EPOCH 27:\n",
      "epoch time: 1.405261516571045s\n",
      "LOSS train 1.6829897165298462 valid 1.6409265995025635\n",
      "EPOCH 28:\n",
      "epoch time: 1.6097283363342285s\n",
      "LOSS train 1.6402949094772339 valid 1.6287505626678467\n",
      "EPOCH 29:\n",
      "epoch time: 1.729212999343872s\n",
      "LOSS train 1.6891143023967743 valid 1.670760154724121\n",
      "EPOCH 30:\n",
      "epoch time: 1.6597375869750977s\n",
      "LOSS train 1.6829046308994293 valid 1.7056788206100464\n",
      "EPOCH 31:\n",
      "epoch time: 1.3936290740966797s\n",
      "LOSS train 1.680767685174942 valid 1.6481444835662842\n",
      "EPOCH 32:\n",
      "epoch time: 1.4172794818878174s\n",
      "LOSS train 1.676528424024582 valid 1.6687772274017334\n",
      "EPOCH 33:\n",
      "epoch time: 1.3854048252105713s\n",
      "LOSS train 1.6631169319152832 valid 1.6667704582214355\n",
      "EPOCH 34:\n",
      "epoch time: 1.4355559349060059s\n",
      "LOSS train 1.6470157504081726 valid 1.6780216693878174\n",
      "EPOCH 35:\n",
      "epoch time: 1.5915162563323975s\n",
      "LOSS train 1.6569533348083496 valid 1.6947710514068604\n",
      "EPOCH 36:\n",
      "epoch time: 1.566748857498169s\n",
      "LOSS train 1.6667079627513885 valid 1.6430716514587402\n",
      "EPOCH 37:\n",
      "epoch time: 1.3975396156311035s\n",
      "LOSS train 1.6993349492549896 valid 1.717308521270752\n",
      "EPOCH 38:\n",
      "epoch time: 1.4126911163330078s\n",
      "LOSS train 1.6451951265335083 valid 1.7171037197113037\n",
      "EPOCH 39:\n",
      "epoch time: 1.3378348350524902s\n",
      "LOSS train 1.6628428101539612 valid 1.6747462749481201\n",
      "EPOCH 40:\n",
      "epoch time: 1.377321481704712s\n",
      "LOSS train 1.6628354787826538 valid 1.6590547561645508\n",
      "EPOCH 41:\n",
      "epoch time: 1.4687011241912842s\n",
      "LOSS train 1.6763364672660828 valid 1.6969029903411865\n",
      "EPOCH 42:\n",
      "epoch time: 1.66243314743042s\n",
      "LOSS train 1.669135868549347 valid 1.648334264755249\n",
      "EPOCH 43:\n",
      "epoch time: 1.454106092453003s\n",
      "LOSS train 1.6536164581775665 valid 1.6933269500732422\n",
      "EPOCH 44:\n",
      "epoch time: 1.3698861598968506s\n",
      "LOSS train 1.6566265523433685 valid 1.667335033416748\n",
      "EPOCH 45:\n",
      "epoch time: 1.3513777256011963s\n",
      "LOSS train 1.6372391283512115 valid 1.7013890743255615\n",
      "EPOCH 46:\n",
      "epoch time: 1.383085012435913s\n",
      "LOSS train 1.6667466163635254 valid 1.6936450004577637\n",
      "EPOCH 47:\n",
      "epoch time: 1.3497154712677002s\n",
      "LOSS train 1.6866807043552399 valid 1.6725095510482788\n",
      "EPOCH 48:\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "training_set = train_loader\n",
    "validation_set = test_loader\n",
    "\n",
    "parameters = {\n",
    "    'model' : model,\n",
    "    'loss' : loss_fn,\n",
    "    'optimizer' : optimizer,\n",
    "    'training' : training_set,\n",
    "    'validation' : validation_set,\n",
    "    'device' : device\n",
    "}\n",
    "#trainer(parameters)\n",
    "trainer(parameters,multiple_epochs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "error",
     "timestamp": 1689164347160,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "FZzOcvNXLK19",
    "outputId": "6d586d17-2309-43bf-e0a8-02c5aa9036d4"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-43ec9088272d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Forward pass to get the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-28ad3a4003c6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m#y = self.decode(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/semantic-segmentation/semseg/models/backbones/mit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# stage 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/semantic-segmentation/semseg/models/backbones/mit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "from semseg.datasets import *\n",
    "\n",
    "#model = model.to(device)\n",
    "predictions = []\n",
    "start = time.time()\n",
    "#print('test')\n",
    "# Use torch.no_grad() to disable gradient computation during testing\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the desired device\n",
    "        #print(images.shape)\n",
    "        #images = images.permute(0,3,1,2).to(device)\n",
    "        #images = images.permute(2,0,1).to(device)\n",
    "        #images = images [None, :, :, :]\n",
    "        #print(images.shape)\n",
    "\n",
    "        #print(images.shape)\n",
    "        #labels = labels.to(device)\n",
    "\n",
    "        # Forward pass to get the predictions\n",
    "        with torch.inference_mode():\n",
    "          prediction = model(images)\n",
    "        #print(prediction)\n",
    "        prediction = prediction.softmax(1).argmax(1).to(int)\n",
    "        #prediction = prediction.round().to(int)\n",
    "        #print(prediction.shape)\n",
    "        un = prediction.unique()\n",
    "        #print(un)\n",
    "        palette = eval('ADE20K').PALETTE.to(device)\n",
    "        prediction_map = palette[prediction].squeeze().to(torch.uint8)\n",
    "        #print(type(prediction_map))\n",
    "        show_image(prediction_map)\n",
    "        predictions.append(prediction_map)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1689164347161,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "UKfyLsOXXBjx"
   },
   "outputs": [],
   "source": [
    "torch.randn(64, 512, 1, 1, device=device).size()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

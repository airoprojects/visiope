{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3551,
     "status": "ok",
     "timestamp": 1689164151821,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kytW-DGR_xaS",
    "outputId": "e2d0b3eb-5cdd-45d6-af7e-00fb52eb82f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIN_COLAB = \\'google.colab\\' in sys.modules\\n\\nif not IN_COLAB:\\n    from git import Repo\\n\\n    # Initialize the Git repository object\\n    repo = Repo(\".\", search_parent_directories=True)\\n\\n    # Get the root directory of the Git project\\n    root_dir = repo.git.rev_parse(\"--show-toplevel\")\\n\\n    from pathlib import Path\\n\\n    # Set up path for custom importer modules\\n    # Data Loader\\n    importer_module = root_dir + \\'/dataloader/\\'\\n    print(importer_module)\\n    sys.path.insert(0, importer_module)\\n    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\\n\\n    # Loss\\n\\n    loss_module = root_dir + \\'/trainer/loss/\\'\\n    sys.path.insert(0, loss_module)\\n    import loss\\n\\n    # Trainer\\n    trainer_module = root_dir + \\'/trainer/\\'\\n    sys.path.insert(0, trainer_module)\\n    from trainer import Ai4MarsTrainer\\n\\n    # Insert here your local path to the dataset (temporary)\\n    data_path = input(\"Path to Dataset: \") #\\'/home/leeoos/Desktop/\\'\\n\\nelse: # IN_COLAB\\n\\n    from google.colab import drive\\n    drive.mount(\\'/content/drive\\')\\n\\n    # On Colab the path to the module ti fixed once you have\\n    # corretly set up the project with gitsetup.ipynb\\n\\n    # Import Loader\\n    fixed_path_loader = \\'/content/drive/MyDrive/Github/visiope/dataloader/\\'\\n    sys.path.insert(0, fixed_path_loader)\\n    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\\n\\n    # Import Trainer\\n    fixed_path_trainer = \\'/content/drive/MyDrive/Github/visiope/trainer/\\'\\n    sys.path.insert(0,fixed_path_trainer )\\n    from trainer import Ai4MarsTrainer\\n\\n    # Import Loss\\n    fixed_path_loss = \\'/content/drive/MyDrive/Github/visiope/trainer/loss/\\'\\n    sys.path.insert(0, fixed_path_loss)\\n    import loss\\n    \\n    !git clone https://github.com/sithu31296/semantic-segmentation\\n    %pip install -U gdown\\n    %pip install -e .\\n    %pip install einops\\n    import gdown\\n    from pathlib import Path\\n\\n    ckpt = Path(\\'./checkpoints/pretrained/segformer\\')\\n    ckpt.mkdir(exist_ok=True, parents=True)\\n\\n    url = \\'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT\\'\\n    output = \\'./checkpoints/pretrained/segformer/segformer.b3.ade.pth\\'\\n\\n    gdown.download(url, output, quiet=False)\\n\\ndevice = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n%cd semantic-segmentation\\n#/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import io\n",
    "from torchvision import transforms \n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import gc\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "'''\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Set up path for custom importer modules\n",
    "    # Data Loader\n",
    "    importer_module = root_dir + '/dataloader/'\n",
    "    print(importer_module)\n",
    "    sys.path.insert(0, importer_module)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Loss\n",
    "\n",
    "    loss_module = root_dir + '/trainer/loss/'\n",
    "    sys.path.insert(0, loss_module)\n",
    "    import loss\n",
    "\n",
    "    # Trainer\n",
    "    trainer_module = root_dir + '/trainer/'\n",
    "    sys.path.insert(0, trainer_module)\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    data_path = input(\"Path to Dataset: \") #'/home/leeoos/Desktop/'\n",
    "\n",
    "else: # IN_COLAB\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # On Colab the path to the module ti fixed once you have\n",
    "    # corretly set up the project with gitsetup.ipynb\n",
    "\n",
    "    # Import Loader\n",
    "    fixed_path_loader = '/content/drive/MyDrive/Github/visiope/dataloader/'\n",
    "    sys.path.insert(0, fixed_path_loader)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Import Trainer\n",
    "    fixed_path_trainer = '/content/drive/MyDrive/Github/visiope/trainer/'\n",
    "    sys.path.insert(0,fixed_path_trainer )\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Import Loss\n",
    "    fixed_path_loss = '/content/drive/MyDrive/Github/visiope/trainer/loss/'\n",
    "    sys.path.insert(0, fixed_path_loss)\n",
    "    import loss\n",
    "    \n",
    "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
    "    %pip install -U gdown\n",
    "    %pip install -e .\n",
    "    %pip install einops\n",
    "    import gdown\n",
    "    from pathlib import Path\n",
    "\n",
    "    ckpt = Path('./checkpoints/pretrained/segformer')\n",
    "    ckpt.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n",
    "    output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n",
    "\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation\n",
    "#/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "# Custom Imports\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "LOCAL = not COLAB\n",
    "\n",
    "if COLAB:\n",
    "\n",
    "    # Clone visiope repo on runtime env\n",
    "    !git clone https://github.com/airoprojects/visiope.git /\n",
    "\n",
    "    # Install pytorchmetrics\n",
    "    !pip install torchmetrics\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = '/content/visiope'\n",
    "\n",
    "    # Add custom modules to path\n",
    "    custom_modules_path = root_dir + '/tools/'\n",
    "    sys.path.insert(0, custom_modules_path)\n",
    "\n",
    "elif LOCAL:\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "    \n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    # Add custom modules to path\n",
    "    custom_modules_path = root_dir  + '/tools/'\n",
    "    sys.path.insert(0, custom_modules_path)\n",
    "\n",
    "\n",
    "# Import Loader\n",
    "from data.utils import Ai4MarsDownload, Ai4MarsSplitter, Ai4MarsDataLoader\n",
    "\n",
    "# Import Loss\n",
    "from loss.loss import Ai4MarsCrossEntropy, Ai4MarsDiceLoss\n",
    "\n",
    "# Import Trainer\n",
    "from trainer.trainer import Ai4MarsTrainer\n",
    "\n",
    "# Import Tester\n",
    "from tester.tester import Ai4MarsTester\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1689164151824,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kwVFZJKgXULT"
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "if test:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nc):\n",
    "            self.nc = nc\n",
    "            super(Generator, self).__init__()\n",
    "\n",
    "\n",
    "        def forward(self, embeds):\n",
    "            ngf = 64\n",
    "            nz = [[None] *6]*4\n",
    "\n",
    "            j = 0\n",
    "            for embed in embeds:\n",
    "                nz[j][0] = embed.size()[1]\n",
    "                for i in range(1,6):\n",
    "                    if i < 4:\n",
    "                        nz[j][i] = nz[i-1]//2\n",
    "                    else:\n",
    "                        nz[j][i] = nz[i-1]//4\n",
    "                j = j+1\n",
    "                print(nz)\n",
    "            self.main = nn.Sequential(\n",
    "                #reduction of dimensionality To Be Changed in conv... maybe\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d( nz[6], ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, self.nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(nc) x 64 x 64``\n",
    "            )\n",
    "\n",
    "            return self.main(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1689164151825,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "1n9BBXOOn-Cl"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 64\n",
    "        nc = 1\n",
    "        print(nz)\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151827,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ZD2IYalLn-Co"
   },
   "outputs": [],
   "source": [
    "test1 = True\n",
    "if test1:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nz):\n",
    "            super(Generator, self).__init__()\n",
    "            ngf = 64\n",
    "            nc = 5\n",
    "            self.main = nn.Sequential()\n",
    "            self.main = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                #in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, ngf//2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf//2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf/2) x 64 x 64``\n",
    "                nn.ConvTranspose2d( ngf//2, nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(ngc) x 128 x 128``\n",
    "                # state size. ``(ngf/4) x 128 x 128``\n",
    "                #nn.BatchNorm2d(ngf),\n",
    "                #nn.ReLU(True),\n",
    "                #nn.ConvTranspose2d( ngf/4, nc, 4, 2, 1, bias=False),\n",
    "                #nn.Tanh()\n",
    "                # state size. ``(nc) x 256 x 256``\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151829,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "PyC-nI41XULT"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class SegFormerHead(nn.Module):\n",
    "    def __init__(self, dims: list, embed_dim: int = 256, num_classes: int = 19):\n",
    "        super().__init__()\n",
    "        for i, dim in enumerate(dims):\n",
    "            self.add_module(f\"linear_c{i+1}\", MLP(dim, embed_dim))\n",
    "\n",
    "        self.linear_fuse = ConvModule(embed_dim*4, embed_dim)\n",
    "        self.linear_pred = nn.Conv2d(embed_dim, num_classes, 1)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        B, _, H, W = features[0].shape\n",
    "        outs = [self.linear_c1(features[0]).permute(0, 2, 1).reshape(B, -1, *features[0].shape[-2:])]\n",
    "\n",
    "        for i, feature in enumerate(features[1:]):\n",
    "            cf = eval(f\"self.linear_c{i+2}\")(feature).permute(0, 2, 1).reshape(B, -1, *feature.shape[-2:])\n",
    "            outs.append(F.interpolate(cf, size=(H, W), mode='bilinear', align_corners=False))\n",
    "\n",
    "        seg = self.linear_fuse(torch.cat(outs[::-1], dim=1))\n",
    "        seg = self.linear_pred(self.dropout(seg))\n",
    "        return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1689164151831,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "MCJtu7Y_n-Cr"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, 1, -1)\n",
    "\n",
    "class FlattenFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, -1, 1, 1)\n",
    "\n",
    "class Conv2DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv1DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class downsample(nn.Module):\n",
    "    def __init__(self, C, H, W):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Sequential()\n",
    "        i = 0\n",
    "        alt = True\n",
    "        if H*W > 128:\n",
    "            while(C>4):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "\n",
    "        else:\n",
    "            while(C>16):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "        self.downsample.append(FlattenFinal())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.downsample(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1689164151833,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ipHImK80n-Ct"
   },
   "outputs": [],
   "source": [
    "class SegFormerHeadGen(nn.Module):\n",
    "\n",
    "    def __init__(self, num_img):\n",
    "      self.num_img = num_img\n",
    "      super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        downsamplers = []\n",
    "        for x in features:\n",
    "            downsamplers.append(downsample(x.shape[1],x.shape[2],x.shape[3]).to(device))\n",
    "        \n",
    "        latents = torch.empty(features[0].shape[0],1,1,1).to(device)\n",
    "        \n",
    "        for i, feature in enumerate(features):            \n",
    "            latents = torch.cat( (latents, downsamplers[i](feature), latents), 1)\n",
    "    \n",
    "        image = Generator(latents.shape[1]).to(device)(latents)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1689164151835,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "cZsudwlzXULU"
   },
   "outputs": [],
   "source": [
    "from semseg.models.base import BaseModel\n",
    "from semseg.models.heads import SegFormerHead\n",
    "#from resDecode import ResDecode\n",
    "\n",
    "\n",
    "class SegFormerpp(BaseModel):\n",
    "    def __init__(self, backbone: str = 'MiT-B0', num_classes: int = 19, head: str = 'B0', num_img: int = -1) -> None:\n",
    "        super().__init__(backbone, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.head = head\n",
    "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
    "        self.newDecode = SegFormerHeadGen(device)\n",
    "        self.newDecode.to(device)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        #y = self.decode(y)\n",
    "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        #embeds = []\n",
    "        y = self.newDecode(y)\n",
    "        '''\n",
    "        y = self.decode(y)\n",
    "        self.upsample = nn.Sequential(\n",
    "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
    "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),\n",
    "                                )\n",
    "        y = self.upsample(y).to(device)\n",
    "        '''\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semseg.models.base import BaseModel\n",
    "from semseg.models.heads import SegFormerHead\n",
    "#from resDecode import ResDecode\n",
    "\n",
    "\n",
    "class SegNetpp(BaseModel):\n",
    "    def __init__(self, backbone: str = 'ResNet', num_classes: int = 19, head: str = 'B0', num_img: int = -1) -> None:\n",
    "        super().__init__(backbone, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.head = head\n",
    "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
    "        self.newDecode = SegFormerHeadGen(num_img)\n",
    "        self.newDecode.to(device)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        #y = self.decode(y)\n",
    "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        #embeds = []\n",
    "        y = self.newDecode(y)\n",
    "        '''\n",
    "        y = self.decode(y)\n",
    "        self.upsample = nn.Sequential(\n",
    "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
    "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),\n",
    "                                )\n",
    "        y = self.upsample(y).to(device)\n",
    "        '''\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1689164378457,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "bglipAaW_xaY",
    "outputId": "3e943d2f-8865-402a-df70-ec5bc156817f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download a pretrained model's weights from the result table.\n",
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "from semseg.models import *\n",
    "#from segFormerpp import SegFormerpp\n",
    "\n",
    "model = eval('SegFormerpp')(\n",
    "    backbone='MiT-B2',\n",
    "    num_classes=5,\n",
    "    num_img = 0\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('checkpointcheckpoints/pretrained/segformer/segformer.b4.ade.pth'))\n",
    "except:\n",
    "    print(\"Download a pretrained model's weights from the result table.\")\n",
    "model.eval()\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28194,
     "status": "ok",
     "timestamp": 1689164179977,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "stv4_1XZXULW",
    "outputId": "ba951ed3-d81a-44e2-cae6-fecb989a9cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting parameters: \n",
      "             Dataset: ai4mars-dataset-merged-0.1 \n",
      "             Colab environment: False \n",
      "             Split percentages: [0.7, 0.2, 0.1] \n",
      "             Transformation: None \n",
      "             Svaving path: None \n",
      "             New image size: 128\n",
      "Extrapolation of random inices ...\n",
      "Splitting in progress ...\n",
      "Done \n",
      "\n",
      "Building Dataloaders\n",
      "Done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "# Set this to True if you wnat to load directly the dataloader\n",
    "# this can be done only on colab and it is useful to avoid runtime crash\n",
    "LOAD = True\n",
    "\n",
    "if LOAD:\n",
    "\n",
    "    if COLAB:\n",
    "\n",
    "        if not(os.path.exists('/content/dataset/')):\n",
    "\n",
    "            import gdown\n",
    "\n",
    "            # get url of torch dataset (temporarerly my drive)\n",
    "            drive = 'https://drive.google.com/uc?id='\n",
    "            url = 'https://drive.google.com/drive/folders/104YvO3LcU76euuVe-_62eS_Rld-tOZeh?usp=drive_link'\n",
    "\n",
    "            !gdown --folder {url} -O /content/\n",
    "\n",
    "            load_data = '/content/dataset/dataset.pt'\n",
    "\n",
    "    elif LOCAL: \n",
    "        load_data = root_dir + '/datasetup/dataset/dataset1000.pt'\n",
    "\n",
    "    X, y = torch.load(load_data)\n",
    "\n",
    "    # Build dataset\n",
    "    splitter = Ai4MarsSplitter()\n",
    "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1])\n",
    "\n",
    "    # Load dataset info\n",
    "    load_info = './.info.pt'\n",
    "    info = torch.load(load_info)\n",
    "\n",
    "    # Build Ai4MarsDataloader\n",
    "    loader = Ai4MarsDataLoader()\n",
    "    train_loader, test_loader, val_loader = loader(\n",
    "        [train_set, test_set, val_set], [64, 32, 32])\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    data_path = \"/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/\" #input(\"Path to Dataset: \")\n",
    "\n",
    "    # Insert here the number of images you want to download\n",
    "    num_images = 100 #int(input(\"Number of images (max 1000): \"))\n",
    "\n",
    "    save_path = None\n",
    "    # Uncomment the following line to the dataset on a local path\n",
    "    #save_path = root_dir + '/datasetup/dataset/'\n",
    "\n",
    "    if num_images > 1000 : raise Exception(\"Trying to import too many images\")\n",
    "\n",
    "    # Import data as Ai4MarsDataset\n",
    "    Ai4MarsDownload()(PATH=data_path)\n",
    "    importer = Ai4MarsImporter()\n",
    "    X, y, _ = importer(PATH=data_path, NUM_IMAGES=num_images, SAVE_PATH=save_path, SIZE=128)\n",
    "\n",
    "    transform = None\n",
    "    # Uncomment the following lines to apply transformations to the dataset\n",
    "    '''\n",
    "    transform = transforms.RandomChoice([\n",
    "     transforms.RandomRotation(90)])\n",
    "    '''\n",
    "\n",
    "    # Load info\n",
    "    load_info = './.info.pt'\n",
    "    info = torch.load(load_info)\n",
    "    \n",
    "    # Split the dataset\n",
    "    splitter = Ai4MarsSplitter()\n",
    "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1], transform=transform,\n",
    "                                            SAVE_PATH=save_path)\n",
    "\n",
    "    # Build Ai4MarsDataloader\n",
    "    loader = Ai4MarsDataLoader()\n",
    "    train_loader, test_loader, val_loader = loader([train_set, test_set, val_set], [32, 16, 16],\n",
    "                                                   SAVE_PATH=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1689164179981,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "O3ytN-ugjHcW",
    "outputId": "29fe6dcc-1983-4c1b-a1e5-eabff10ea398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  print(img.device)\\n  print(img.shape)\\n  if (img.device != 'cpu'):\\n    img.to('cpu')\\n    print('test')\\n  print(img.device)\\n  plt.imshow(img)\\n  plt.show()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show_image(imgs):\n",
    "    if len(imgs.size()) == 4:\n",
    "        for img in imgs:\n",
    "            imgs = imgs.permute(2,0,1)\n",
    "    else:\n",
    "        imgs = imgs.permute(2,0,1)\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "'''\n",
    "  print(img.device)\n",
    "  print(img.shape)\n",
    "  if (img.device != 'cpu'):\n",
    "    img.to('cpu')\n",
    "    print('test')\n",
    "  print(img.device)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1689164179986,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "3lU21D6nXULX"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer module for MER-Segmentation 2.0 \"\"\"\n",
    "test2 = False\n",
    "if test2:\n",
    "\n",
    "    import time\n",
    "    from datetime import datetime \n",
    "\n",
    "    # This class collects all the training functionalities to train different models\n",
    "    class Ai4MarsTrainer():\n",
    "\n",
    "        # Initialization of training parameters in the class constructor\n",
    "        def __init__(self, loss_fn, optimizer, train_loader, val_loader,\n",
    "                     transform=None, device='cpu', save_state=None):\n",
    "            self.loss_fn = loss_fn\n",
    "            self.optimizer = optimizer\n",
    "            self.train_loader = train_loader\n",
    "            self.val_loader = val_loader\n",
    "            self.device = device\n",
    "            self.save_state = save_state\n",
    "            self.transform = transform\n",
    "            self.loss_list = []\n",
    "            self.tloss_list = []\n",
    "\n",
    "        # This function implements training for just one epoch\n",
    "        def train_one_epoch(self, model, epoch_index=0):\n",
    "            running_loss = 0.\n",
    "            last_loss = 0.\n",
    "\n",
    "            # parameters for online data augmentation (batch transformation)\n",
    "            running_tloss = 0.\n",
    "            last_tloss = 0.\n",
    "            t_index = 0 \n",
    "\n",
    "            for batch_index, batch in enumerate(self.train_loader):\n",
    "                # Every data instance is an (input, label) pair\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Zero your gradients for every batch!\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Send inputs and labels to GPU (or whatever device is)\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Make predictions for this batch\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Adjust label to be 2D tensors of batch size\n",
    "                labels = labels.squeeze()\n",
    "                labels = labels.long()\n",
    "\n",
    "                # Compute the loss and its gradients\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                # Adjust learning weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # if transformation exists apply them to the batch\n",
    "                if self.transform:\n",
    "                    tinputs = self.transform(inputs)\n",
    "                    tinputs = tinputs.to(self.device)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    toutputs = model(tinputs)\n",
    "                    tloss = self.loss_fn(toutputs, labels)\n",
    "                    tloss.backward()\n",
    "                    running_tloss = tloss.item()\n",
    "                    t_index += 1\n",
    "                    tinputs.detach()\n",
    "                    del tinputs\n",
    "\n",
    "                # Free up RAM/VRAM\n",
    "                inputs.detach()\n",
    "                labels.detach()\n",
    "                del inputs\n",
    "                del labels\n",
    "\n",
    "            # Compute the average loss over all batches\n",
    "            last_loss =  running_loss / (batch_index + 1)\n",
    "\n",
    "            # Print report at the end of the last batch\n",
    "            print(f'Epoch {epoch_index+1}')\n",
    "            print(f'LOSS ON TRAIN: {last_loss}')\n",
    "\n",
    "            if self.transform:\n",
    "                last_tloss = running_tloss / (t_index + 1)\n",
    "                print(f'LOSS ON TRANSFORMED-TRAIN: {last_tloss}')\n",
    "\n",
    "            else:\n",
    "                last_tloss = None\n",
    "\n",
    "            return last_loss, last_tloss\n",
    "\n",
    "        # This function implements training for multiple epochs\n",
    "        def train_multiple_epoch(self, model, EPOCHS=100):\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            epoch_number = 0 # just a counter\n",
    "            best_vloss = 1_000_000.\n",
    "            self.loss_list = []\n",
    "            self.tloss_list = []\n",
    "\n",
    "            for epoch in range(EPOCHS):\n",
    "                # Make sure gradient tracking is on, and do a pass over the data\n",
    "                model.train(True)\n",
    "\n",
    "                # Start monitoring training time\n",
    "                start = time.time()\n",
    "\n",
    "                avg_loss = self.train_one_epoch(model, epoch)\n",
    "\n",
    "                end = time.time()\n",
    "\n",
    "                # We don't need gradients on to do reporting\n",
    "                model.train(False)\n",
    "\n",
    "                # Test loss\n",
    "                running_vloss = 0.0\n",
    "                for vbatch_index, vbatch in enumerate(self.val_loader):\n",
    "\n",
    "                    # Every data instance is a (input, label) pair\n",
    "                    vinputs, vlabels = vbatch\n",
    "\n",
    "                    # Send inputs and labels to GPU\n",
    "                    vinputs = vinputs.to(self.device)\n",
    "                    vlabels = vlabels.to(self.device)\n",
    "\n",
    "                    # Model prediction\n",
    "                    voutputs = model(vinputs)\n",
    "\n",
    "                    # Send inputs and labels to GPU (or whatever device is)\n",
    "                    vlabels = vlabels.squeeze()\n",
    "                    vlabels = vlabels.long()\n",
    "\n",
    "                    # Run validation loss\n",
    "                    val_loss = self.loss_fn(voutputs, vlabels)\n",
    "                    running_vloss += val_loss.item()\n",
    "\n",
    "                    # Free up RAM/VRAM\n",
    "                    vinputs.detach()\n",
    "                    vlabels.detach()\n",
    "                    del vinputs\n",
    "                    del vlabels\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                # Compute the average loss over all batches\n",
    "                avg_vloss = running_vloss / (vbatch_index + 1)\n",
    "\n",
    "                print(\"Time needed for training: \" + str(end-start)+ \" seconds\")\n",
    "\n",
    "                # Print report at the end of the epoch\n",
    "                print(f'LOSS ON VALIDATION: {avg_vloss}')\n",
    "\n",
    "                # Save loss in a list to then perform metrics evaluation\n",
    "                self.loss_list.append((avg_loss[0], end-start))\n",
    "\n",
    "                # If online data augmentation has been performed:\n",
    "                if avg_loss[1]:\n",
    "                    self.tloss_list.append((avg_loss[1], end-start))\n",
    "\n",
    "                # Track best performance, and save the model's state\n",
    "                if avg_vloss < best_vloss:\n",
    "                    best_vloss = avg_vloss\n",
    "                    model_path = self.save_state + 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test2:\n",
    "    from typing import Optional\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "\n",
    "    # based on:\n",
    "    # https://github.com/kevinzakka/pytorch-goodies/blob/master/losses.py\n",
    "\n",
    "    class DiceLoss(nn.Module):\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            super(DiceLoss, self).__init__()\n",
    "            self.eps: float = 1e-6\n",
    "\n",
    "        def forward(\n",
    "                self,\n",
    "                input: torch.Tensor,\n",
    "                target: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "\n",
    "            #errors:\n",
    "            if not torch.is_tensor(input):\n",
    "                raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                                .format(type(input)))\n",
    "            if not len(input.shape) == 4:\n",
    "                raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n",
    "                                 .format(input.shape))\n",
    "            if not input.shape[-2:] == target.shape[-2:]:\n",
    "                raise ValueError(\"input and target shapes must be the same. Got: {}\"\n",
    "                                 .format(input.shape, input.shape))\n",
    "            if not input.device == target.device:\n",
    "                raise ValueError(\n",
    "                    \"input and target must be in the same device. Got: {}\" .format(\n",
    "                        input.device, target.device))\n",
    "\n",
    "\n",
    "            num_classes = input.shape[1]\n",
    "\n",
    "            # compute softmax over the classes axis\n",
    "            input_soft = F.softmax(input, dim=1)\n",
    "\n",
    "            # print(\"shape\", input_soft.shape)\n",
    "\n",
    "            input_soft = input_soft.permute(0,2,1,3)\n",
    "            input_soft = input_soft.permute(0,1,3,2)\n",
    "\n",
    "            # create the labels one hot tensor\n",
    "            target_one_hot = F.one_hot(target, num_classes=input.shape[1])\n",
    "\n",
    "            # target_one_hot = target_one_hot.permute(0,1,3,2)\n",
    "            # target_one_hot = target_one_hot.permute(0,2,1,3)\n",
    "\n",
    "            # print(\"target_one_hot\",target_one_hot.shape)\n",
    "            # print(\"input_soft\",input_soft.shape)\n",
    "\n",
    "\n",
    "            # compute the actual dice score\n",
    "            dims = (1, 2, 3)\n",
    "            intersection = torch.sum(input_soft.reshape(-1) * target_one_hot.reshape(-1), -1)\n",
    "            cardinality = torch.sum(input_soft.reshape(-1) + target_one_hot.reshape(-1), -1)\n",
    "\n",
    "            dice_score = 2. * intersection / (cardinality + self.eps)\n",
    "\n",
    "            # if (self.stampa):\n",
    "            #   print(\"outputs\",input_soft)\n",
    "            #   print(\"labels\",target_one_hot)\n",
    "            #   print((1. - dice_score).item())\n",
    "\n",
    "\n",
    "\n",
    "            # print((1. - dice_score).shape)\n",
    "\n",
    "\n",
    "\n",
    "            return 1. - dice_score\n",
    "\n",
    "            #Alternative Universe\n",
    "\n",
    "            # labels = target_one_hot\n",
    "            # preds = input_soft\n",
    "\n",
    "            # tp = torch.sum(labels*preds, dim=(2, 3))\n",
    "            # fn = torch.sum(labels*(1-preds), dim=(2, 3))\n",
    "            # fp = torch.sum((1-labels)*preds, dim=(2, 3))\n",
    "\n",
    "\n",
    "            # delta = 0.5 # va messo come hyperparameter\n",
    "\n",
    "            # dice_score = (tp + 1e-6) / (tp + delta * fn + (1 - delta) * fp + 1e-6)\n",
    "            # dice_score = torch.sum(1 - dice_score, dim=-1)\n",
    "\n",
    "            # dice_score = dice_score / num_classes\n",
    "            # return dice_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def init_weights_xavier(m):\n",
    "\n",
    "    if type(m) == nn.Linear or type(m) == nn.ConvTranspose2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def init_weights_normal(m):\n",
    "\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    model.backbone.apply(init_weights_normal)\n",
    "    model.decode.apply(init_weights_xavier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVll-qRSXULY",
    "outputId": "e125181d-a822-4c69-f272-ea55ec43af18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Train loss: 0.8003262877464294\n",
      "Time needed for training: 34.80905556678772 seconds\n",
      "Validation loss: 0.7989651560783386 \n",
      "\n",
      "EPOCH 2\n",
      "Train loss: 0.8000654794953086\n",
      "Time needed for training: 32.36293983459473 seconds\n",
      "Validation loss: nan \n",
      "\n",
      "EPOCH 3\n",
      "Train loss: 0.7993070808323947\n",
      "Time needed for training: 33.10045266151428 seconds\n",
      "Validation loss: 0.7994084805250168 \n",
      "\n",
      "EPOCH 4\n",
      "Train loss: 0.7995981736616655\n",
      "Time needed for training: 33.0832257270813 seconds\n",
      "Validation loss: nan \n",
      "\n",
      "EPOCH 5\n",
      "Train loss: 0.800524581562389\n",
      "Time needed for training: 32.86004662513733 seconds\n",
      "Validation loss: 0.798665389418602 \n",
      "\n",
      "EPOCH 6\n",
      "Train loss: 0.8000861785628579\n",
      "Time needed for training: 32.58212113380432 seconds\n",
      "Validation loss: 0.8043806254863739 \n",
      "\n",
      "EPOCH 7\n",
      "Train loss: 0.7985266501253302\n",
      "Time needed for training: 32.81612491607666 seconds\n",
      "Validation loss: 0.805020347237587 \n",
      "\n",
      "EPOCH 8\n",
      "Train loss: 0.7990947094830599\n",
      "Time needed for training: 32.71581745147705 seconds\n",
      "Validation loss: 0.8034236431121826 \n",
      "\n",
      "EPOCH 9\n",
      "Train loss: 0.7999099493026733\n",
      "Time needed for training: 32.69322085380554 seconds\n",
      "Validation loss: 0.7980072647333145 \n",
      "\n",
      "EPOCH 10\n",
      "Train loss: 0.8000971403988925\n",
      "Time needed for training: 32.74015831947327 seconds\n",
      "Validation loss: 0.7960719764232635 \n",
      "\n",
      "EPOCH 11\n",
      "Train loss: 0.7979099208658392\n",
      "Time needed for training: 33.51514005661011 seconds\n",
      "Validation loss: 0.8020370006561279 \n",
      "\n",
      "EPOCH 12\n",
      "Train loss: 0.8001247915354642\n",
      "Time needed for training: 33.219170808792114 seconds\n",
      "Validation loss: 0.8047980219125748 \n",
      "\n",
      "EPOCH 13\n",
      "Train loss: 0.7999998168511824\n",
      "Time needed for training: 32.95850467681885 seconds\n",
      "Validation loss: 0.800253301858902 \n",
      "\n",
      "EPOCH 14\n",
      "Train loss: 0.7995387965982611\n",
      "Time needed for training: 32.73846960067749 seconds\n",
      "Validation loss: 0.7997070103883743 \n",
      "\n",
      "EPOCH 15\n",
      "Train loss: 0.7982894778251648\n",
      "Time needed for training: 32.995418548583984 seconds\n",
      "Validation loss: 0.7989921569824219 \n",
      "\n",
      "EPOCH 16\n",
      "Train loss: 0.8002324591983448\n",
      "Time needed for training: 33.04868149757385 seconds\n",
      "Validation loss: 0.8020833432674408 \n",
      "\n",
      "EPOCH 17\n",
      "Train loss: 0.7994150681929155\n",
      "Time needed for training: 32.73614168167114 seconds\n",
      "Validation loss: 0.7979907542467117 \n",
      "\n",
      "EPOCH 18\n",
      "Train loss: 0.8009405677968805\n",
      "Time needed for training: 33.279704093933105 seconds\n",
      "Validation loss: 0.8017270117998123 \n",
      "\n",
      "EPOCH 19\n",
      "Train loss: 0.7996132102879611\n",
      "Time needed for training: 32.836955070495605 seconds\n",
      "Validation loss: 0.8006551116704941 \n",
      "\n",
      "EPOCH 20\n",
      "Train loss: 0.8001791455528953\n",
      "Time needed for training: 33.06965756416321 seconds\n",
      "Validation loss: 0.799157127737999 \n",
      "\n",
      "EPOCH 21\n",
      "Train loss: 0.800603601065549\n",
      "Time needed for training: 32.98754596710205 seconds\n",
      "Validation loss: 0.8001896739006042 \n",
      "\n",
      "EPOCH 22\n",
      "Train loss: 0.8011978485367515\n",
      "Time needed for training: 32.943583726882935 seconds\n",
      "Validation loss: 0.79783795773983 \n",
      "\n",
      "EPOCH 23\n",
      "Train loss: 0.8005267110737887\n",
      "Time needed for training: 33.178356885910034 seconds\n",
      "Validation loss: 0.8036098629236221 \n",
      "\n",
      "EPOCH 24\n",
      "Train loss: 0.8002383221279491\n",
      "Time needed for training: 33.1928277015686 seconds\n",
      "Validation loss: 0.8006197363138199 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "                {'params': model.backbone.parameters(), 'lr': 5e-10},\n",
    "                {'params': model.decode.parameters(), 'lr': 1e-8}\n",
    "                ]\n",
    "                            ,amsgrad = True)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 5000)\n",
    "loss_fn_cross = Ai4MarsCrossEntropy().to(device)\n",
    "loss_fn_dice = Ai4MarsDiceLoss().to(device)\n",
    "\n",
    "\n",
    "trainer = Ai4MarsTrainer(loss_fn_dice, optimizer, train_loader, val_loader, lr_scheduler, device = device)\n",
    "model.to(device)\n",
    "trainer.train_multiple_epoch(model, EPOCHS = 1400)\n",
    "# Plot the histogram\n",
    "trainer.param_hist(model)\n",
    "trainer.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "error",
     "timestamp": 1689164347160,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "FZzOcvNXLK19",
    "outputId": "6d586d17-2309-43bf-e0a8-02c5aa9036d4"
   },
   "outputs": [],
   "source": [
    "from semseg.datasets import *\n",
    "\n",
    "#model = model.to(device)\n",
    "predictions = []\n",
    "start = time.time()\n",
    "#print('test')\n",
    "# Use torch.no_grad() to disable gradient computation during testing\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the desired device\n",
    "        #print(images.shape)\n",
    "        #images = images.permute(0,3,1,2).to(device)\n",
    "        #images = images.permute(2,0,1).to(device)\n",
    "        #images = images [None, :, :, :]\n",
    "        #print(images.shape)\n",
    "\n",
    "        #print(images.shape)\n",
    "        labels = labels.to(device)\n",
    "        images = images.to(device)\n",
    "        # Forward pass to get the predictions\n",
    "        with torch.inference_mode():\n",
    "          prediction = model(images)\n",
    "        #print(prediction)\n",
    "        prediction = prediction.softmax(1).argmax(1).to(int)\n",
    "        \n",
    "        #prediction = prediction.round().to(int)\n",
    "        #print(prediction.shape)\n",
    "        un = prediction.unique()\n",
    "        #print(un)\n",
    "        palette = eval('ADE20K').PALETTE.to(device)\n",
    "        prediction_map = palette[prediction].squeeze().to(torch.uint8)\n",
    "        #print(type(prediction_map))\n",
    "        #show_image(prediction_map)\n",
    "        predictions.append(prediction_map)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1689164347161,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "UKfyLsOXXBjx"
   },
   "outputs": [],
   "source": [
    "image, label = test_loader.dataset.__getitem__(10)\n",
    "\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "output = model(image)\n",
    "\n",
    "output = output.permute(0,2,1,3).permute(0,1,3,2)\n",
    "\n",
    "label = label.squeeze()\n",
    "label = label.long()\n",
    "\n",
    "print(loss_fn_dice(output, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(64, 324, 1, 1)\n",
    "x2 = torch.randn(64, 144, 1, 1)\n",
    "x3 = torch.randn(64, 1268, 1, 1)\n",
    "x4 = torch.randn(64, 8174, 1, 1)\n",
    "x0 = torch.empty(64,1,1,1)\n",
    "\n",
    "\n",
    "x0 = torch.cat((x0, x1 ,x0),1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

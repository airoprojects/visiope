{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3551,
     "status": "ok",
     "timestamp": 1689164151821,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kytW-DGR_xaS",
    "outputId": "e2d0b3eb-5cdd-45d6-af7e-00fb52eb82f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIN_COLAB = \\'google.colab\\' in sys.modules\\n\\nif not IN_COLAB:\\n    from git import Repo\\n\\n    # Initialize the Git repository object\\n    repo = Repo(\".\", search_parent_directories=True)\\n\\n    # Get the root directory of the Git project\\n    root_dir = repo.git.rev_parse(\"--show-toplevel\")\\n\\n    from pathlib import Path\\n\\n    # Set up path for custom importer modules\\n    # Data Loader\\n    importer_module = root_dir + \\'/dataloader/\\'\\n    print(importer_module)\\n    sys.path.insert(0, importer_module)\\n    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\\n\\n    # Loss\\n\\n    loss_module = root_dir + \\'/trainer/loss/\\'\\n    sys.path.insert(0, loss_module)\\n    import loss\\n\\n    # Trainer\\n    trainer_module = root_dir + \\'/trainer/\\'\\n    sys.path.insert(0, trainer_module)\\n    from trainer import Ai4MarsTrainer\\n\\n    # Insert here your local path to the dataset (temporary)\\n    data_path = input(\"Path to Dataset: \") #\\'/home/leeoos/Desktop/\\'\\n\\nelse: # IN_COLAB\\n\\n    from google.colab import drive\\n    drive.mount(\\'/content/drive\\')\\n\\n    # On Colab the path to the module ti fixed once you have\\n    # corretly set up the project with gitsetup.ipynb\\n\\n    # Import Loader\\n    fixed_path_loader = \\'/content/drive/MyDrive/Github/visiope/dataloader/\\'\\n    sys.path.insert(0, fixed_path_loader)\\n    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\\n\\n    # Import Trainer\\n    fixed_path_trainer = \\'/content/drive/MyDrive/Github/visiope/trainer/\\'\\n    sys.path.insert(0,fixed_path_trainer )\\n    from trainer import Ai4MarsTrainer\\n\\n    # Import Loss\\n    fixed_path_loss = \\'/content/drive/MyDrive/Github/visiope/trainer/loss/\\'\\n    sys.path.insert(0, fixed_path_loss)\\n    import loss\\n    \\n    !git clone https://github.com/sithu31296/semantic-segmentation\\n    %pip install -U gdown\\n    %pip install -e .\\n    %pip install einops\\n    import gdown\\n    from pathlib import Path\\n\\n    ckpt = Path(\\'./checkpoints/pretrained/segformer\\')\\n    ckpt.mkdir(exist_ok=True, parents=True)\\n\\n    url = \\'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT\\'\\n    output = \\'./checkpoints/pretrained/segformer/segformer.b3.ade.pth\\'\\n\\n    gdown.download(url, output, quiet=False)\\n\\ndevice = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n%cd semantic-segmentation\\n#/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import io\n",
    "from torchvision import transforms \n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import gc\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "'''\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Set up path for custom importer modules\n",
    "    # Data Loader\n",
    "    importer_module = root_dir + '/dataloader/'\n",
    "    print(importer_module)\n",
    "    sys.path.insert(0, importer_module)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Loss\n",
    "\n",
    "    loss_module = root_dir + '/trainer/loss/'\n",
    "    sys.path.insert(0, loss_module)\n",
    "    import loss\n",
    "\n",
    "    # Trainer\n",
    "    trainer_module = root_dir + '/trainer/'\n",
    "    sys.path.insert(0, trainer_module)\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    data_path = input(\"Path to Dataset: \") #'/home/leeoos/Desktop/'\n",
    "\n",
    "else: # IN_COLAB\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # On Colab the path to the module ti fixed once you have\n",
    "    # corretly set up the project with gitsetup.ipynb\n",
    "\n",
    "    # Import Loader\n",
    "    fixed_path_loader = '/content/drive/MyDrive/Github/visiope/dataloader/'\n",
    "    sys.path.insert(0, fixed_path_loader)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Import Trainer\n",
    "    fixed_path_trainer = '/content/drive/MyDrive/Github/visiope/trainer/'\n",
    "    sys.path.insert(0,fixed_path_trainer )\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Import Loss\n",
    "    fixed_path_loss = '/content/drive/MyDrive/Github/visiope/trainer/loss/'\n",
    "    sys.path.insert(0, fixed_path_loss)\n",
    "    import loss\n",
    "    \n",
    "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
    "    %pip install -U gdown\n",
    "    %pip install -e .\n",
    "    %pip install einops\n",
    "    import gdown\n",
    "    from pathlib import Path\n",
    "\n",
    "    ckpt = Path('./checkpoints/pretrained/segformer')\n",
    "    ckpt.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n",
    "    output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n",
    "\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation\n",
    "#/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "# Custom Imports\n",
    "\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "LOCAL = not COLAB\n",
    "\n",
    "if COLAB:\n",
    "\n",
    "    # Clone visiope repo on runtime env\n",
    "    !git clone https://github.com/airoprojects/visiope.git /\n",
    "\n",
    "    # Install pytorchmetrics\n",
    "    !pip install torchmetrics\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = '/content/visiope'\n",
    "\n",
    "    # Add custom modules to path\n",
    "    custom_modules_path = root_dir + '/tools/'\n",
    "    sys.path.insert(0, custom_modules_path)\n",
    "\n",
    "elif LOCAL:\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "    \n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    # Add custom modules to path\n",
    "    custom_modules_path = root_dir  + '/tools/'\n",
    "    sys.path.insert(0, custom_modules_path)\n",
    "\n",
    "\n",
    "# Import Loader\n",
    "from data.utils import Ai4MarsDownload, Ai4MarsSplitter, Ai4MarsDataLoader\n",
    "\n",
    "# Import Loss\n",
    "from loss.loss import Ai4MarsCrossEntropy, Ai4MarsDiceLoss\n",
    "\n",
    "# Import Trainer\n",
    "from trainer.trainer import Ai4MarsTrainer\n",
    "\n",
    "# Import Tester\n",
    "from tester.tester import Ai4MarsTester\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1689164151824,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kwVFZJKgXULT"
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "if test:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nc):\n",
    "            self.nc = nc\n",
    "            super(Generator, self).__init__()\n",
    "\n",
    "\n",
    "        def forward(self, embeds):\n",
    "            ngf = 64\n",
    "            nz = [[None] *6]*4\n",
    "\n",
    "            j = 0\n",
    "            for embed in embeds:\n",
    "                nz[j][0] = embed.size()[1]\n",
    "                for i in range(1,6):\n",
    "                    if i < 4:\n",
    "                        nz[j][i] = nz[i-1]//2\n",
    "                    else:\n",
    "                        nz[j][i] = nz[i-1]//4\n",
    "                j = j+1\n",
    "                print(nz)\n",
    "            self.main = nn.Sequential(\n",
    "                #reduction of dimensionality To Be Changed in conv... maybe\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d( nz[6], ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, self.nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(nc) x 64 x 64``\n",
    "            )\n",
    "\n",
    "            return self.main(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1689164151825,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "1n9BBXOOn-Cl"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 64\n",
    "        nc = 1\n",
    "        print(nz)\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151827,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ZD2IYalLn-Co"
   },
   "outputs": [],
   "source": [
    "test1 = True\n",
    "if test1:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nz):\n",
    "            super(Generator, self).__init__()\n",
    "            ngf = 64\n",
    "            nc = 5\n",
    "            self.main = nn.Sequential()\n",
    "            self.main = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                #in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, ngf//2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf//2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf/2) x 64 x 64``\n",
    "                nn.ConvTranspose2d( ngf//2, nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(ngc) x 128 x 128``\n",
    "                # state size. ``(ngf/4) x 128 x 128``\n",
    "                #nn.BatchNorm2d(ngf),\n",
    "                #nn.ReLU(True),\n",
    "                #nn.ConvTranspose2d( ngf/4, nc, 4, 2, 1, bias=False),\n",
    "                #nn.Tanh()\n",
    "                # state size. ``(nc) x 256 x 256``\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151829,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "PyC-nI41XULT"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class SegFormerHead(nn.Module):\n",
    "    def __init__(self, dims: list, embed_dim: int = 256, num_classes: int = 19):\n",
    "        super().__init__()\n",
    "        for i, dim in enumerate(dims):\n",
    "            self.add_module(f\"linear_c{i+1}\", MLP(dim, embed_dim))\n",
    "\n",
    "        self.linear_fuse = ConvModule(embed_dim*4, embed_dim)\n",
    "        self.linear_pred = nn.Conv2d(embed_dim, num_classes, 1)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        B, _, H, W = features[0].shape\n",
    "        outs = [self.linear_c1(features[0]).permute(0, 2, 1).reshape(B, -1, *features[0].shape[-2:])]\n",
    "\n",
    "        for i, feature in enumerate(features[1:]):\n",
    "            cf = eval(f\"self.linear_c{i+2}\")(feature).permute(0, 2, 1).reshape(B, -1, *feature.shape[-2:])\n",
    "            outs.append(F.interpolate(cf, size=(H, W), mode='bilinear', align_corners=False))\n",
    "\n",
    "        seg = self.linear_fuse(torch.cat(outs[::-1], dim=1))\n",
    "        seg = self.linear_pred(self.dropout(seg))\n",
    "        return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1689164151831,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "MCJtu7Y_n-Cr"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, 1, -1)\n",
    "\n",
    "class FlattenFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, -1, 1, 1)\n",
    "\n",
    "class Conv2DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv1DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class downsample(nn.Module):\n",
    "    def __init__(self, C, H, W):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Sequential()\n",
    "        i = 0\n",
    "        alt = True\n",
    "        if H*W > 128:\n",
    "            while(C>4):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "\n",
    "        else:\n",
    "            while(C>16):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "        self.downsample.append(FlattenFinal())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.downsample(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1689164151833,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ipHImK80n-Ct"
   },
   "outputs": [],
   "source": [
    "class SegFormerHeadGen(nn.Module):\n",
    "\n",
    "    def __init__(self, num_img):\n",
    "      self.num_img = num_img\n",
    "      super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "      x = features[self.num_img]\n",
    "      downsampler = downsample(x.shape[1],x.shape[2],x.shape[3]).to(device)\n",
    "\n",
    "\n",
    "      downsampler(x).size()\n",
    "      self.G = Generator(downsampler(x).size()[1]).to(device)\n",
    "      image = self.G(downsampler(x))\n",
    "\n",
    "\n",
    "      return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1689164151835,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "cZsudwlzXULU"
   },
   "outputs": [],
   "source": [
    "from semseg.models.base import BaseModel\n",
    "from semseg.models.heads import SegFormerHead\n",
    "#from resDecode import ResDecode\n",
    "\n",
    "\n",
    "class SegFormerpp(BaseModel):\n",
    "    def __init__(self, backbone: str = 'MiT-B0', num_classes: int = 19, head: str = 'B0', num_img: int = -1) -> None:\n",
    "        super().__init__(backbone, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.head = head\n",
    "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
    "        self.newDecode = SegFormerHeadGen(num_img)\n",
    "        self.newDecode.to(device)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        #y = self.decode(y)\n",
    "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        #embeds = []\n",
    "        y = self.newDecode(y)\n",
    "        '''\n",
    "        y = self.decode(y)\n",
    "        self.upsample = nn.Sequential(\n",
    "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
    "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),\n",
    "                                )\n",
    "        y = self.upsample(y).to(device)\n",
    "        '''\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1689164378457,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "bglipAaW_xaY",
    "outputId": "3e943d2f-8865-402a-df70-ec5bc156817f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download a pretrained model's weights from the result table.\n",
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "from semseg.models import *\n",
    "#from segFormerpp import SegFormerpp\n",
    "\n",
    "model = eval('SegFormerpp')(\n",
    "    backbone='MiT-B4',\n",
    "    num_classes=5,\n",
    "    num_img = 0\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('checkpointcheckpoints/pretrained/segformer/segformer.b4.ade.pth'))\n",
    "except:\n",
    "    print(\"Download a pretrained model's weights from the result table.\")\n",
    "model.eval()\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28194,
     "status": "ok",
     "timestamp": 1689164179977,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "stv4_1XZXULW",
    "outputId": "ba951ed3-d81a-44e2-cae6-fecb989a9cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This are the Class parameters: \n",
      "               Dataset: ai4mars-dataset-merged-0.1 \n",
      "               Path to the dataset: /home/paolo/Downloads/magistrale/1 anno/visiope/visiope/ \n",
      "               Colab Environment: False \n",
      "               Number of images to load: 500 \n",
      "               Saving path for X and y: None\n",
      "You already have ai4mars-dataset-merged-0.1\n",
      "Unpacking images and lables from: ai4mars-dataset-merged-0.1 ...\n",
      "Inputs len: 500\n",
      "Labels len: 500\n",
      "Converting inputs and labels into torch tensors ...\n",
      "Done\n",
      "\n",
      "Begin processing: \n",
      "             Dataset: ai4mars-dataset-merged-0.1 \n",
      "             Colab environment: False \n",
      "             Split percentages: [0.7, 0.2, 0.1] \n",
      "             Transformation: None\n",
      "Splitting in progress ...\n",
      "Resizing the ai4mars-dataset-merged-0.1 images at size: 128 ...\n",
      "Done \n",
      "\n",
      "Building Dataloaders\n",
      "Done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "# Set this to True if you wnat to load directly the dataloader \n",
    "# this can be done only on colab and it is useful to avoid runtime crash\n",
    "LOAD = False\n",
    "\n",
    "if LOAD:\n",
    "\n",
    "    if COLAB:\n",
    "\n",
    "        if not(os.path.exists('/content/dataset/')):\n",
    "\n",
    "            import gdown\n",
    "\n",
    "            # get url of torch dataset (temporarerly my drive)\n",
    "            drive = 'https://drive.google.com/uc?id='\n",
    "            url = 'https://drive.google.com/drive/folders/104YvO3LcU76euuVe-_62eS_Rld-tOZeh?usp=drive_link'\n",
    "\n",
    "            !gdown --folder {url} -O /content/\n",
    "\n",
    "            load_path = '/content/dataset/dataset.pt'\n",
    "\n",
    "    elif LOCAL: load_path = root_dir + '/datasetup/dataset/dataset.pt'\n",
    "\n",
    "    dataset = torch.load(load_path)\n",
    "    train_set = dataset[0]\n",
    "    test_set = dataset[1]\n",
    "    val_set = dataset[2]\n",
    "\n",
    "    # Build Ai4MarsDataloader\n",
    "    loader = Ai4MarsDataLoader()\n",
    "    train_loader, test_loader, val_loader = loader(\n",
    "        [train_set, test_set, val_set], [32, 16, 16])\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary on airodrive)\n",
    "    #raise Exception('Remove this line and inset the path to the dataset below')\n",
    "    data_path = \"/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/\"\n",
    "\n",
    "    save_path = None\n",
    "    # Uncomment the following line to the dataset on a local path\n",
    "    #save_path = root_dir + '/datasetup/dataset/'\n",
    "\n",
    "    # Import data as Ai4MarsDataset\n",
    "    importer = Ai4MarsDownload()\n",
    "    X, y = importer(PATH=data_path, NUM_IMAGES=500)\n",
    "\n",
    "    transform = None\n",
    "    # Uncomment the following lines to apply transformations to the dataset\n",
    "    '''\n",
    "    transform = transforms.RandomChoice([\n",
    "     transforms.RandomRotation(90)])\n",
    "    '''\n",
    "\n",
    "    # Split the dataset\n",
    "    splitter = Ai4MarsSplitter()\n",
    "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1], transform=transform, SAVE_PATH=save_path, SIZE=128)\n",
    "\n",
    "    # Build Ai4MarsDataloader\n",
    "    loader = Ai4MarsDataLoader()\n",
    "    train_loader, test_loader, val_loader = loader([train_set, test_set, val_set], [32, 16, 16], SIZE=128, SAVE_PATH=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1689164179981,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "O3ytN-ugjHcW",
    "outputId": "29fe6dcc-1983-4c1b-a1e5-eabff10ea398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  print(img.device)\\n  print(img.shape)\\n  if (img.device != 'cpu'):\\n    img.to('cpu')\\n    print('test')\\n  print(img.device)\\n  plt.imshow(img)\\n  plt.show()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show_image(imgs):\n",
    "    if len(imgs.size()) == 4:\n",
    "        for img in imgs:\n",
    "            imgs = imgs.permute(2,0,1)\n",
    "    else:\n",
    "        imgs = imgs.permute(2,0,1)\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "'''\n",
    "  print(img.device)\n",
    "  print(img.shape)\n",
    "  if (img.device != 'cpu'):\n",
    "    img.to('cpu')\n",
    "    print('test')\n",
    "  print(img.device)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1689164179986,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "3lU21D6nXULX"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer module for MER-Segmentation 2.0 \"\"\"\n",
    "test2 = False\n",
    "if test2:\n",
    "\n",
    "    import time\n",
    "    from datetime import datetime \n",
    "\n",
    "    # This class collects all the training functionalities to train different models\n",
    "    class Ai4MarsTrainer():\n",
    "\n",
    "        # Initialization of training parameters in the class constructor\n",
    "        def __init__(self, loss_fn, optimizer, train_loader, val_loader,\n",
    "                     transform=None, device='cpu', save_state=None):\n",
    "            self.loss_fn = loss_fn\n",
    "            self.optimizer = optimizer\n",
    "            self.train_loader = train_loader\n",
    "            self.val_loader = val_loader\n",
    "            self.device = device\n",
    "            self.save_state = save_state\n",
    "            self.transform = transform\n",
    "            self.loss_list = []\n",
    "            self.tloss_list = []\n",
    "\n",
    "        # This function implements training for just one epoch\n",
    "        def train_one_epoch(self, model, epoch_index=0):\n",
    "            running_loss = 0.\n",
    "            last_loss = 0.\n",
    "\n",
    "            # parameters for online data augmentation (batch transformation)\n",
    "            running_tloss = 0.\n",
    "            last_tloss = 0.\n",
    "            t_index = 0 \n",
    "\n",
    "            for batch_index, batch in enumerate(self.train_loader):\n",
    "                # Every data instance is an (input, label) pair\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Zero your gradients for every batch!\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Send inputs and labels to GPU (or whatever device is)\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                # Make predictions for this batch\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Adjust label to be 2D tensors of batch size\n",
    "                labels = labels.squeeze()\n",
    "                labels = labels.long()\n",
    "\n",
    "                # Compute the loss and its gradients\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                # Adjust learning weights\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # if transformation exists apply them to the batch\n",
    "                if self.transform:\n",
    "                    tinputs = self.transform(inputs)\n",
    "                    tinputs = tinputs.to(self.device)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    toutputs = model(tinputs)\n",
    "                    tloss = self.loss_fn(toutputs, labels)\n",
    "                    tloss.backward()\n",
    "                    running_tloss = tloss.item()\n",
    "                    t_index += 1\n",
    "                    tinputs.detach()\n",
    "                    del tinputs\n",
    "\n",
    "                # Free up RAM/VRAM\n",
    "                inputs.detach()\n",
    "                labels.detach()\n",
    "                del inputs\n",
    "                del labels\n",
    "\n",
    "            # Compute the average loss over all batches\n",
    "            last_loss =  running_loss / (batch_index + 1)\n",
    "\n",
    "            # Print report at the end of the last batch\n",
    "            print(f'Epoch {epoch_index+1}')\n",
    "            print(f'LOSS ON TRAIN: {last_loss}')\n",
    "\n",
    "            if self.transform:\n",
    "                last_tloss = running_tloss / (t_index + 1)\n",
    "                print(f'LOSS ON TRANSFORMED-TRAIN: {last_tloss}')\n",
    "\n",
    "            else:\n",
    "                last_tloss = None\n",
    "\n",
    "            return last_loss, last_tloss\n",
    "\n",
    "        # This function implements training for multiple epochs\n",
    "        def train_multiple_epoch(self, model, EPOCHS=100):\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            epoch_number = 0 # just a counter\n",
    "            best_vloss = 1_000_000.\n",
    "            self.loss_list = []\n",
    "            self.tloss_list = []\n",
    "\n",
    "            for epoch in range(EPOCHS):\n",
    "                # Make sure gradient tracking is on, and do a pass over the data\n",
    "                model.train(True)\n",
    "\n",
    "                # Start monitoring training time\n",
    "                start = time.time()\n",
    "\n",
    "                avg_loss = self.train_one_epoch(model, epoch)\n",
    "\n",
    "                end = time.time()\n",
    "\n",
    "                # We don't need gradients on to do reporting\n",
    "                model.train(False)\n",
    "\n",
    "                # Test loss\n",
    "                running_vloss = 0.0\n",
    "                for vbatch_index, vbatch in enumerate(self.val_loader):\n",
    "\n",
    "                    # Every data instance is a (input, label) pair\n",
    "                    vinputs, vlabels = vbatch\n",
    "\n",
    "                    # Send inputs and labels to GPU\n",
    "                    vinputs = vinputs.to(self.device)\n",
    "                    vlabels = vlabels.to(self.device)\n",
    "\n",
    "                    # Model prediction\n",
    "                    voutputs = model(vinputs)\n",
    "\n",
    "                    # Send inputs and labels to GPU (or whatever device is)\n",
    "                    vlabels = vlabels.squeeze()\n",
    "                    vlabels = vlabels.long()\n",
    "\n",
    "                    # Run validation loss\n",
    "                    val_loss = self.loss_fn(voutputs, vlabels)\n",
    "                    running_vloss += val_loss.item()\n",
    "\n",
    "                    # Free up RAM/VRAM\n",
    "                    vinputs.detach()\n",
    "                    vlabels.detach()\n",
    "                    del vinputs\n",
    "                    del vlabels\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                # Compute the average loss over all batches\n",
    "                avg_vloss = running_vloss / (vbatch_index + 1)\n",
    "\n",
    "                print(\"Time needed for training: \" + str(end-start)+ \" seconds\")\n",
    "\n",
    "                # Print report at the end of the epoch\n",
    "                print(f'LOSS ON VALIDATION: {avg_vloss}')\n",
    "\n",
    "                # Save loss in a list to then perform metrics evaluation\n",
    "                self.loss_list.append((avg_loss[0], end-start))\n",
    "\n",
    "                # If online data augmentation has been performed:\n",
    "                if avg_loss[1]:\n",
    "                    self.tloss_list.append((avg_loss[1], end-start))\n",
    "\n",
    "                # Track best performance, and save the model's state\n",
    "                if avg_vloss < best_vloss:\n",
    "                    best_vloss = avg_vloss\n",
    "                    model_path = self.save_state + 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test2:\n",
    "    from typing import Optional\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "\n",
    "    # based on:\n",
    "    # https://github.com/kevinzakka/pytorch-goodies/blob/master/losses.py\n",
    "\n",
    "    class DiceLoss(nn.Module):\n",
    "\n",
    "        def __init__(self) -> None:\n",
    "            super(DiceLoss, self).__init__()\n",
    "            self.eps: float = 1e-6\n",
    "\n",
    "        def forward(\n",
    "                self,\n",
    "                input: torch.Tensor,\n",
    "                target: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "\n",
    "            #errors:\n",
    "            if not torch.is_tensor(input):\n",
    "                raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                                .format(type(input)))\n",
    "            if not len(input.shape) == 4:\n",
    "                raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n",
    "                                 .format(input.shape))\n",
    "            if not input.shape[-2:] == target.shape[-2:]:\n",
    "                raise ValueError(\"input and target shapes must be the same. Got: {}\"\n",
    "                                 .format(input.shape, input.shape))\n",
    "            if not input.device == target.device:\n",
    "                raise ValueError(\n",
    "                    \"input and target must be in the same device. Got: {}\" .format(\n",
    "                        input.device, target.device))\n",
    "\n",
    "\n",
    "            num_classes = input.shape[1]\n",
    "\n",
    "            # compute softmax over the classes axis\n",
    "            input_soft = F.softmax(input, dim=1)\n",
    "\n",
    "            # print(\"shape\", input_soft.shape)\n",
    "\n",
    "            input_soft = input_soft.permute(0,2,1,3)\n",
    "            input_soft = input_soft.permute(0,1,3,2)\n",
    "\n",
    "            # create the labels one hot tensor\n",
    "            target_one_hot = F.one_hot(target, num_classes=input.shape[1])\n",
    "\n",
    "            # target_one_hot = target_one_hot.permute(0,1,3,2)\n",
    "            # target_one_hot = target_one_hot.permute(0,2,1,3)\n",
    "\n",
    "            # print(\"target_one_hot\",target_one_hot.shape)\n",
    "            # print(\"input_soft\",input_soft.shape)\n",
    "\n",
    "\n",
    "            # compute the actual dice score\n",
    "            dims = (1, 2, 3)\n",
    "            intersection = torch.sum(input_soft.reshape(-1) * target_one_hot.reshape(-1), -1)\n",
    "            cardinality = torch.sum(input_soft.reshape(-1) + target_one_hot.reshape(-1), -1)\n",
    "\n",
    "            dice_score = 2. * intersection / (cardinality + self.eps)\n",
    "\n",
    "            # if (self.stampa):\n",
    "            #   print(\"outputs\",input_soft)\n",
    "            #   print(\"labels\",target_one_hot)\n",
    "            #   print((1. - dice_score).item())\n",
    "\n",
    "\n",
    "\n",
    "            # print((1. - dice_score).shape)\n",
    "\n",
    "\n",
    "\n",
    "            return 1. - dice_score\n",
    "\n",
    "            #Alternative Universe\n",
    "\n",
    "            # labels = target_one_hot\n",
    "            # preds = input_soft\n",
    "\n",
    "            # tp = torch.sum(labels*preds, dim=(2, 3))\n",
    "            # fn = torch.sum(labels*(1-preds), dim=(2, 3))\n",
    "            # fp = torch.sum((1-labels)*preds, dim=(2, 3))\n",
    "\n",
    "\n",
    "            # delta = 0.5 # va messo come hyperparameter\n",
    "\n",
    "            # dice_score = (tp + 1e-6) / (tp + delta * fn + (1 - delta) * fp + 1e-6)\n",
    "            # dice_score = torch.sum(1 - dice_score, dim=-1)\n",
    "\n",
    "            # dice_score = dice_score / num_classes\n",
    "            # return dice_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVll-qRSXULY",
    "outputId": "e125181d-a822-4c69-f272-ea55ec43af18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Train loss: 0.7988098859786987\n",
      "Time needed for training: 7.309244632720947 seconds\n",
      "Validation loss: 0.7976264208555222 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Ai4MarsTrainer(loss_fn_dice, optimizer, train_loader, val_loader, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_multiple_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Plot the histogram\u001b[39;00m\n\u001b[1;32m     14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mparam_hist(model)\n",
      "File \u001b[0;32m~/Downloads/magistrale/1 anno/visiope/visiope/tools/trainer/trainer.py:143\u001b[0m, in \u001b[0;36mAi4MarsTrainer.train_multiple_epoch\u001b[0;34m(self, model, EPOCHS, SAVE_PATH)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Start monitoring training time\u001b[39;00m\n\u001b[1;32m    141\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 143\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# End of monitoring time\u001b[39;00m\n\u001b[1;32m    146\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Downloads/magistrale/1 anno/visiope/visiope/tools/trainer/trainer.py:65\u001b[0m, in \u001b[0;36mAi4MarsTrainer.train_one_epoch\u001b[0;34m(self, model, epoch_index)\u001b[0m\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(outputs, labels)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Compute loss gradient\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Adjust learning weights\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam([\n",
    "                {'params': model.backbone.parameters(), 'lr': 1e1},\n",
    "                {'params': model.decode.parameters(), 'lr': 1e-5}\n",
    "                ]\n",
    "                            ,amsgrad = False)\n",
    "loss_fn_cross = Ai4MarsCrossEntropy().to(device)\n",
    "loss_fn_dice = Ai4MarsDiceLoss().to(device)\n",
    "\n",
    "\n",
    "trainer = Ai4MarsTrainer(loss_fn_dice, optimizer, train_loader, val_loader, device = device)\n",
    "model.to(device)\n",
    "trainer.train_multiple_epoch(model, EPOCHS = 300)\n",
    "# Plot the histogram\n",
    "trainer.param_hist(model)\n",
    "trainer.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "error",
     "timestamp": 1689164347160,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "FZzOcvNXLK19",
    "outputId": "6d586d17-2309-43bf-e0a8-02c5aa9036d4"
   },
   "outputs": [],
   "source": [
    "from semseg.datasets import *\n",
    "\n",
    "#model = model.to(device)\n",
    "predictions = []\n",
    "start = time.time()\n",
    "#print('test')\n",
    "# Use torch.no_grad() to disable gradient computation during testing\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the desired device\n",
    "        #print(images.shape)\n",
    "        #images = images.permute(0,3,1,2).to(device)\n",
    "        #images = images.permute(2,0,1).to(device)\n",
    "        #images = images [None, :, :, :]\n",
    "        #print(images.shape)\n",
    "\n",
    "        #print(images.shape)\n",
    "        labels = labels.to(device)\n",
    "        images = images.to(device)\n",
    "        # Forward pass to get the predictions\n",
    "        with torch.inference_mode():\n",
    "          prediction = model(images)\n",
    "        #print(prediction)\n",
    "        prediction = prediction.softmax(1).argmax(1).to(int)\n",
    "        \n",
    "        #prediction = prediction.round().to(int)\n",
    "        #print(prediction.shape)\n",
    "        un = prediction.unique()\n",
    "        #print(un)\n",
    "        palette = eval('ADE20K').PALETTE.to(device)\n",
    "        prediction_map = palette[prediction].squeeze().to(torch.uint8)\n",
    "        #print(type(prediction_map))\n",
    "        #show_image(prediction_map)\n",
    "        predictions.append(prediction_map)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1689164347161,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "UKfyLsOXXBjx"
   },
   "outputs": [],
   "source": [
    "image, label = test_loader.dataset.__getitem__(10)\n",
    "\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "image = image.to(device)\n",
    "label = label.to(device)\n",
    "output = model(image)\n",
    "\n",
    "output = output.permute(0,2,1,3).permute(0,1,3,2)\n",
    "\n",
    "label = label.squeeze()\n",
    "label = label.long()\n",
    "\n",
    "print(loss_fn_dice(output, label))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

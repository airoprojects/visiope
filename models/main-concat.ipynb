{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3551,
     "status": "ok",
     "timestamp": 1689164151821,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kytW-DGR_xaS",
    "outputId": "e2d0b3eb-5cdd-45d6-af7e-00fb52eb82f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIN_COLAB = \\'google.colab\\' in sys.modules\\n\\nif not IN_COLAB:\\n    from git import Repo\\n\\n    # Initialize the Git repository object\\n    repo = Repo(\".\", search_parent_directories=True)\\n\\n    # Get the root directory of the Git project\\n    root_dir = repo.git.rev_parse(\"--show-toplevel\")\\n\\n    from pathlib import Path\\n\\n    # Set up path for custom importer modules\\n    # Data Loader\\n    importer_module = root_dir + \\'/dataloader/\\'\\n    print(importer_module)\\n    sys.path.insert(0, importer_module)\\n    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\\n\\n    # Loss\\n\\n    loss_module = root_dir + \\'/trainer/loss/\\'\\n    sys.path.insert(0, loss_module)\\n    import loss\\n\\n    # Trainer\\n    trainer_module = root_dir + \\'/trainer/\\'\\n    sys.path.insert(0, trainer_module)\\n    from trainer import Ai4MarsTrainer\\n\\n    # Insert here your local path to the dataset (temporary)\\n    data_path = input(\"Path to Dataset: \") #\\'/home/leeoos/Desktop/\\'\\n\\nelse: # IN_COLAB\\n\\n    from google.colab import drive\\n    drive.mount(\\'/content/drive\\')\\n\\n    # On Colab the path to the module ti fixed once you have\\n    # corretly set up the project with gitsetup.ipynb\\n\\n    # Import Loader\\n    fixed_path_loader = \\'/content/drive/MyDrive/Github/visiope/dataloader/\\'\\n    sys.path.insert(0, fixed_path_loader)\\n    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\\n\\n    # Import Trainer\\n    fixed_path_trainer = \\'/content/drive/MyDrive/Github/visiope/trainer/\\'\\n    sys.path.insert(0,fixed_path_trainer )\\n    from trainer import Ai4MarsTrainer\\n\\n    # Import Loss\\n    fixed_path_loss = \\'/content/drive/MyDrive/Github/visiope/trainer/loss/\\'\\n    sys.path.insert(0, fixed_path_loss)\\n    import loss\\n    \\n    !git clone https://github.com/sithu31296/semantic-segmentation\\n    %pip install -U gdown\\n    %pip install -e .\\n    %pip install einops\\n    import gdown\\n    from pathlib import Path\\n\\n    ckpt = Path(\\'./checkpoints/pretrained/segformer\\')\\n    ckpt.mkdir(exist_ok=True, parents=True)\\n\\n    url = \\'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT\\'\\n    output = \\'./checkpoints/pretrained/segformer/segformer.b3.ade.pth\\'\\n\\n    gdown.download(url, output, quiet=False)\\n\\ndevice = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n%cd semantic-segmentation\\n#/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import io\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import gc\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "'''\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if not IN_COLAB:\n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Set up path for custom importer modules\n",
    "    # Data Loader\n",
    "    importer_module = root_dir + '/dataloader/'\n",
    "    print(importer_module)\n",
    "    sys.path.insert(0, importer_module)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Loss\n",
    "\n",
    "    loss_module = root_dir + '/trainer/loss/'\n",
    "    sys.path.insert(0, loss_module)\n",
    "    import loss\n",
    "\n",
    "    # Trainer\n",
    "    trainer_module = root_dir + '/trainer/'\n",
    "    sys.path.insert(0, trainer_module)\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    data_path = input(\"Path to Dataset: \") #'/home/leeoos/Desktop/'\n",
    "\n",
    "else: # IN_COLAB\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # On Colab the path to the module ti fixed once you have\n",
    "    # corretly set up the project with gitsetup.ipynb\n",
    "\n",
    "    # Import Loader\n",
    "    fixed_path_loader = '/content/drive/MyDrive/Github/visiope/dataloader/'\n",
    "    sys.path.insert(0, fixed_path_loader)\n",
    "    from loader import Ai4MarsImporter, Ai4MarsProcessor, Ai4MarsData\n",
    "\n",
    "    # Import Trainer\n",
    "    fixed_path_trainer = '/content/drive/MyDrive/Github/visiope/trainer/'\n",
    "    sys.path.insert(0,fixed_path_trainer )\n",
    "    from trainer import Ai4MarsTrainer\n",
    "\n",
    "    # Import Loss\n",
    "    fixed_path_loss = '/content/drive/MyDrive/Github/visiope/trainer/loss/'\n",
    "    sys.path.insert(0, fixed_path_loss)\n",
    "    import loss\n",
    "    \n",
    "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
    "    %pip install -U gdown\n",
    "    %pip install -e .\n",
    "    %pip install einops\n",
    "    import gdown\n",
    "    from pathlib import Path\n",
    "\n",
    "    ckpt = Path('./checkpoints/pretrained/segformer')\n",
    "    ckpt.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n",
    "    output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n",
    "\n",
    "    gdown.download(url, output, quiet=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation\n",
    "#/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "# Custom Imports\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "LOCAL = not IN_COLAB\n",
    "\n",
    "if IN_COLAB:\n",
    "\n",
    "    # Clone visiope repo on runtime env\n",
    "    !git clone https://github.com/airoprojects/visiope.git /content/visiope/\n",
    "\n",
    "    # Add custom modules to path\n",
    "    custom_modules_path = '/content/visiope/tools/'\n",
    "    sys.path.insert(0, custom_modules_path)\n",
    "\n",
    "elif LOCAL:\n",
    "    \n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "    \n",
    "    from git import Repo\n",
    "\n",
    "    # Initialize the Git repository object\n",
    "    repo = Repo(\".\", search_parent_directories=True)\n",
    "\n",
    "    # Get the root directory of the Git project\n",
    "    root_dir = repo.git.rev_parse(\"--show-toplevel\")\n",
    "\n",
    "    # Add custom modules to path\n",
    "    custom_modules_path = root_dir  + '/tools/'\n",
    "    sys.path.insert(0, custom_modules_path)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Unknown Environment\")\n",
    "\n",
    "\n",
    "# Import Loader\n",
    "from data.utils import Ai4MarsDownload, Ai4MarsSplitter, Ai4MarsDataloader\n",
    "\n",
    "# Import Loss\n",
    "import loss.loss\n",
    "\n",
    "# Import Trainer\n",
    "import trainer.trainer\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1689164151824,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "kwVFZJKgXULT"
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "if test:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nc):\n",
    "            self.nc = nc\n",
    "            super(Generator, self).__init__()\n",
    "\n",
    "\n",
    "        def forward(self, embeds):\n",
    "            ngf = 64\n",
    "            nz = [[None] *6]*4\n",
    "\n",
    "            j = 0\n",
    "            for embed in embeds:\n",
    "                nz[j][0] = embed.size()[1]\n",
    "                for i in range(1,6):\n",
    "                    if i < 4:\n",
    "                        nz[j][i] = nz[i-1]//2\n",
    "                    else:\n",
    "                        nz[j][i] = nz[i-1]//4\n",
    "                j = j+1\n",
    "                print(nz)\n",
    "            self.main = nn.Sequential(\n",
    "                #reduction of dimensionality To Be Changed in conv... maybe\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d( nz[6], ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, self.nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(nc) x 64 x 64``\n",
    "            )\n",
    "\n",
    "            return self.main(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1689164151825,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "1n9BBXOOn-Cl"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 64\n",
    "        nc = 1\n",
    "        print(nz)\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1689172253886,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "JQZWxsQIe5z0",
    "outputId": "7a82fbd2-e89f-4939-85ff-9cbdacb1196f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "T: tensor([[0., 0., 1., 2., 3., 4., 4., 3., 2., 5., 6., 5.],\n",
      "        [0., 0., 0., 3., 4., 1., 0., 3., 4., 1., 6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# Python program to join tensors in PyTorch\n",
    "# import necessary library\n",
    "import torch\n",
    "\n",
    "# create tensors\n",
    "\n",
    "T1 = torch.zeros((2,2))\n",
    "T2 = torch.Tensor([[1,2,3,4],[0,3,4,1]])\n",
    "T3 = torch.Tensor([[4,3,2,5,6,5], [0,3,4,1,6,8]])\n",
    "\n",
    "print(T1)\n",
    "\n",
    "# join (concatenate) above tensors using torch.cat()\n",
    "T = torch.cat((T1,T2,T3), dim=1)\n",
    "# print final tensor after concatenation\n",
    "print(\"T:\",T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151827,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ZD2IYalLn-Co"
   },
   "outputs": [],
   "source": [
    "test1 = True\n",
    "if test1:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nz):\n",
    "            super(Generator, self).__init__()\n",
    "            ngf = 64\n",
    "            nc = 5\n",
    "            self.main = nn.Sequential()\n",
    "            self.main = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                #in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, ngf//2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf//2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf/2) x 64 x 64``\n",
    "                nn.ConvTranspose2d( ngf//2, nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(ngc) x 128 x 128``\n",
    "                # state size. ``(ngf/4) x 128 x 128``\n",
    "                #nn.BatchNorm2d(ngf),\n",
    "                #nn.ReLU(True),\n",
    "                #nn.ConvTranspose2d( ngf/4, nc, 4, 2, 1, bias=False),\n",
    "                #nn.Tanh()\n",
    "                # state size. ``(nc) x 256 x 256``\n",
    "            )\n",
    "\n",
    "        def forward(self, input):\n",
    "            return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1689164151829,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "PyC-nI41XULT"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class SegFormerHead(nn.Module):\n",
    "    def __init__(self, dims: list, embed_dim: int = 256, num_classes: int = 19):\n",
    "        super().__init__()\n",
    "        for i, dim in enumerate(dims):\n",
    "            self.add_module(f\"linear_c{i+1}\", MLP(dim, embed_dim))\n",
    "\n",
    "        self.linear_fuse = ConvModule(embed_dim*4, embed_dim)\n",
    "        self.linear_pred = nn.Conv2d(embed_dim, num_classes, 1)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        B, _, H, W = features[0].shape\n",
    "        outs = [self.linear_c1(features[0]).permute(0, 2, 1).reshape(B, -1, *features[0].shape[-2:])]\n",
    "\n",
    "        for i, feature in enumerate(features[1:]):\n",
    "            cf = eval(f\"self.linear_c{i+2}\")(feature).permute(0, 2, 1).reshape(B, -1, *feature.shape[-2:])\n",
    "            outs.append(F.interpolate(cf, size=(H, W), mode='bilinear', align_corners=False))\n",
    "\n",
    "        seg = self.linear_fuse(torch.cat(outs[::-1], dim=1))\n",
    "        seg = self.linear_pred(self.dropout(seg))\n",
    "        return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1689164151831,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "MCJtu7Y_n-Cr"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, 1, -1)\n",
    "\n",
    "class FlattenFinal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, -1, 1, 1)\n",
    "\n",
    "class Conv2DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class Conv1DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "class downsample(nn.Module):\n",
    "    def __init__(self, C, H, W):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Sequential()\n",
    "        i = 0\n",
    "        alt = True\n",
    "        if H*W > 128:\n",
    "            while(C>4):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "\n",
    "        else:\n",
    "            while(C>16):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "\n",
    "                if H//2<3 or W//2<3:\n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    self.downsample.append(Conv1DModule(1, 1, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-2\n",
    "                    W = W-2\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2 -1\n",
    "                    W = W//2 -1\n",
    "        self.downsample.append(FlattenFinal())\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.downsample(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1689164151833,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "ipHImK80n-Ct"
   },
   "outputs": [],
   "source": [
    "class SegFormerHeadGen(nn.Module):\n",
    "\n",
    "    def __init__(self, num_img):\n",
    "      self.num_img = num_img\n",
    "      super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "      x = features[self.num_img]\n",
    "      downsampler = downsample(x.shape[1],x.shape[2],x.shape[3]).to(device)\n",
    "\n",
    "\n",
    "      downsampler(x).size()\n",
    "      self.G = Generator(downsampler(x).size()[1]).to(device)\n",
    "      image = self.G(downsampler(x))\n",
    "\n",
    "\n",
    "      return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1689164151835,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "cZsudwlzXULU"
   },
   "outputs": [],
   "source": [
    "from semseg.models.base import BaseModel\n",
    "from semseg.models.heads import SegFormerHead\n",
    "#from resDecode import ResDecode\n",
    "\n",
    "\n",
    "class SegFormerpp(BaseModel):\n",
    "    def __init__(self, backbone: str = 'MiT-B0', num_classes: int = 19, head: str = 'B0', num_img: int = -1) -> None:\n",
    "        super().__init__(backbone, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.head = head\n",
    "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
    "        self.newDecode = SegFormerHeadGen(num_img)\n",
    "        self.newDecode.to(device)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        #y = self.decode(y)\n",
    "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        #embeds = []\n",
    "        y = self.newDecode(y)\n",
    "        '''\n",
    "        y = self.decode(y)\n",
    "        self.upsample = nn.Sequential(\n",
    "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
    "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),\n",
    "                                )\n",
    "        y = self.upsample(y).to(device)\n",
    "        '''\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1689164378457,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "bglipAaW_xaY",
    "outputId": "3e943d2f-8865-402a-df70-ec5bc156817f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download a pretrained model's weights from the result table.\n",
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "from semseg.models import *\n",
    "#from segFormerpp import SegFormerpp\n",
    "\n",
    "model = eval('SegFormerpp')(\n",
    "    backbone='MiT-B4',\n",
    "    num_classes=5,\n",
    "    num_img = 0\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('checkpointcheckpoints/pretrained/segformer/segformer.b3.ade.pth'))\n",
    "except:\n",
    "    print(\"Download a pretrained model's weights from the result table.\")\n",
    "model.eval()\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28194,
     "status": "ok",
     "timestamp": 1689164179977,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "stv4_1XZXULW",
    "outputId": "ba951ed3-d81a-44e2-cae6-fecb989a9cab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This are the import parameters: \n",
      "               Dataset: ai4mars-dataset-merged-0.1 \n",
      "               Path to the dataset: /home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/ \n",
      "               Colab Environment: False \n",
      "               Number of images to load: 500 \n",
      "               Saving path for X and y: None\n",
      "You already have ai4mars-dataset-merged-0.1\n",
      "Unpacking images and lables from: ai4mars-dataset-merged-0.1 ...\n",
      "Inputs len: 500\n",
      "Labels len: 500\n",
      "Converting inputs and labels into torch tensors ...\n",
      "Done\n",
      "Begin processing: \n",
      "             Dataset: ai4mars-dataset-merged-0.1 \n",
      "             Colab environment: False \n",
      "             Split percentages: [0.7, 0.2, 0.1] \n",
      "             Transformation: None\n",
      "Splitting in progress ...\n",
      "Done\n",
      "Building Dataloaders\n",
      "The Ai4MarsDataloaders will be saved here: /home/paolo/Desktop/dataset/\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "# Set this to True if you wnat to load directly the dataloader \n",
    "# this can be done only on colab and it is useful to avoid runtime crash\n",
    "LOAD = False\n",
    "\n",
    "if LOAD and not LOCAL:\n",
    "\n",
    "    if not(os.path.exists('/content/dataset/')):\n",
    "\n",
    "        import gdown\n",
    "\n",
    "        # get url of torch dataset (temporarerly my drive)\n",
    "        drive = 'https://drive.google.com/uc?id='\n",
    "        url_train = drive + '1agH_nuMOUaaVnX6_kzVu3me0lFHNU69L'\n",
    "        url_test = drive + '12Jy9VCzX4AHyCeGyALerIixpY2v37czm'\n",
    "        url_val = drive + '1KPv8juXivSk3gH6BXsRJqyV_wgZqGi8Y'\n",
    "\n",
    "        # download np dataset on runtime env\n",
    "        data_path = '/content/dataset/'\n",
    "        gdown.download(url_train, data_path, quiet=False)\n",
    "        gdown.download(url_test, data_path, quiet=False)\n",
    "        gdown.download(url_val, data_path, quiet=False)\n",
    "\n",
    "    train_loader = torch.load(\"/content/dataset/train_0.pt\")\n",
    "    test_loader = torch.load(\"/content/dataset/test_0.pt\")\n",
    "    val_loader = torch.load(\"/content/dataset/val_0.pt\")\n",
    "        \n",
    "elif LOCAL or not LOAD:\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    data_path = \"/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader/\"\n",
    "\n",
    "    # Insert here the number of images you want to download\n",
    "    num_images = 500 #int(input(\"Number of images (max 1000): \"))\n",
    "\n",
    "    # Insert here your local path to the dataset (temporary)\n",
    "    save_path = '/home/paolo/Desktop/dataset/' #input(\"Path to Save the Dataset: \")\n",
    "\n",
    "    if num_images > 1000 : raise Exception(\"Trying to import too many images\")\n",
    "\n",
    "    # Import data as Ai4MarsDataset\n",
    "    importer = Ai4MarsDownload()\n",
    "    X, y = importer(PATH=data_path, NUM_IMAGES=num_images)\n",
    "\n",
    "    # Split the dataset\n",
    "    splitter = Ai4MarsSplitter()\n",
    "    train_set, test_set, val_set = splitter(X, y, [0.7, 0.2, 0.1])\n",
    "\n",
    "    # Build Ai4MarsDataloader\n",
    "    loader = Ai4MarsDataloader()\n",
    "    train_loader, test_loader, val_loader = loader([train_set, test_set, val_set], [32, 16, 16], \n",
    "                                               SIZE=128, SAVE_PATH=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1689164179981,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "O3ytN-ugjHcW",
    "outputId": "29fe6dcc-1983-4c1b-a1e5-eabff10ea398"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  print(img.device)\\n  print(img.shape)\\n  if (img.device != 'cpu'):\\n    img.to('cpu')\\n    print('test')\\n  print(img.device)\\n  plt.imshow(img)\\n  plt.show()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show_image(imgs):\n",
    "    imgs = imgs.permute(2,0,1)\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "'''\n",
    "  print(img.device)\n",
    "  print(img.shape)\n",
    "  if (img.device != 'cpu'):\n",
    "    img.to('cpu')\n",
    "    print('test')\n",
    "  print(img.device)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1689164179986,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "3lU21D6nXULX"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer module for MER-Segmentation 2.0 \"\"\"\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from datetime import datetime \n",
    "\n",
    "# This class collects all the training functionalities to train different models\n",
    "class Ai4MarsTrainer():\n",
    "\n",
    "    # Initialization of training parameters in the class constructor\n",
    "    def __init__(self, loss_fn, optimizer, train_loader, val_loader,\n",
    "                 transform=None, device='cpu', save_state=None):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.save_state = save_state\n",
    "        self.transform = transform\n",
    "        self.loss_list = []\n",
    "        self.tloss_list = []\n",
    "\n",
    "    # This function implements training for just one epoch\n",
    "    def train_one_epoch(self, model, epoch_index=0):\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "\n",
    "        # parameters for online data augmentation (batch transformation)\n",
    "        running_tloss = 0.\n",
    "        last_tloss = 0.\n",
    "        t_index = 0 \n",
    "\n",
    "        for batch_index, batch in enumerate(self.train_loader):\n",
    "            # Every data instance is an (input, label) pair\n",
    "            inputs, labels = batch\n",
    "\n",
    "            # Zero your gradients for every batch!\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Send inputs and labels to GPU (or whatever device is)\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Adjust label to be 2D tensors of batch size\n",
    "            labels = labels.squeeze()\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # if transformation exists apply them to the batch\n",
    "            if self.transform:\n",
    "                tinputs = self.transform(inputs)\n",
    "                tinputs = tinputs.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                toutputs = model(tinputs)\n",
    "                tloss = self.loss_fn(toutputs, labels)\n",
    "                tloss.backward()\n",
    "                running_tloss = tloss.item()\n",
    "                t_index += 1\n",
    "                tinputs.detach()\n",
    "                del tinputs\n",
    "\n",
    "            # Free up RAM/VRAM\n",
    "            inputs.detach()\n",
    "            labels.detach()\n",
    "            del inputs\n",
    "            del labels\n",
    "\n",
    "        # Compute the average loss over all batches\n",
    "        last_loss =  running_loss / (batch_index + 1)\n",
    "\n",
    "        # Print report at the end of the last batch\n",
    "        print(f'Epoch {epoch_index+1}')\n",
    "        print(f'LOSS ON TRAIN: {last_loss}')\n",
    "        \n",
    "        if self.transform:\n",
    "            last_tloss = running_tloss / (t_index + 1)\n",
    "            print(f'LOSS ON TRANSFORMED-TRAIN: {last_tloss}')\n",
    "\n",
    "        else:\n",
    "            last_tloss = None\n",
    "\n",
    "        return last_loss, last_tloss\n",
    "\n",
    "    # This function implements training for multiple epochs\n",
    "    def train_multiple_epoch(self, model, EPOCHS=100):\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        epoch_number = 0 # just a counter\n",
    "        best_vloss = 1_000_000.\n",
    "        self.loss_list = []\n",
    "        self.tloss_list = []\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # Make sure gradient tracking is on, and do a pass over the data\n",
    "            model.train(True)\n",
    "\n",
    "            # Start monitoring training time\n",
    "            start = time.time()\n",
    "\n",
    "            avg_loss = self.train_one_epoch(model, epoch)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            # We don't need gradients on to do reporting\n",
    "            model.train(False)\n",
    "\n",
    "            # Test loss\n",
    "            running_vloss = 0.0\n",
    "            for vbatch_index, vbatch in enumerate(self.val_loader):\n",
    "\n",
    "                # Every data instance is a (input, label) pair\n",
    "                vinputs, vlabels = vbatch\n",
    "\n",
    "                # Send inputs and labels to GPU\n",
    "                vinputs = vinputs.to(self.device)\n",
    "                vlabels = vlabels.to(self.device)\n",
    "\n",
    "                # Model prediction\n",
    "                voutputs = model(vinputs)\n",
    "\n",
    "                # Send inputs and labels to GPU (or whatever device is)\n",
    "                vlabels = vlabels.squeeze()\n",
    "                vlabels = vlabels.long()\n",
    "\n",
    "                # Run validation loss\n",
    "                val_loss = self.loss_fn(voutputs, vlabels)\n",
    "                running_vloss += val_loss.item()\n",
    "\n",
    "                # Free up RAM/VRAM\n",
    "                vinputs.detach()\n",
    "                vlabels.detach()\n",
    "                del vinputs\n",
    "                del vlabels\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            # Compute the average loss over all batches\n",
    "            avg_vloss = running_vloss / (vbatch_index + 1)\n",
    "\n",
    "            print(\"Time needed for training: \" + str(end-start)+ \" seconds\")\n",
    "\n",
    "            # Print report at the end of the epoch\n",
    "            print(f'LOSS ON VALIDATION: {avg_vloss}')\n",
    "\n",
    "            # Save loss in a list to then perform metrics evaluation\n",
    "            self.loss_list.append((avg_loss[0], end-start))\n",
    "            \n",
    "            # If online data augmentation has been performed:\n",
    "            if avg_loss[1]:\n",
    "                self.tloss_list.append((avg_loss[1], end-start))\n",
    "\n",
    "            # Track best performance, and save the model's state\n",
    "            if avg_vloss < best_vloss:\n",
    "                best_vloss = avg_vloss\n",
    "                model_path = self.save_state + 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# based on:\n",
    "# https://github.com/kevinzakka/pytorch-goodies/blob/master/losses.py\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps: float = 1e-6\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input: torch.Tensor,\n",
    "            target: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "\n",
    "        #errors:\n",
    "        if not torch.is_tensor(input):\n",
    "            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n",
    "                            .format(type(input)))\n",
    "        if not len(input.shape) == 4:\n",
    "            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n",
    "                             .format(input.shape))\n",
    "        if not input.shape[-2:] == target.shape[-2:]:\n",
    "            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n",
    "                             .format(input.shape, input.shape))\n",
    "        if not input.device == target.device:\n",
    "            raise ValueError(\n",
    "                \"input and target must be in the same device. Got: {}\" .format(\n",
    "                    input.device, target.device))\n",
    "\n",
    "\n",
    "        num_classes = input.shape[1]\n",
    "\n",
    "        # compute softmax over the classes axis\n",
    "        input_soft = F.softmax(input, dim=1)\n",
    "\n",
    "        # print(\"shape\", input_soft.shape)\n",
    "\n",
    "        input_soft = input_soft.permute(0,2,1,3)\n",
    "        input_soft = input_soft.permute(0,1,3,2)\n",
    "\n",
    "        # create the labels one hot tensor\n",
    "        target_one_hot = F.one_hot(target, num_classes=input.shape[1])\n",
    "\n",
    "        # target_one_hot = target_one_hot.permute(0,1,3,2)\n",
    "        # target_one_hot = target_one_hot.permute(0,2,1,3)\n",
    "\n",
    "        # print(\"target_one_hot\",target_one_hot.shape)\n",
    "        # print(\"input_soft\",input_soft.shape)\n",
    "\n",
    "\n",
    "        # compute the actual dice score\n",
    "        dims = (1, 2, 3)\n",
    "        intersection = torch.sum(input_soft.reshape(-1) * target_one_hot.reshape(-1), -1)\n",
    "        cardinality = torch.sum(input_soft.reshape(-1) + target_one_hot.reshape(-1), -1)\n",
    "\n",
    "        dice_score = 2. * intersection / (cardinality + self.eps)\n",
    "\n",
    "        # if (self.stampa):\n",
    "        #   print(\"outputs\",input_soft)\n",
    "        #   print(\"labels\",target_one_hot)\n",
    "        #   print((1. - dice_score).item())\n",
    "\n",
    "\n",
    "\n",
    "        # print((1. - dice_score).shape)\n",
    "\n",
    "\n",
    "\n",
    "        return 1. - dice_score\n",
    "\n",
    "        #Alternative Universe\n",
    "\n",
    "        # labels = target_one_hot\n",
    "        # preds = input_soft\n",
    "\n",
    "        # tp = torch.sum(labels*preds, dim=(2, 3))\n",
    "        # fn = torch.sum(labels*(1-preds), dim=(2, 3))\n",
    "        # fp = torch.sum((1-labels)*preds, dim=(2, 3))\n",
    "\n",
    "\n",
    "        # delta = 0.5 # va messo come hyperparameter\n",
    "\n",
    "        # dice_score = (tp + 1e-6) / (tp + delta * fn + (1 - delta) * fp + 1e-6)\n",
    "        # dice_score = torch.sum(1 - dice_score, dim=-1)\n",
    "\n",
    "        # dice_score = dice_score / num_classes\n",
    "        # return dice_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVll-qRSXULY",
    "outputId": "e125181d-a822-4c69-f272-ea55ec43af18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "LOSS ON TRAIN: 0.8016570210456848\n",
      "Time needed for training: 6.446149587631226 seconds\n",
      "LOSS ON VALIDATION: 0.7944235056638718\n",
      "Epoch 2\n",
      "LOSS ON TRAIN: 0.800677933476188\n",
      "Time needed for training: 6.422220706939697 seconds\n",
      "LOSS ON VALIDATION: 0.8009003400802612\n",
      "Epoch 3\n",
      "LOSS ON TRAIN: 0.7990752133456144\n",
      "Time needed for training: 6.437650203704834 seconds\n",
      "LOSS ON VALIDATION: 0.7962034195661545\n",
      "Epoch 4\n",
      "LOSS ON TRAIN: 0.8007372617721558\n",
      "Time needed for training: 6.424295902252197 seconds\n",
      "LOSS ON VALIDATION: 0.7966146767139435\n",
      "Epoch 5\n",
      "LOSS ON TRAIN: 0.8037344975904985\n",
      "Time needed for training: 6.314681529998779 seconds\n",
      "LOSS ON VALIDATION: 0.8052686899900436\n",
      "Epoch 6\n",
      "LOSS ON TRAIN: 0.8023430542512373\n",
      "Time needed for training: 6.286259889602661 seconds\n",
      "LOSS ON VALIDATION: 0.8026094138622284\n",
      "Epoch 7\n",
      "LOSS ON TRAIN: 0.7993912967768583\n",
      "Time needed for training: 6.294966459274292 seconds\n",
      "LOSS ON VALIDATION: 0.8000606745481491\n",
      "Epoch 8\n",
      "LOSS ON TRAIN: 0.8037724169817838\n",
      "Time needed for training: 6.411431074142456 seconds\n",
      "LOSS ON VALIDATION: 0.8050799071788788\n",
      "Epoch 9\n",
      "LOSS ON TRAIN: 0.803417828950015\n",
      "Time needed for training: 6.404505729675293 seconds\n",
      "LOSS ON VALIDATION: 0.8010784983634949\n",
      "Epoch 10\n",
      "LOSS ON TRAIN: 0.8010863119905646\n",
      "Time needed for training: 6.351136684417725 seconds\n",
      "LOSS ON VALIDATION: 0.8036840856075287\n",
      "Epoch 11\n",
      "LOSS ON TRAIN: 0.799120924689553\n",
      "Time needed for training: 6.291815280914307 seconds\n",
      "LOSS ON VALIDATION: 0.7991165071725845\n",
      "Epoch 12\n",
      "LOSS ON TRAIN: 0.8024183674292131\n",
      "Time needed for training: 6.331637620925903 seconds\n",
      "LOSS ON VALIDATION: 0.7917678952217102\n",
      "Epoch 13\n",
      "LOSS ON TRAIN: 0.8016484488140453\n",
      "Time needed for training: 6.2373762130737305 seconds\n",
      "LOSS ON VALIDATION: 0.8000865280628204\n",
      "Epoch 14\n",
      "LOSS ON TRAIN: 0.8055593154647134\n",
      "Time needed for training: 6.284935712814331 seconds\n",
      "LOSS ON VALIDATION: 0.7980547696352005\n",
      "Epoch 15\n",
      "LOSS ON TRAIN: 0.7996642697941173\n",
      "Time needed for training: 6.408324956893921 seconds\n",
      "LOSS ON VALIDATION: 0.8027081787586212\n",
      "Epoch 16\n",
      "LOSS ON TRAIN: 0.7976969209584323\n",
      "Time needed for training: 6.2960944175720215 seconds\n",
      "LOSS ON VALIDATION: 0.8091400414705276\n",
      "Epoch 17\n",
      "LOSS ON TRAIN: 0.799523803320798\n",
      "Time needed for training: 6.2862160205841064 seconds\n",
      "LOSS ON VALIDATION: 0.7958801686763763\n",
      "Epoch 18\n",
      "LOSS ON TRAIN: 0.7999383265321905\n",
      "Time needed for training: 6.390305519104004 seconds\n",
      "LOSS ON VALIDATION: 0.7934540957212448\n",
      "Epoch 19\n",
      "LOSS ON TRAIN: 0.8031344576315447\n",
      "Time needed for training: 6.517831087112427 seconds\n",
      "LOSS ON VALIDATION: 0.788801521062851\n",
      "Epoch 20\n",
      "LOSS ON TRAIN: 0.7978567318482832\n",
      "Time needed for training: 6.39747166633606 seconds\n",
      "LOSS ON VALIDATION: 0.8048884123563766\n",
      "Epoch 21\n",
      "LOSS ON TRAIN: 0.7977773384614424\n",
      "Time needed for training: 6.358023643493652 seconds\n",
      "LOSS ON VALIDATION: 0.7897280305624008\n",
      "Epoch 22\n",
      "LOSS ON TRAIN: 0.7995651472698558\n",
      "Time needed for training: 6.3561320304870605 seconds\n",
      "LOSS ON VALIDATION: 0.7964621931314468\n",
      "Epoch 23\n",
      "LOSS ON TRAIN: 0.7988649335774508\n",
      "Time needed for training: 6.357247829437256 seconds\n",
      "LOSS ON VALIDATION: 0.7978312820196152\n",
      "Epoch 24\n",
      "LOSS ON TRAIN: 0.8008922771974043\n",
      "Time needed for training: 6.357372999191284 seconds\n",
      "LOSS ON VALIDATION: 0.7979355752468109\n",
      "Epoch 25\n",
      "LOSS ON TRAIN: 0.7973967844789679\n",
      "Time needed for training: 6.38297963142395 seconds\n",
      "LOSS ON VALIDATION: 0.8009375333786011\n",
      "Epoch 26\n",
      "LOSS ON TRAIN: 0.7959903424436395\n",
      "Time needed for training: 6.3729424476623535 seconds\n",
      "LOSS ON VALIDATION: 0.8018887937068939\n",
      "Epoch 27\n",
      "LOSS ON TRAIN: 0.8013360879637978\n",
      "Time needed for training: 6.305338144302368 seconds\n",
      "LOSS ON VALIDATION: 0.7957920879125595\n",
      "Epoch 28\n",
      "LOSS ON TRAIN: 0.7974774078889326\n",
      "Time needed for training: 6.404709100723267 seconds\n",
      "LOSS ON VALIDATION: 0.8014223575592041\n",
      "Epoch 29\n",
      "LOSS ON TRAIN: 0.7995084469968622\n",
      "Time needed for training: 6.342122793197632 seconds\n",
      "LOSS ON VALIDATION: 0.7985862046480179\n",
      "Epoch 30\n",
      "LOSS ON TRAIN: 0.7995083711364053\n",
      "Time needed for training: 6.299077033996582 seconds\n",
      "LOSS ON VALIDATION: 0.7961948812007904\n",
      "Epoch 31\n",
      "LOSS ON TRAIN: 0.8011214949867942\n",
      "Time needed for training: 6.312309741973877 seconds\n",
      "LOSS ON VALIDATION: 0.8032166957855225\n",
      "Epoch 32\n",
      "LOSS ON TRAIN: 0.7979126084934581\n",
      "Time needed for training: 6.334310531616211 seconds\n",
      "LOSS ON VALIDATION: 0.7992827147245407\n",
      "Epoch 33\n",
      "LOSS ON TRAIN: 0.8000821362842213\n",
      "Time needed for training: 6.541789293289185 seconds\n",
      "LOSS ON VALIDATION: 0.785811647772789\n",
      "Epoch 34\n",
      "LOSS ON TRAIN: 0.799977882341905\n",
      "Time needed for training: 6.501095294952393 seconds\n",
      "LOSS ON VALIDATION: 0.8025657832622528\n",
      "Epoch 35\n",
      "LOSS ON TRAIN: 0.7978978265415538\n",
      "Time needed for training: 6.463663578033447 seconds\n",
      "LOSS ON VALIDATION: 0.7972235232591629\n",
      "Epoch 36\n",
      "LOSS ON TRAIN: 0.7998938993974165\n",
      "Time needed for training: 6.482722759246826 seconds\n",
      "LOSS ON VALIDATION: 0.7981524020433426\n",
      "Epoch 37\n",
      "LOSS ON TRAIN: 0.8009730523282831\n",
      "Time needed for training: 6.4267871379852295 seconds\n",
      "LOSS ON VALIDATION: 0.8040941208600998\n",
      "Epoch 38\n",
      "LOSS ON TRAIN: 0.8041137131777677\n",
      "Time needed for training: 6.409138441085815 seconds\n",
      "LOSS ON VALIDATION: 0.8026832491159439\n",
      "Epoch 39\n",
      "LOSS ON TRAIN: 0.7963882955637845\n",
      "Time needed for training: 6.38154673576355 seconds\n",
      "LOSS ON VALIDATION: 0.802038386464119\n",
      "Epoch 40\n",
      "LOSS ON TRAIN: 0.7990538748827848\n",
      "Time needed for training: 6.421226739883423 seconds\n",
      "LOSS ON VALIDATION: 0.808060884475708\n",
      "Epoch 41\n",
      "LOSS ON TRAIN: 0.8006566871296276\n",
      "Time needed for training: 6.410194396972656 seconds\n",
      "LOSS ON VALIDATION: 0.7931682765483856\n",
      "Epoch 42\n",
      "LOSS ON TRAIN: 0.8003525896505876\n",
      "Time needed for training: 6.398430824279785 seconds\n",
      "LOSS ON VALIDATION: 0.7977605313062668\n",
      "Epoch 43\n",
      "LOSS ON TRAIN: 0.8013955896550958\n",
      "Time needed for training: 6.425954818725586 seconds\n",
      "LOSS ON VALIDATION: 0.8031314015388489\n",
      "Epoch 44\n",
      "LOSS ON TRAIN: 0.8005752509290521\n",
      "Time needed for training: 6.278897523880005 seconds\n",
      "LOSS ON VALIDATION: 0.7941876798868179\n",
      "Epoch 45\n",
      "LOSS ON TRAIN: 0.7993018572980707\n",
      "Time needed for training: 6.29190731048584 seconds\n",
      "LOSS ON VALIDATION: 0.798734501004219\n",
      "Epoch 46\n",
      "LOSS ON TRAIN: 0.8018357753753662\n",
      "Time needed for training: 6.274502754211426 seconds\n",
      "LOSS ON VALIDATION: 0.800299733877182\n",
      "Epoch 47\n",
      "LOSS ON TRAIN: 0.8021531430157748\n",
      "Time needed for training: 6.282399415969849 seconds\n",
      "LOSS ON VALIDATION: 0.8050091415643692\n",
      "Epoch 48\n",
      "LOSS ON TRAIN: 0.7978746403347362\n",
      "Time needed for training: 6.27372145652771 seconds\n",
      "LOSS ON VALIDATION: 0.8032904863357544\n",
      "Epoch 49\n",
      "LOSS ON TRAIN: 0.800890017639507\n",
      "Time needed for training: 6.304840564727783 seconds\n",
      "LOSS ON VALIDATION: 0.7973455488681793\n",
      "Epoch 50\n",
      "LOSS ON TRAIN: 0.8001396439292214\n",
      "Time needed for training: 6.253993511199951 seconds\n",
      "LOSS ON VALIDATION: 0.8004279583692551\n",
      "Epoch 51\n",
      "LOSS ON TRAIN: 0.7993490370837125\n",
      "Time needed for training: 6.27236008644104 seconds\n",
      "LOSS ON VALIDATION: 0.7919849753379822\n",
      "Epoch 52\n",
      "LOSS ON TRAIN: 0.8001846725290472\n",
      "Time needed for training: 6.269374370574951 seconds\n",
      "LOSS ON VALIDATION: 0.7983574718236923\n",
      "Epoch 53\n",
      "LOSS ON TRAIN: 0.8009567910974676\n",
      "Time needed for training: 6.305412530899048 seconds\n",
      "LOSS ON VALIDATION: 0.8047002553939819\n",
      "Epoch 54\n",
      "LOSS ON TRAIN: 0.7978693680329756\n",
      "Time needed for training: 6.308757066726685 seconds\n",
      "LOSS ON VALIDATION: 0.8060188889503479\n",
      "Epoch 55\n",
      "LOSS ON TRAIN: 0.8020778135819868\n",
      "Time needed for training: 6.7508745193481445 seconds\n",
      "LOSS ON VALIDATION: 0.8047750294208527\n",
      "Epoch 56\n",
      "LOSS ON TRAIN: 0.8015995025634766\n",
      "Time needed for training: 6.734682083129883 seconds\n",
      "LOSS ON VALIDATION: 0.7989423424005508\n",
      "Epoch 57\n",
      "LOSS ON TRAIN: 0.8005961667407643\n",
      "Time needed for training: 6.676299571990967 seconds\n",
      "LOSS ON VALIDATION: 0.7985870391130447\n",
      "Epoch 58\n",
      "LOSS ON TRAIN: 0.7981082417748191\n",
      "Time needed for training: 6.663826942443848 seconds\n",
      "LOSS ON VALIDATION: 0.8035391420125961\n",
      "Epoch 59\n",
      "LOSS ON TRAIN: 0.8012442209503867\n",
      "Time needed for training: 6.615195035934448 seconds\n",
      "LOSS ON VALIDATION: 0.7947491705417633\n",
      "Epoch 60\n",
      "LOSS ON TRAIN: 0.7991537180813876\n",
      "Time needed for training: 6.6978843212127686 seconds\n",
      "LOSS ON VALIDATION: 0.7973388135433197\n",
      "Epoch 61\n",
      "LOSS ON TRAIN: 0.7980838472192938\n",
      "Time needed for training: 6.701141357421875 seconds\n",
      "LOSS ON VALIDATION: 0.8019040375947952\n",
      "Epoch 62\n",
      "LOSS ON TRAIN: 0.7995129552754489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed for training: 6.70486855506897 seconds\n",
      "LOSS ON VALIDATION: 0.798577219247818\n",
      "Epoch 63\n",
      "LOSS ON TRAIN: 0.797753632068634\n",
      "Time needed for training: 6.673217296600342 seconds\n",
      "LOSS ON VALIDATION: 0.7971982061862946\n",
      "Epoch 64\n",
      "LOSS ON TRAIN: 0.794938250021501\n",
      "Time needed for training: 6.732165098190308 seconds\n",
      "LOSS ON VALIDATION: 0.7988870441913605\n",
      "Epoch 65\n",
      "LOSS ON TRAIN: 0.7962051196531816\n",
      "Time needed for training: 6.688254356384277 seconds\n",
      "LOSS ON VALIDATION: 0.7954755276441574\n",
      "Epoch 66\n",
      "LOSS ON TRAIN: 0.8002242229201577\n",
      "Time needed for training: 6.6762096881866455 seconds\n",
      "LOSS ON VALIDATION: 0.7974141240119934\n",
      "Epoch 67\n",
      "LOSS ON TRAIN: 0.8007240187038075\n",
      "Time needed for training: 6.6762213706970215 seconds\n",
      "LOSS ON VALIDATION: 0.8045574426651001\n",
      "Epoch 68\n",
      "LOSS ON TRAIN: 0.7970087148926475\n",
      "Time needed for training: 6.653101682662964 seconds\n",
      "LOSS ON VALIDATION: 0.7954332381486893\n",
      "Epoch 69\n",
      "LOSS ON TRAIN: 0.802130249413577\n",
      "Time needed for training: 6.686516284942627 seconds\n",
      "LOSS ON VALIDATION: 0.8052925765514374\n",
      "Epoch 70\n",
      "LOSS ON TRAIN: 0.7986048730936918\n",
      "Time needed for training: 6.6604602336883545 seconds\n",
      "LOSS ON VALIDATION: 0.7963938415050507\n",
      "Epoch 71\n",
      "LOSS ON TRAIN: 0.7970179211009633\n",
      "Time needed for training: 6.722538471221924 seconds\n",
      "LOSS ON VALIDATION: 0.8019460141658783\n",
      "Epoch 72\n",
      "LOSS ON TRAIN: 0.7984541004354303\n",
      "Time needed for training: 6.719719171524048 seconds\n",
      "LOSS ON VALIDATION: 0.7996197938919067\n",
      "Epoch 73\n",
      "LOSS ON TRAIN: 0.7972115603360262\n",
      "Time needed for training: 6.70952844619751 seconds\n",
      "LOSS ON VALIDATION: 0.798044428229332\n",
      "Epoch 74\n",
      "LOSS ON TRAIN: 0.7979718934405934\n",
      "Time needed for training: 6.676716327667236 seconds\n",
      "LOSS ON VALIDATION: 0.7963927686214447\n",
      "Epoch 75\n",
      "LOSS ON TRAIN: 0.7985931038856506\n",
      "Time needed for training: 6.673390626907349 seconds\n",
      "LOSS ON VALIDATION: 0.8028659224510193\n",
      "Epoch 76\n",
      "LOSS ON TRAIN: 0.7988929694349115\n",
      "Time needed for training: 6.706583738327026 seconds\n",
      "LOSS ON VALIDATION: 0.7986628115177155\n",
      "Epoch 77\n",
      "LOSS ON TRAIN: 0.800670786337419\n",
      "Time needed for training: 6.69437837600708 seconds\n",
      "LOSS ON VALIDATION: 0.8026463091373444\n",
      "Epoch 78\n",
      "LOSS ON TRAIN: 0.8029081983999773\n",
      "Time needed for training: 6.667917490005493 seconds\n",
      "LOSS ON VALIDATION: 0.8050883114337921\n",
      "Epoch 79\n",
      "LOSS ON TRAIN: 0.7972939339551058\n",
      "Time needed for training: 6.683117628097534 seconds\n",
      "LOSS ON VALIDATION: 0.8089127987623215\n",
      "Epoch 80\n",
      "LOSS ON TRAIN: 0.8013083284551447\n",
      "Time needed for training: 6.485374927520752 seconds\n",
      "LOSS ON VALIDATION: 0.8021902740001678\n",
      "Epoch 81\n",
      "LOSS ON TRAIN: 0.7981234897266735\n",
      "Time needed for training: 6.462124586105347 seconds\n",
      "LOSS ON VALIDATION: 0.7957143783569336\n",
      "Epoch 82\n",
      "LOSS ON TRAIN: 0.8024992346763611\n",
      "Time needed for training: 6.368237257003784 seconds\n",
      "LOSS ON VALIDATION: 0.8001394867897034\n",
      "Epoch 83\n",
      "LOSS ON TRAIN: 0.8013055378740485\n",
      "Time needed for training: 6.45339035987854 seconds\n",
      "LOSS ON VALIDATION: 0.8024805039167404\n",
      "Epoch 84\n",
      "LOSS ON TRAIN: 0.800868874246424\n",
      "Time needed for training: 6.440495491027832 seconds\n",
      "LOSS ON VALIDATION: 0.7947797477245331\n",
      "Epoch 85\n",
      "LOSS ON TRAIN: 0.8017975091934204\n",
      "Time needed for training: 6.386777877807617 seconds\n",
      "LOSS ON VALIDATION: 0.7974379062652588\n",
      "Epoch 86\n",
      "LOSS ON TRAIN: 0.800962047143416\n",
      "Time needed for training: 6.446077346801758 seconds\n",
      "LOSS ON VALIDATION: 0.8000979572534561\n",
      "Epoch 87\n",
      "LOSS ON TRAIN: 0.8022864515131171\n",
      "Time needed for training: 6.477773666381836 seconds\n",
      "LOSS ON VALIDATION: 0.8014775961637497\n",
      "Epoch 88\n",
      "LOSS ON TRAIN: 0.8006353703412142\n",
      "Time needed for training: 6.420858144760132 seconds\n",
      "LOSS ON VALIDATION: 0.7996678352355957\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
    "loss_fn_cross = torch.nn.CrossEntropyLoss().to(device)\n",
    "loss_fn_dice = DiceLoss().to(device)\n",
    "\n",
    "\n",
    "trainer = Ai4MarsTrainer(loss_fn_dice, optimizer, train_loader, val_loader, device = device, save_state = \"/home/paolo/Desktop/dataset/\")\n",
    "model.to(device)\n",
    "trainer.train_multiple_epoch(model)\n",
    "# Plot the histogram\n",
    "plt.plot(np.array(trainer.loss_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "error",
     "timestamp": 1689164347160,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "FZzOcvNXLK19",
    "outputId": "6d586d17-2309-43bf-e0a8-02c5aa9036d4"
   },
   "outputs": [],
   "source": [
    "from semseg.datasets import *\n",
    "\n",
    "#model = model.to(device)\n",
    "predictions = []\n",
    "start = time.time()\n",
    "#print('test')\n",
    "# Use torch.no_grad() to disable gradient computation during testing\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the desired device\n",
    "        #print(images.shape)\n",
    "        #images = images.permute(0,3,1,2).to(device)\n",
    "        #images = images.permute(2,0,1).to(device)\n",
    "        #images = images [None, :, :, :]\n",
    "        #print(images.shape)\n",
    "\n",
    "        #print(images.shape)\n",
    "        #labels = labels.to(device)\n",
    "\n",
    "        # Forward pass to get the predictions\n",
    "        with torch.inference_mode():\n",
    "          prediction = model(images)\n",
    "        #print(prediction)\n",
    "        prediction = prediction.softmax(1).argmax(1).to(int)\n",
    "        #prediction = prediction.round().to(int)\n",
    "        #print(prediction.shape)\n",
    "        un = prediction.unique()\n",
    "        #print(un)\n",
    "        palette = eval('ADE20K').PALETTE.to(device)\n",
    "        prediction_map = palette[prediction].squeeze().to(torch.uint8)\n",
    "        #print(type(prediction_map))\n",
    "        show_image(prediction_map)\n",
    "        predictions.append(prediction_map)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1689164347161,
     "user": {
      "displayName": "paolo renzi",
      "userId": "12765974689024670837"
     },
     "user_tz": -120
    },
    "id": "UKfyLsOXXBjx"
   },
   "outputs": [],
   "source": [
    "torch.randn(64, 512, 1, 1, device=device).size()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

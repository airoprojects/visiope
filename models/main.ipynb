{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mrwBo-RKXULP",
        "outputId": "1015b11a-fa55-4f11-d77b-c6d25a6761ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semantic-segmentation'...\n",
            "remote: Enumerating objects: 792, done.\u001b[K\n",
            "remote: Counting objects: 100% (789/789), done.\u001b[K\n",
            "remote: Compressing objects: 100% (312/312), done.\u001b[K\n",
            "remote: Total 792 (delta 479), reused 749 (delta 470), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (792/792), 54.99 MiB | 36.54 MiB/s, done.\n",
            "Resolving deltas: 100% (479/479), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/semantic-segmentation\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (4.65.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (0.8.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (1.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (3.7.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (2.12.2)\n",
            "Collecting fvcore (from semseg==0.4.1)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops (from semseg==0.4.1)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from semseg==0.4.1) (13.3.4)\n",
            "Collecting yacs>=0.1.6 (from fvcore->semseg==0.4.1)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->semseg==0.4.1) (6.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->semseg==0.4.1) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->semseg==0.4.1) (8.4.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore->semseg==0.4.1)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->semseg==0.4.1) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->semseg==0.4.1) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->semseg==0.4.1) (2.14.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->semseg==0.4.1) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->semseg==0.4.1) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->semseg==0.4.1) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->semseg==0.4.1) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->semseg==0.4.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->semseg==0.4.1) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore->semseg==0.4.1) (4.5.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore->semseg==0.4.1)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->semseg==0.4.1) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->semseg==0.4.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->semseg==0.4.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->semseg==0.4.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->semseg==0.4.1) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->semseg==0.4.1) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->semseg==0.4.1) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->semseg==0.4.1) (3.2.2)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=33fbae146a2a2b1e80be43e7c614f9f5469ce2dc4319878b40593e8011c5f6f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31531 sha256=51ad18053b30c9f42e0afe09c850439481ba7dac5c50f8111d61aae9fef4e575\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, einops, iopath, fvcore, semseg\n",
            "  Running setup.py develop for semseg\n",
            "Successfully installed einops-0.6.1 fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 semseg-0.4.1 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT\n",
            "From (redirected): https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT&confirm=t&uuid=a2e18c30-585b-4baf-9455-ba0b72b0db15\n",
            "To: /content/semantic-segmentation/checkpoints/pretrained/segformer/segformer.b3.ade.pth\n",
            "100%|██████████| 190M/190M [00:01<00:00, 122MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./checkpoints/pretrained/segformer/segformer.b3.ade.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "!git clone https://github.com/sithu31296/semantic-segmentation\n",
        "%pip install -U gdown\n",
        "%pip install -e .\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "ckpt = Path('./checkpoints/pretrained/segformer')\n",
        "ckpt.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n",
        "output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5vQ0kHSCTjj",
        "outputId": "20f11aeb-f4c2-4b48-90a2-579cbb9bfc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kytW-DGR_xaS",
        "outputId": "c3de695c-4155-461d-e626-862af302610d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/semantic-segmentation\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import io\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import torchvision.transforms.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "%cd semantic-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70KFVZ45XULQ"
      },
      "outputs": [],
      "source": [
        "help(torch.Size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xMda6sXbXULS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from itertools import chain\n",
        "from math import ceil\n",
        "#from base_model import BaseModel\n",
        "\n",
        "class DecoderBottleneck(nn.Module):\n",
        "    def __init__(self, inchannels):\n",
        "        super(DecoderBottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inchannels, inchannels//4, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(inchannels//4)\n",
        "        self.conv2 = nn.ConvTranspose2d(inchannels//4, inchannels//4, kernel_size=2, stride=2, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(inchannels//4)\n",
        "        self.conv3 = nn.Conv2d(inchannels//4, inchannels//2, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(inchannels//2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(inchannels, inchannels//2, kernel_size=2, stride=2, bias=False),\n",
        "                nn.BatchNorm2d(inchannels//2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class LastBottleneck(nn.Module):\n",
        "    def __init__(self, inchannels):\n",
        "        super(LastBottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inchannels, inchannels//4, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(inchannels//4)\n",
        "        self.conv2 = nn.Conv2d(inchannels//4, inchannels//4, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(inchannels//4)\n",
        "        self.conv3 = nn.Conv2d(inchannels//4, inchannels//4, 1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(inchannels//4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(inchannels, inchannels//4, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(inchannels//4))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0qP9p2W5XULT",
        "outputId": "88fd0c53-3564-4ea6-a95b-11fc0e4e3f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-79b1d63c9d7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mResDecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_bn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResDecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mresnet50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BaseModel' is not defined"
          ]
        }
      ],
      "source": [
        "class ResDecode(BaseModel):\n",
        "    def __init__(self, num_classes, pretrained=True, freeze_bn=False, **_):\n",
        "        super(ResDecode, self).__init__()\n",
        "        resnet50 = torchvision.models.resnet50()\n",
        "        num_classes = 10\n",
        "        # Decoder\n",
        "        resnet50_untrained = models.resnet50(pretrained=False)\n",
        "        resnet50_blocks = list(resnet50_untrained.children())[4:-2][::-1]\n",
        "        decoder = []\n",
        "        channels = (2048, 1024, 512)\n",
        "        for i, block in enumerate(resnet50_blocks[:-1]):\n",
        "            new_block = list(block.children())[::-1][:-1]\n",
        "            decoder.append(nn.Sequential(*new_block, DecoderBottleneck(channels[i])))\n",
        "        new_block = list(resnet50_blocks[-1].children())[::-1][:-1]\n",
        "        decoder.append(nn.Sequential(*new_block, LastBottleneck(256)))\n",
        "        self.decoder = nn.Sequential(*decoder)\n",
        "        \n",
        "        self.last_conv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2, bias=False),\n",
        "            nn.Conv2d(64, num_classes, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \n",
        "        inputsize = x.size()\n",
        "\n",
        "        # Decoder\n",
        "        x = self.decoder(x)\n",
        "        h_diff = ceil((x.size()[2] - indices.size()[2]) / 2)\n",
        "        w_diff = ceil((x.size()[3] - indices.size()[3]) / 2)\n",
        "        if indices.size()[2] % 2 == 1:\n",
        "            x = x[:, :, h_diff:x.size()[2]-(h_diff-1), w_diff: x.size()[3]-(w_diff-1)]\n",
        "        else:\n",
        "            x = x[:, :, h_diff:x.size()[2]-h_diff, w_diff: x.size()[3]-w_diff]\n",
        "\n",
        "        x = F.max_unpool2d(x, indices, kernel_size=2, stride=2)\n",
        "        x = self.last_conv(x)\n",
        "        \n",
        "        if inputsize != x.size():\n",
        "            h_diff = (x.size()[2] - inputsize[2]) // 2\n",
        "            w_diff = (x.size()[3] - inputsize[3]) // 2\n",
        "            x = x[:, :, h_diff:x.size()[2]-h_diff, w_diff: x.size()[3]-w_diff]\n",
        "            if h_diff % 2 != 0: x = x[:, :, :-1, :]\n",
        "            if w_diff % 2 != 0: x = x[:, :, :, :-1]\n",
        "\n",
        "        return x    \n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    module = nn.Module()\n",
        "    model = ResDecode(module)\n",
        "    #x = torch.zeros(1, 3, 224, 224)\n",
        "    #outs = model(x)\n",
        "    #for y in outs:\n",
        "    #    print(y.shape)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kwVFZJKgXULT"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, nc):\n",
        "        nc = nc\n",
        "        super(Generator, self).__init__()\n",
        "       \n",
        "\n",
        "    def forward(self, embeds):\n",
        "        ngf = 64\n",
        "        nz = [[None] *6]*4\n",
        "        \n",
        "        j = 0\n",
        "        for embed in embeds:\n",
        "            nz[j][0] = embed.size()[1]\n",
        "            for i in range(1,6):\n",
        "                if i < 4:\n",
        "                    nz[j][i] = nz[i-1]//2\n",
        "                else:\n",
        "                    nz[j][i] = nz[i-1]//4\n",
        "            j = j+1\n",
        "            print(nz)\n",
        "        self.main = nn.Sequential(\n",
        "            #reduction of dimensionality To Be Changed in conv... maybe\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz[6], ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf*8) x 4 x 4``\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf*4) x 8 x 8``\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf*2) x 16 x 16``\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf) x 32 x 32``\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. ``(nc) x 64 x 64``\n",
        "        )\n",
        "        \n",
        "        return self.main(embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PyC-nI41XULT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from typing import Tuple\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim, embed_dim):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(dim, embed_dim)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvModule(nn.Module):\n",
        "    def __init__(self, c1, c2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(c1, c2, 1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(c2)        # use SyncBN in original\n",
        "        self.activate = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.activate(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "class SegFormerHead(nn.Module):\n",
        "    def __init__(self, dims: list, embed_dim: int = 256, num_classes: int = 19):\n",
        "        super().__init__()\n",
        "        for i, dim in enumerate(dims):\n",
        "            self.add_module(f\"linear_c{i+1}\", MLP(dim, embed_dim))\n",
        "\n",
        "        self.linear_fuse = ConvModule(embed_dim*4, embed_dim)\n",
        "        self.linear_pred = nn.Conv2d(embed_dim, num_classes, 1)\n",
        "        self.dropout = nn.Dropout2d(0.1)\n",
        "\n",
        "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
        "        B, _, H, W = features[0].shape\n",
        "        outs = [self.linear_c1(features[0]).permute(0, 2, 1).reshape(B, -1, *features[0].shape[-2:])]\n",
        "\n",
        "        for i, feature in enumerate(features[1:]):\n",
        "            cf = eval(f\"self.linear_c{i+2}\")(feature).permute(0, 2, 1).reshape(B, -1, *feature.shape[-2:])\n",
        "            outs.append(F.interpolate(cf, size=(H, W), mode='bilinear', align_corners=False))\n",
        "\n",
        "        seg = self.linear_fuse(torch.cat(outs[::-1], dim=1))\n",
        "        seg = self.linear_pred(self.dropout(seg))\n",
        "        return seg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cZsudwlzXULU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn import functional as F\n",
        "from semseg.models.base import BaseModel\n",
        "from semseg.models.heads import SegFormerHead\n",
        "#from resDecode import ResDecode\n",
        "\n",
        "\n",
        "class SegFormerpp(BaseModel):\n",
        "    def __init__(self, backbone: str = 'MiT-B0', num_classes: int = 19, head: str = 'B0') -> None:\n",
        "        super().__init__(backbone, num_classes)\n",
        "        self.num_classes = num_classes\n",
        "        self.head = head\n",
        "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
        "        self.decode_head = Generator(num_classes)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        y = self.backbone(x)\n",
        "        #y = self.decode(y)\n",
        "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "        #embeds = []\n",
        "        #for h in y:\n",
        "        #    embed = torch.reshape(h,(h.shape[0],h.shape[1]*h.shape[2]*h.shape[3]))\n",
        "        #    embeds.append(embed)\n",
        "        y = self.decode(y)\n",
        "        upsample = nn.Sequential(        \n",
        "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
        "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),   \n",
        "        #torch.nn.ConvTranspose2d(y.shape[1],3,3,stride=2,padding=1)\n",
        "                                ).to(device)\n",
        "        y = upsample(y)\n",
        "        return y\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = SegFormerpp('MiT-B0')\n",
        "    # model.load_state_dict(torch.load('checkpoints/pretrained/segformer/segformer.b0.ade.pth', map_location='cpu'))\n",
        "    #x = torch.zeros(1, 3, 512, 512).to(device)\n",
        "    #y = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bglipAaW_xaY",
        "outputId": "0ef004ba-4063-469a-9535-3218505b913f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download a pretrained model's weights from the result table.\n",
            "Loaded Model\n"
          ]
        }
      ],
      "source": [
        "from semseg.models import *\n",
        "#from segFormerpp import SegFormerpp\n",
        "\n",
        "model = eval('SegFormerpp')(\n",
        "    backbone='MiT-B3',\n",
        "    num_classes=4\n",
        ")\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load('checkpointcheckpoints/pretrained/segformer/segformer.b3.ade.pth'))\n",
        "except:\n",
        "    print(\"Download a pretrained model's weights from the result table.\")\n",
        "model.eval()\n",
        "model.to(device)\n",
        "print('Loaded Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AujMSfML_xaa"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "L2H1x10FXULW",
        "outputId": "b8f671cc-a07d-4467-80a4-af7183d36381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '../../dataloader/'\n",
            "/content/semantic-segmentation\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-dd3669df631e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../../dataloader/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAi4MarsData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/semantic-segmentation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "%cd ../../dataloader/\n",
        "from load import Ai4MarsData\n",
        "%cd ../models/semantic-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stv4_1XZXULW",
        "outputId": "e2e04d5b-4a2c-4875-8887-c10d71b3cd7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'visiope' already exists and is not an empty directory.\n",
            "/content/semantic-segmentation/visiope/dataloader\n",
            "/content/semantic-segmentation\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.utils.data.dataset.Subset'>\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/airoprojects/visiope\n",
        "%cd visiope/dataloader/\n",
        "from load import Ai4MarsData\n",
        "%cd ../..\n",
        "with open('/content/drive/MyDrive/Dataset/data_loader.pkl', 'rb') as f:\n",
        "    data_loader = pickle.load(f)\n",
        "\n",
        "\n",
        "data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\n",
        "data_loader['dataloader'].dataset.setDevice(device,0)\n",
        "data_loader['dataloader'].dataset.setDevice(device,1)\n",
        "#data_loader['dataloader'].dataset.setdevice(device)\n",
        "\n",
        "train_loader, test_loader, validation_loader = data_loader['dataloader'].dataset.splitLoader(80,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kUgDMrCLXULW",
        "outputId": "f49a2b12-bf3f-4522-8f9b-0c3680ce741d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b9463c94d659>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../dataloader/data_loader.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../dataloader/data_loader.pkl'"
          ]
        }
      ],
      "source": [
        "#local\n",
        "with open('../../dataloader/data_loader.pkl', 'rb') as f:\n",
        "    data_loader = pickle.load(f)\n",
        "\n",
        "data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\n",
        "#data_loader['dataloader'].dataset.convertion(0)\n",
        "data_loader['dataloader'].dataset.setDevice(device,0)\n",
        "data_loader['dataloader'].dataset.setDevice(device,1)\n",
        "#data_loader['dataloader'].dataset.setdevice(device)\n",
        "\n",
        "train_loader, test_loader, validation_loader = data_loader['dataloader'].dataset.splitLoader(80,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "O3ytN-ugjHcW",
        "outputId": "b7707c4c-5282-431c-8663-1493ee0348ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"  \\n  print(img.device)\\n  print(img.shape)\\n  if (img.device != 'cpu'):\\n    img.to('cpu')\\n    print('test')\\n  print(img.device)\\n  plt.imshow(img)\\n  plt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "def show_image(imgs):\n",
        "    imgs = imgs.permute(2,0,1)\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "'''  \n",
        "  print(img.device)\n",
        "  print(img.shape)\n",
        "  if (img.device != 'cpu'):\n",
        "    img.to('cpu')\n",
        "    print('test')\n",
        "  print(img.device)\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "bCdsw7j2XULX",
        "outputId": "58e92eef-12f8-4004-c049-30657b509506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/loss\n",
            "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
          ]
        }
      ],
      "source": [
        "#local\n",
        "%cd ../../loss/\n",
        "from trainer_module import trainer\n",
        "%cd ../models/semantic-segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqlb9HnBYe54",
        "outputId": "c12b6f9f-fa92-407d-dd2c-5495cdb86904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/semantic-segmentation/visiope/loss\n",
            "/content/semantic-segmentation\n"
          ]
        }
      ],
      "source": [
        "%cd visiope/loss/\n",
        "from trainer_module import trainer\n",
        "%cd ../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vVEzddUXULX"
      },
      "outputs": [],
      "source": [
        "for i, data in enumerate(training_set):\n",
        "        inputs, labels = data\n",
        "        print(inputs.shape)\n",
        "        inputs = inputs.permute(0,3,1,2).to(device)\n",
        "        # Zero your gradients for every batch!+\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3lU21D6nXULX"
      },
      "outputs": [],
      "source": [
        "\"\"\" Trainer module for MER-Segmentation \"\"\"\n",
        "\n",
        "from datetime import datetime\n",
        "import torch\n",
        "\n",
        "# Setup path for custom imports\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/Github/visiope/loss')\n",
        "from loss_functions import *\n",
        "\n",
        "# Main trainer function\n",
        "def trainer(parameters, multiple_epochs=False, epoch_index=0, tb_writer=0):\n",
        "\n",
        "    if multiple_epochs: \n",
        "        train_multiple_epoch(parameters, EPOCHS=100)\n",
        "\n",
        "    else:\n",
        "        train_one_epoch(parameters, epoch_index, tb_writer)\n",
        "    \n",
        "# IMPORTANT: FIND OUT ABOUT TB_WRITER\n",
        "def train_one_epoch(parameters, epoch_index, tb_writer):\n",
        "\n",
        "    # Initialization of training parameters\n",
        "    model = parameters['model']\n",
        "    loss_fn = parameters['loss']\n",
        "    optimizer = parameters['optimizer']\n",
        "    training_set = parameters['training']\n",
        "    device = parameters['device']\n",
        "\n",
        "    # To keep track of the last loss when the function is executed through multiple epochs\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_set):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "        #inputs = inputs.permute(0,3,1,2).to(device)\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        #print(labels.type())\n",
        "        print(outputs)\n",
        "        #labels = labels.type(torch.DoubleTensor)\n",
        "\n",
        "        #labels = labels.to(device)       \n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        # IMPORTANT: UNCOMMENT THIS PART AFTER FINDING OUT ABOUT TB_WRITER\n",
        "        '''\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_set) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "        '''\n",
        "\n",
        "    return last_loss\n",
        "\n",
        "\n",
        "def train_multiple_epoch(parameters, EPOCHS=100):\n",
        "\n",
        "    # Initialization of training parameters\n",
        "    model = parameters['model']\n",
        "    loss_fn = parameters['loss']\n",
        "    #optimizer = parameters['optimizer']\n",
        "    #training_set = parameters['training']\n",
        "    validation_set = parameters['validation']\n",
        "\n",
        "    # Initialization of report parameters\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    writer = 0 #SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "    epoch_number = 0 # just a counter\n",
        "    best_vloss = 1_000_000.\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "        # Make sure gradient tracking is on, and do a pass over the data\n",
        "        model.train(True)\n",
        "        avg_loss = train_one_epoch(parameters, epoch_number, writer)\n",
        "\n",
        "        # We don't need gradients on to do reporting\n",
        "        model.train(False)\n",
        "\n",
        "        # Validation loss\n",
        "        running_vloss = 0.0\n",
        "        for i, vdata in enumerate(validation_set):\n",
        "            vinputs, vlabels = vdata\n",
        "            \n",
        "            voutputs = model(vinputs)\n",
        "            \n",
        "            vlabels = vlabels.type(torch.DoubleTensor)\n",
        "\n",
        "            vlabels = vlabels.to(device)       \n",
        "\n",
        "            \n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "        avg_vloss = running_vloss / (i + 1)\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "        # IMPORTANT: UNCOMMENT THIS PART AFTER FINDING OUT ABOUT TB_WRITER\n",
        "        '''\n",
        "        # Log the running loss averaged per batch\n",
        "        # for both training and validation\n",
        "        writer.add_scalars('Training vs. Validation Loss',\n",
        "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                        epoch_number + 1)\n",
        "        writer.flush()\n",
        "        '''\n",
        "\n",
        "        '''\n",
        "        # Track best performance, and save the model's state\n",
        "        if avg_vloss < best_vloss:\n",
        "            best_vloss = avg_vloss\n",
        "            model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        '''\n",
        "        torch.cuda.empty_cache()\n",
        "        epoch_number += 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # This variable needs to be initialized with dummy values/data to test loss integration\n",
        "    '''\n",
        "    model = 0\n",
        "    optimizer = 0\n",
        "    loss_fn = 0\n",
        "    training_set = 0 \n",
        "    validation_set = 0\n",
        "\n",
        "    parameters = {\n",
        "                    'model' : model,\n",
        "                    'loss' : loss_fn,\n",
        "                    'optimizer' : optimizer,\n",
        "                    'training' : training_set,\n",
        "                    'validation': validation_set\n",
        "    }\n",
        "    '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uVll-qRSXULY",
        "outputId": "b402c01b-8720-4765-a406-7d4d27840f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "tensor([[[[-4.9114e-01, -6.9389e-01, -3.5933e-01,  ...,  8.4469e-02,\n",
            "            5.8770e-05, -9.6120e-02],\n",
            "          [ 8.1815e-02,  1.0720e-01, -1.3767e+00,  ...,  1.0286e-01,\n",
            "            1.1882e-01, -3.3575e-02],\n",
            "          [-1.2103e+00,  1.0138e+00,  4.2301e-01,  ..., -1.3438e-01,\n",
            "            4.6746e-02,  2.3477e-01],\n",
            "          ...,\n",
            "          [-7.0399e-02, -2.5424e-01, -2.4429e-01,  ...,  5.3917e-01,\n",
            "           -1.4160e-01, -6.9830e-01],\n",
            "          [-5.8997e-01, -5.4969e-01,  3.5556e-01,  ..., -1.0218e-01,\n",
            "            1.6349e-01, -1.6984e-01],\n",
            "          [-6.7554e-01, -5.3373e-02,  7.8492e-01,  ...,  8.0222e-02,\n",
            "            8.5912e-02,  3.7110e-01]],\n",
            "\n",
            "         [[ 4.7415e-01,  4.1932e-01,  3.2826e-02,  ...,  5.6196e-02,\n",
            "            2.0329e-01,  2.4891e-01],\n",
            "          [-3.0254e-01, -9.8527e-02, -5.4722e-02,  ..., -1.2210e-01,\n",
            "            4.9419e-02, -3.4381e-01],\n",
            "          [ 6.7504e-01,  3.7625e-01,  3.8011e-01,  ..., -2.1014e-01,\n",
            "           -1.3307e-01, -1.4983e-01],\n",
            "          ...,\n",
            "          [ 5.0286e-01,  6.9833e-01, -4.8557e-01,  ..., -2.2493e-01,\n",
            "            9.0204e-01, -7.6054e-02],\n",
            "          [ 7.5835e-01,  4.4597e-01, -2.9583e-01,  ...,  4.7148e-01,\n",
            "            1.8480e-01,  2.5394e-01],\n",
            "          [-4.7233e-02, -1.8971e-01, -2.4652e-01,  ..., -4.6973e-01,\n",
            "           -1.7402e-01,  4.2781e-01]],\n",
            "\n",
            "         [[-2.2118e-01, -3.9964e-01,  4.2752e-01,  ...,  4.1261e-01,\n",
            "           -3.5813e-02, -2.0813e-01],\n",
            "          [-3.1340e-01, -1.8462e+00, -5.0382e-01,  ...,  5.6625e-01,\n",
            "           -4.5193e-01, -6.5842e-02],\n",
            "          [ 3.6944e-01,  6.1953e-01,  7.0240e-02,  ...,  1.7766e-02,\n",
            "            3.0991e-01, -2.0393e-02],\n",
            "          ...,\n",
            "          [ 1.3938e-01, -1.4627e+00, -7.5669e-01,  ..., -3.1907e-01,\n",
            "           -1.4027e-01, -6.8755e-01],\n",
            "          [-3.7734e-01, -6.7606e-01,  1.8574e-01,  ..., -2.5966e-01,\n",
            "            5.3067e-02, -6.7465e-01],\n",
            "          [-3.4337e-01, -8.9572e-01, -4.7499e-01,  ...,  2.7874e-02,\n",
            "            3.1231e-02,  2.0091e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.5049e-02, -5.6984e-01,  2.1459e-01,  ..., -1.4759e-01,\n",
            "            4.9201e-03, -6.4118e-02],\n",
            "          [ 7.9868e-02, -6.2985e-01, -9.7213e-01,  ...,  3.8105e-02,\n",
            "            2.7713e-01, -2.9170e-01],\n",
            "          [ 4.5712e-01, -2.8448e+00,  5.1033e-01,  ...,  3.5953e-01,\n",
            "            8.6925e-02,  7.9233e-02],\n",
            "          ...,\n",
            "          [ 3.2507e-01, -6.2003e-01, -4.6712e-01,  ..., -1.5512e-01,\n",
            "            1.8403e-01, -8.1765e-01],\n",
            "          [ 3.9692e-02, -7.3899e-01,  3.1652e-01,  ..., -8.8724e-01,\n",
            "            3.8629e-02, -3.4224e-02],\n",
            "          [-1.9015e-01,  5.2642e-01, -1.8994e-01,  ...,  6.2512e-01,\n",
            "            4.4939e-01, -3.4223e-01]],\n",
            "\n",
            "         [[ 1.0424e+00, -3.4866e-01,  1.9752e-01,  ..., -3.9938e-02,\n",
            "            1.4762e-02,  9.3913e-02],\n",
            "          [-2.0960e-01,  5.0965e-01,  2.5132e-01,  ...,  4.0456e-01,\n",
            "            7.3484e-02,  2.0273e-01],\n",
            "          [-7.5867e-01, -8.4571e-01,  2.2492e+00,  ...,  2.6036e-02,\n",
            "           -1.3345e-01,  4.9064e-02],\n",
            "          ...,\n",
            "          [-4.5550e-02,  3.4319e-01, -1.8296e-01,  ...,  4.4091e-01,\n",
            "            1.5088e-01, -4.7540e-02],\n",
            "          [-1.3952e-01, -2.9477e-01,  7.9611e-01,  ...,  1.0544e-01,\n",
            "            9.5899e-01,  3.2750e-01],\n",
            "          [-4.7111e-02,  3.9286e-01,  1.9094e-01,  ..., -1.3829e-02,\n",
            "           -3.7933e-01, -2.9196e-01]],\n",
            "\n",
            "         [[ 9.4970e-01,  1.3118e+00,  5.0034e-02,  ...,  4.2662e-02,\n",
            "           -1.3044e-01,  1.1143e-01],\n",
            "          [ 7.9217e-01,  7.3854e-01, -1.0774e+00,  ...,  1.0416e-01,\n",
            "            1.7758e-01, -2.4151e-01],\n",
            "          [-2.8680e-01,  1.5550e+00,  1.0331e+00,  ..., -1.6838e-01,\n",
            "           -3.4288e-01, -1.0864e-01],\n",
            "          ...,\n",
            "          [-4.9009e-03,  4.5392e-01, -7.7835e-02,  ...,  1.3162e-01,\n",
            "           -4.2734e-01,  1.0306e-01],\n",
            "          [ 2.5816e-01,  8.4326e-01,  6.7643e-01,  ...,  6.0811e-01,\n",
            "            2.5502e-01,  5.7364e-01],\n",
            "          [-7.2056e-02,  9.1684e-01,  4.6573e-02,  ...,  6.5188e-01,\n",
            "           -1.2555e-01, -9.7381e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-3.2525e-01, -1.3205e+00, -1.2755e+00,  ...,  2.4807e-01,\n",
            "            5.2997e-01,  7.4927e-01],\n",
            "          [ 2.4797e-01, -1.2652e+00,  2.8232e-01,  ..., -1.6607e+00,\n",
            "            8.4967e-02,  1.3161e-01],\n",
            "          [-7.6362e-01,  1.1231e+00,  5.2770e-01,  ..., -3.2625e-01,\n",
            "           -4.2724e-01, -9.6872e-01],\n",
            "          ...,\n",
            "          [-6.7118e-01, -4.9200e-01, -6.4936e-01,  ...,  3.7486e-03,\n",
            "            1.1725e-01,  1.4842e-01],\n",
            "          [ 1.6576e-02,  6.9757e-01,  3.7234e-01,  ...,  3.7607e-02,\n",
            "            4.8431e-02, -8.1291e-02],\n",
            "          [ 3.7333e-02,  9.8954e-01,  5.6903e-01,  ...,  6.2837e-02,\n",
            "            1.1370e-01,  1.8995e-01]],\n",
            "\n",
            "         [[ 1.0094e+00,  3.0210e-01,  7.7557e-01,  ...,  1.5749e-01,\n",
            "           -1.4204e-02, -2.6365e-01],\n",
            "          [ 2.2104e+00, -2.9824e-01,  1.7240e+00,  ..., -4.3816e-01,\n",
            "            2.0031e-01, -2.2116e-01],\n",
            "          [-7.6265e-01,  1.7724e-01, -2.8764e-01,  ..., -6.1665e-01,\n",
            "           -1.9949e-02, -9.2907e-02],\n",
            "          ...,\n",
            "          [ 3.6457e+00,  1.5206e+00,  2.3800e+00,  ..., -3.6675e-02,\n",
            "           -1.0377e-01,  9.6674e-02],\n",
            "          [-3.9800e-01,  1.2697e+00, -9.0272e-01,  ..., -8.8660e-02,\n",
            "            4.1665e-02,  3.9164e-03],\n",
            "          [-1.0087e+00, -4.0662e+00,  3.7668e-01,  ...,  3.2285e-01,\n",
            "            9.5433e-02,  1.7892e-01]],\n",
            "\n",
            "         [[ 1.1856e+00,  3.2342e-02,  1.8419e-01,  ...,  1.0942e-01,\n",
            "           -2.0446e-01,  6.1938e-01],\n",
            "          [ 1.3591e-01,  1.0618e+00,  1.5494e-01,  ..., -2.3547e-01,\n",
            "            1.7397e-01,  1.2282e-01],\n",
            "          [-1.0425e+00, -1.2307e+00,  5.4292e-01,  ...,  4.1987e-01,\n",
            "           -9.3446e-03,  5.2165e-02],\n",
            "          ...,\n",
            "          [ 2.3024e-02,  2.0441e+00,  6.6458e-01,  ...,  3.5320e-02,\n",
            "            3.5874e-02,  4.5312e-03],\n",
            "          [-1.1038e+00, -3.2848e+00,  9.1408e-01,  ...,  2.3465e-01,\n",
            "           -6.6075e-03,  1.3733e-01],\n",
            "          [-1.3869e-01,  1.3349e+00, -1.4802e+00,  ..., -1.3268e-01,\n",
            "            2.3465e-02, -1.4053e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.4547e-01, -2.4419e-01, -7.5359e-01,  ...,  2.7622e-02,\n",
            "           -3.8990e-01,  1.4372e-01],\n",
            "          [-1.3323e+00,  1.4218e+00,  3.4155e-01,  ..., -1.5158e-01,\n",
            "            5.7528e-01,  1.5711e-01],\n",
            "          [ 4.8161e-01,  6.4575e-01,  1.4107e-01,  ...,  3.4470e-01,\n",
            "            1.9692e-01, -6.9882e-02],\n",
            "          ...,\n",
            "          [-7.8801e-01,  2.2538e+00,  3.1073e-01,  ..., -1.4914e-01,\n",
            "            3.1352e-03, -1.5240e-01],\n",
            "          [ 5.2729e-01, -9.3069e-01, -4.2545e-02,  ...,  6.1828e-02,\n",
            "           -3.7000e-02, -9.5228e-03],\n",
            "          [-6.7677e-01,  1.4021e+00, -1.3790e+00,  ..., -2.9705e-01,\n",
            "            6.9533e-02, -4.2265e-02]],\n",
            "\n",
            "         [[ 5.6348e-01,  8.4069e-01, -3.2759e-01,  ..., -1.9871e-02,\n",
            "            8.7300e-02, -3.8970e-01],\n",
            "          [-2.7273e+00, -3.6665e+00,  5.9811e-01,  ...,  2.0991e+00,\n",
            "            8.0396e-01,  8.4201e-01],\n",
            "          [-4.1463e-01,  7.5279e-01, -6.6731e-01,  ..., -5.1014e-02,\n",
            "           -7.9039e-02,  7.1014e-01],\n",
            "          ...,\n",
            "          [-2.7530e+00, -6.0605e+00,  4.2361e-01,  ...,  4.6750e-01,\n",
            "            1.2225e-01,  2.1997e-01],\n",
            "          [-9.4924e-01,  1.4600e+00, -1.8439e+00,  ..., -1.9630e-02,\n",
            "            1.0364e-01,  7.3745e-02],\n",
            "          [-3.1480e-01, -3.6078e-01,  1.6672e+00,  ...,  2.3966e-01,\n",
            "           -7.7990e-02, -2.2806e-02]],\n",
            "\n",
            "         [[-4.6717e-01, -6.3158e-01, -5.1705e-01,  ...,  8.1779e-01,\n",
            "            2.5863e-01, -3.8968e-01],\n",
            "          [ 1.6032e+00, -8.8104e-01, -4.0122e-02,  ...,  9.5113e-01,\n",
            "           -2.0350e-01, -3.5436e-01],\n",
            "          [ 5.3730e-01,  7.7565e-02,  1.1883e-01,  ..., -3.5291e-02,\n",
            "           -2.1861e-01,  1.0556e-01],\n",
            "          ...,\n",
            "          [ 8.5782e-01, -2.4282e+00,  1.4965e+00,  ...,  2.0914e-01,\n",
            "           -9.8977e-02, -2.2936e-02],\n",
            "          [ 1.4901e-02,  9.7492e-01,  1.8482e-01,  ..., -9.3971e-02,\n",
            "           -9.7211e-02, -1.3132e-01],\n",
            "          [ 1.6594e-01,  1.3184e+00,  9.2339e-02,  ..., -1.4091e-01,\n",
            "           -6.7028e-02, -4.2591e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 0.0286,  0.1995,  0.5797,  ...,  0.1207,  0.0477, -0.0453],\n",
            "          [-0.4596,  0.0346,  0.6486,  ...,  0.4594,  0.3340, -0.1453],\n",
            "          [ 0.3793,  0.0622, -0.1527,  ..., -0.2236, -0.0300,  0.1630],\n",
            "          ...,\n",
            "          [ 0.1567, -0.2894, -0.0739,  ...,  0.2380,  0.0357,  0.0383],\n",
            "          [-0.2799, -0.0307,  0.1443,  ..., -0.0935,  0.0303,  0.0483],\n",
            "          [ 0.5275,  0.5770,  0.6598,  ..., -0.1467,  0.0179,  0.0627]],\n",
            "\n",
            "         [[-0.2123, -0.0603, -0.2834,  ...,  0.0720, -0.2020,  0.0320],\n",
            "          [-0.2131, -0.1487, -0.8475,  ..., -0.1253,  0.0302,  0.2554],\n",
            "          [ 0.5062,  0.5103, -0.3410,  ...,  0.2971,  0.0021,  0.0360],\n",
            "          ...,\n",
            "          [ 0.1209,  0.6884, -0.7558,  ..., -0.1246,  0.0822,  0.0872],\n",
            "          [ 0.0812,  0.1435,  0.0762,  ...,  0.0168,  0.0268,  0.0158],\n",
            "          [ 0.2736, -0.3691,  0.1150,  ...,  0.0844,  0.0496,  0.0268]],\n",
            "\n",
            "         [[ 0.5994,  0.4242,  0.9270,  ..., -0.0455, -0.0502, -0.1225],\n",
            "          [ 0.8676,  0.7987, -0.0163,  ...,  0.3608, -0.0923, -0.0946],\n",
            "          [ 0.1987, -0.0862,  0.2138,  ..., -0.3258, -0.0459,  0.1198],\n",
            "          ...,\n",
            "          [ 0.1633, -0.2796,  0.2518,  ...,  0.0446, -0.0917, -0.1532],\n",
            "          [ 0.5468, -0.1281, -0.4695,  ...,  0.0555, -0.0134,  0.1086],\n",
            "          [-0.1956,  0.3646,  0.1017,  ..., -0.0046, -0.0397,  0.1189]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.6547, -0.3131, -0.4795,  ..., -0.0379, -0.1430, -0.0728],\n",
            "          [ 0.6640, -1.1888, -0.0811,  ..., -0.4762, -0.2970,  0.3144],\n",
            "          [-0.3985,  0.6679, -0.3973,  ...,  0.1039,  0.0460, -0.0417],\n",
            "          ...,\n",
            "          [ 0.0934, -0.2904,  0.1844,  ...,  0.0674, -0.1301,  0.1924],\n",
            "          [-0.0632,  0.5939, -0.6818,  ...,  0.0463,  0.0282,  0.0162],\n",
            "          [ 0.3149, -0.4056, -0.7014,  ..., -0.0482,  0.0418, -0.0774]],\n",
            "\n",
            "         [[-0.0689,  0.0051, -0.1863,  ..., -0.1807,  0.0886, -0.1483],\n",
            "          [ 0.1147, -0.1320,  0.3273,  ...,  0.2427, -0.0299,  0.0246],\n",
            "          [-0.2205, -0.5766,  0.6567,  ..., -0.3061,  0.0626,  0.2134],\n",
            "          ...,\n",
            "          [ 0.0709,  0.4269,  0.5116,  ...,  0.0032,  0.1372,  0.0968],\n",
            "          [ 0.2851, -0.2027,  0.2622,  ...,  0.1039, -0.0319,  0.1033],\n",
            "          [ 0.1939,  0.4709, -0.0539,  ..., -0.1202,  0.0888, -0.0300]],\n",
            "\n",
            "         [[-0.2055, -1.1719,  0.3413,  ..., -0.1400, -0.0495, -0.0403],\n",
            "          [-0.9316, -0.6727,  1.2745,  ..., -0.0956,  0.1059,  0.0294],\n",
            "          [ 0.3840,  0.2826, -0.2269,  ...,  0.0969,  0.0336,  0.2178],\n",
            "          ...,\n",
            "          [ 0.1439,  0.4479,  0.7856,  ..., -0.1846,  0.0143, -0.0528],\n",
            "          [ 0.1665,  0.4020, -0.1040,  ...,  0.0341,  0.1188,  0.1094],\n",
            "          [ 0.3815, -0.4566,  0.2280,  ...,  0.0830,  0.1020,  0.0950]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 0.2747,  0.2356,  0.0529,  ..., -0.4212, -0.6659, -0.1782],\n",
            "          [ 0.4603,  0.3842, -0.0626,  ..., -0.1981,  0.0139,  0.0668],\n",
            "          [-0.0395, -0.0724, -0.0090,  ...,  0.5357,  0.2425, -0.0254],\n",
            "          ...,\n",
            "          [ 0.2481, -0.2878,  0.4156,  ..., -0.0777,  0.0242,  0.0332],\n",
            "          [ 0.0378,  0.1664,  0.0913,  ...,  0.0552,  0.0186,  0.0444],\n",
            "          [ 0.0447, -0.2446, -0.2499,  ..., -0.0535,  0.0814,  0.0498]],\n",
            "\n",
            "         [[-0.0645, -0.0902,  0.0450,  ..., -0.0280,  0.2172, -0.5914],\n",
            "          [ 0.4189, -0.1318,  0.4222,  ...,  0.9432, -0.2354,  0.1847],\n",
            "          [-0.0361, -0.4959,  0.0808,  ...,  0.4266, -0.9444,  0.0311],\n",
            "          ...,\n",
            "          [ 0.1322, -0.6228,  0.2066,  ..., -0.1869, -0.0162,  0.1230],\n",
            "          [ 0.0267,  0.6794,  0.4046,  ...,  0.1482,  0.0642,  0.1095],\n",
            "          [-0.0603,  0.4730, -0.2809,  ...,  0.0856,  0.0419,  0.0736]],\n",
            "\n",
            "         [[-0.2403,  0.1466,  0.0092,  ..., -0.3813,  0.1098, -0.6392],\n",
            "          [-0.3377,  0.2455, -0.0121,  ..., -0.1967,  0.2803,  0.0461],\n",
            "          [ 0.1854, -0.0243,  0.1869,  ..., -0.1376,  0.3202,  0.1866],\n",
            "          ...,\n",
            "          [-0.3415, -0.5665, -0.5791,  ..., -0.1069, -0.0252, -0.0322],\n",
            "          [ 0.1003,  0.0995, -0.2246,  ...,  0.0940, -0.1362,  0.0638],\n",
            "          [ 0.0345, -0.0402, -0.0035,  ..., -0.0334, -0.0625, -0.0450]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0183,  0.1075,  0.1435,  ..., -0.8651,  0.2215, -0.4020],\n",
            "          [ 0.0330,  0.0410, -0.4428,  ...,  0.0896,  1.0715, -0.6601],\n",
            "          [ 0.2055, -0.3982, -0.1441,  ...,  1.1490, -0.1680,  0.4298],\n",
            "          ...,\n",
            "          [ 0.2717,  0.4292, -0.4153,  ...,  0.0906,  0.0643,  0.0032],\n",
            "          [ 0.0048, -0.1626, -0.2333,  ...,  0.0755, -0.0138,  0.0773],\n",
            "          [ 0.0580, -0.3151, -0.2869,  ..., -0.0596, -0.0047, -0.0443]],\n",
            "\n",
            "         [[ 0.2485, -0.2685,  0.2625,  ...,  0.5933,  0.1012,  0.4550],\n",
            "          [ 0.0753, -0.0428,  0.4250,  ...,  1.2549, -0.6289,  0.0688],\n",
            "          [ 0.1393,  0.3638, -0.0358,  ..., -0.6918, -0.0306, -0.0502],\n",
            "          ...,\n",
            "          [ 0.1729, -0.2592,  0.2905,  ...,  0.1173,  0.1524,  0.1153],\n",
            "          [ 0.1075,  0.5539, -0.3944,  ...,  0.1672,  0.0839,  0.0988],\n",
            "          [ 0.2338, -0.4572,  0.5974,  ..., -0.0386,  0.0876,  0.1054]],\n",
            "\n",
            "         [[-0.2468,  0.2378, -0.2564,  ..., -0.5507,  0.6170, -0.3362],\n",
            "          [-0.2706, -0.3583,  0.0201,  ..., -0.5406,  0.0102, -0.1383],\n",
            "          [-0.0317,  0.2256,  0.0890,  ...,  0.1786,  0.0861,  0.0383],\n",
            "          ...,\n",
            "          [-0.4741,  0.0715, -0.4850,  ..., -0.0147, -0.0898,  0.0189],\n",
            "          [ 0.2380, -0.4068,  0.5253,  ..., -0.1376,  0.0956, -0.0473],\n",
            "          [-0.1474, -0.0984, -0.0459,  ..., -0.0373, -0.0554,  0.0674]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-8.2344e-02,  2.1290e-02, -1.1828e-01,  ..., -5.1188e-01,\n",
            "            2.1297e-01,  5.5672e-01],\n",
            "          [ 2.2324e-01,  2.1714e-01,  5.3103e-02,  ..., -1.1826e-01,\n",
            "           -1.6012e-01,  4.5196e-01],\n",
            "          [ 1.2424e-01, -1.3289e-01,  2.5388e-01,  ...,  3.0291e-01,\n",
            "            2.1360e-01,  1.8940e-01],\n",
            "          ...,\n",
            "          [ 4.2303e-02, -3.6578e-02, -1.3988e-02,  ...,  1.2085e-01,\n",
            "            7.4995e-04, -2.8539e-02],\n",
            "          [ 3.3737e-02, -1.2349e-01, -6.6899e-02,  ...,  5.3514e-02,\n",
            "           -1.2038e-01, -3.7952e-02],\n",
            "          [-1.1513e-01, -3.9241e-02, -1.1031e-01,  ...,  5.5204e-02,\n",
            "            4.0059e-04, -2.3087e-02]],\n",
            "\n",
            "         [[-7.9077e-02, -3.8323e-01,  1.2047e-01,  ...,  5.3971e-01,\n",
            "           -5.4538e-02, -2.2262e-01],\n",
            "          [-7.8794e-02,  4.9509e-02, -8.1037e-02,  ..., -5.7985e-01,\n",
            "            7.4011e-02, -8.4052e-03],\n",
            "          [-4.1206e-01, -7.0195e-02, -2.7288e-01,  ...,  5.9718e-01,\n",
            "            4.6383e-03,  1.2606e-01],\n",
            "          ...,\n",
            "          [-9.8552e-02, -2.7674e-01, -3.9355e-02,  ..., -2.2778e-01,\n",
            "           -2.4489e-02, -2.3767e-01],\n",
            "          [-1.3164e-01, -1.3592e-01, -8.4591e-02,  ...,  2.3068e-03,\n",
            "           -8.5282e-02, -7.0799e-02],\n",
            "          [-5.5661e-02, -1.3591e-01, -1.6671e-01,  ..., -1.2453e-01,\n",
            "           -2.9334e-02, -5.3640e-02]],\n",
            "\n",
            "         [[ 1.7040e-01,  1.1754e-01, -2.5162e-01,  ...,  4.5405e-01,\n",
            "            2.3018e-01, -1.2558e-01],\n",
            "          [ 1.6175e-02,  3.0619e-01,  1.8585e-01,  ..., -5.9536e-01,\n",
            "           -2.7822e-01, -2.7987e-01],\n",
            "          [ 9.0492e-02, -2.0841e-01, -9.0733e-02,  ...,  1.9505e-01,\n",
            "            5.8919e-02,  5.4649e-03],\n",
            "          ...,\n",
            "          [ 3.6941e-03,  1.8226e-01,  3.8233e-02,  ...,  4.0345e-02,\n",
            "            3.7052e-02, -1.7256e-04],\n",
            "          [-2.5754e-02,  8.5393e-02, -7.8033e-02,  ..., -1.5428e-02,\n",
            "           -1.2670e-01, -5.1736e-02],\n",
            "          [-8.8320e-02,  6.3965e-02, -6.6541e-02,  ...,  8.1983e-02,\n",
            "            6.3886e-02,  9.0297e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3331e-01, -1.7736e-01, -2.7249e-01,  ...,  2.7174e-01,\n",
            "            2.8833e-01, -2.4938e-01],\n",
            "          [-2.0327e-01, -6.9502e-01, -8.1984e-01,  ...,  6.3892e-01,\n",
            "            2.8632e-01, -1.8277e-01],\n",
            "          [ 1.2724e-01, -3.8036e-01, -8.0814e-02,  ...,  3.0365e-01,\n",
            "            2.9306e-01, -1.2819e-01],\n",
            "          ...,\n",
            "          [-1.1766e-01, -1.1507e-01, -1.4451e-01,  ...,  2.5824e-01,\n",
            "           -2.4426e-02, -8.5776e-02],\n",
            "          [-2.4709e-02,  8.8123e-02, -5.8455e-02,  ..., -5.3486e-02,\n",
            "           -1.3827e-01, -6.6166e-02],\n",
            "          [-7.7547e-02, -8.6173e-03, -3.5443e-02,  ..., -2.5630e-01,\n",
            "           -8.9007e-02, -4.4201e-02]],\n",
            "\n",
            "         [[-2.0072e-01,  1.2038e-01,  2.0724e-01,  ..., -2.7925e-01,\n",
            "           -1.6236e-01, -1.1697e-01],\n",
            "          [ 2.8936e-02,  8.4547e-01,  2.1797e-01,  ..., -7.3373e-01,\n",
            "            2.1548e-01,  5.6812e-02],\n",
            "          [-9.9616e-02,  8.7132e-01,  4.8618e-01,  ..., -4.8915e-01,\n",
            "           -2.8524e-01, -2.2376e-01],\n",
            "          ...,\n",
            "          [ 4.8688e-02,  3.1875e-01, -1.5903e-01,  ...,  7.9721e-02,\n",
            "           -4.5315e-02, -4.9623e-02],\n",
            "          [ 1.6045e-02,  3.0456e-01,  1.7580e-01,  ..., -8.7716e-03,\n",
            "            4.6720e-02,  2.7750e-03],\n",
            "          [ 1.7708e-02,  3.2215e-02,  3.9187e-02,  ..., -7.8131e-02,\n",
            "           -1.3953e-02, -8.3906e-02]],\n",
            "\n",
            "         [[-7.3900e-02,  1.6041e-01, -1.2912e-02,  ..., -1.7183e-01,\n",
            "           -1.2266e-01, -1.5863e-01],\n",
            "          [-2.4064e-01,  3.9899e-01, -2.6595e-01,  ..., -4.7998e-01,\n",
            "            5.8544e-01, -4.7705e-01],\n",
            "          [ 9.0635e-02, -1.1559e-01,  3.6856e-01,  ..., -2.8905e-01,\n",
            "           -1.3878e-01, -6.0510e-01],\n",
            "          ...,\n",
            "          [-1.0487e-01,  8.8932e-02, -4.7803e-02,  ..., -2.5977e-01,\n",
            "           -8.3834e-02, -4.0024e-02],\n",
            "          [-2.4671e-02, -7.5656e-02,  1.5133e-01,  ..., -2.0891e-01,\n",
            "            2.0043e-02, -4.8847e-02],\n",
            "          [ 8.9634e-03, -9.2002e-02, -8.4977e-02,  ..., -2.0913e-02,\n",
            "           -9.2758e-02, -1.3402e-01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 1.4770e-02, -2.2509e-02, -1.4485e-01,  ...,  7.4534e-03,\n",
            "            4.6303e-02, -1.4561e-01],\n",
            "          [-1.4214e-01,  7.7087e-02,  4.2630e-03,  ...,  1.0960e-01,\n",
            "           -4.1736e-01, -1.8416e-01],\n",
            "          [ 1.8793e-01, -2.0265e-01, -1.0618e-01,  ..., -2.0749e-01,\n",
            "           -1.9809e-01,  4.1791e-03],\n",
            "          ...,\n",
            "          [-3.6401e-01,  9.8374e-02,  2.0105e-01,  ...,  1.1630e-01,\n",
            "            1.6020e-01,  4.0815e-02],\n",
            "          [ 2.6967e-01, -1.7464e-01,  7.6784e-02,  ..., -4.6102e-03,\n",
            "            1.1186e-02, -4.2174e-02],\n",
            "          [ 1.1574e-01,  2.1863e-01,  2.1507e-01,  ..., -1.2392e-01,\n",
            "           -1.7727e-01,  7.3238e-02]],\n",
            "\n",
            "         [[-3.6199e-02, -1.9098e-01, -1.9173e-01,  ...,  1.4639e-01,\n",
            "            8.6989e-02, -8.2768e-02],\n",
            "          [-7.2786e-02, -1.0487e-01,  1.5178e-01,  ...,  4.1407e-01,\n",
            "            5.6791e-02, -1.8778e-01],\n",
            "          [ 5.8254e-02,  3.7076e-02, -2.8079e-02,  ...,  1.2654e-01,\n",
            "           -5.4139e-02, -1.6627e-01],\n",
            "          ...,\n",
            "          [ 7.3166e-02, -9.0560e-02,  9.3175e-02,  ..., -3.8119e-02,\n",
            "           -1.5589e-01, -9.0936e-03],\n",
            "          [ 1.4548e-01, -1.5720e-01, -1.0431e-01,  ..., -1.2269e-01,\n",
            "           -8.7756e-02, -5.4425e-02],\n",
            "          [-9.3560e-02, -8.1992e-02,  1.2096e-02,  ..., -1.9631e-01,\n",
            "            1.2746e-02, -2.7467e-02]],\n",
            "\n",
            "         [[ 9.8923e-02,  1.2341e-01, -5.4579e-03,  ..., -8.6474e-02,\n",
            "            1.6502e-01, -7.6537e-02],\n",
            "          [ 2.4598e-01,  3.1331e-01, -1.3702e-01,  ...,  2.9859e-02,\n",
            "            8.9458e-02, -1.9335e-01],\n",
            "          [ 1.7519e-01,  1.4898e-01, -3.3066e-02,  ...,  3.0081e-01,\n",
            "           -5.1656e-02, -7.4333e-02],\n",
            "          ...,\n",
            "          [ 1.5265e-01,  4.8490e-01, -3.6048e-01,  ...,  1.4818e-01,\n",
            "            8.3081e-02,  1.2737e-01],\n",
            "          [ 2.6154e-01,  7.4991e-02, -5.0640e-02,  ..., -3.6142e-03,\n",
            "            9.5477e-02,  1.1494e-01],\n",
            "          [ 1.2784e-02,  3.3203e-01, -2.2168e-01,  ...,  1.1703e-01,\n",
            "            8.9007e-02,  1.6143e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0597e-01, -9.7624e-02, -6.6352e-02,  ..., -1.6744e-01,\n",
            "            5.2822e-02, -1.3224e-01],\n",
            "          [-5.7283e-02,  2.7011e-02, -1.5380e-01,  ...,  1.7332e-01,\n",
            "           -2.1496e-01, -4.6523e-03],\n",
            "          [ 7.3890e-02, -7.8065e-02, -3.9008e-03,  ..., -3.1126e-01,\n",
            "           -6.1262e-02,  2.8023e-02],\n",
            "          ...,\n",
            "          [-2.3104e-02,  4.6584e-03, -1.2445e-01,  ..., -1.9680e-01,\n",
            "            4.2298e-02, -8.8079e-03],\n",
            "          [ 2.4828e-01,  2.5578e-01,  1.0651e-01,  ..., -1.0719e-02,\n",
            "           -2.7635e-02, -1.2218e-01],\n",
            "          [ 1.3261e-01, -1.3468e-01,  8.2505e-02,  ...,  1.3988e-01,\n",
            "           -6.1393e-02,  2.1020e-02]],\n",
            "\n",
            "         [[ 2.2666e-01, -1.6668e-01,  1.7260e-01,  ...,  3.6771e-01,\n",
            "            2.6011e-02,  8.8354e-02],\n",
            "          [-6.2480e-02, -1.4092e-01, -6.4401e-02,  ...,  9.0683e-02,\n",
            "           -1.5322e-05, -2.1818e-01],\n",
            "          [-5.3041e-03,  1.3319e-01,  1.5808e-02,  ..., -1.0988e-01,\n",
            "           -5.6206e-02, -8.5515e-02],\n",
            "          ...,\n",
            "          [-9.2194e-02,  7.6798e-03, -1.7533e-02,  ...,  1.0120e-01,\n",
            "            4.0652e-02,  1.5593e-01],\n",
            "          [-1.7782e-01,  1.5122e-01,  1.2007e-01,  ..., -1.1250e-01,\n",
            "            1.2758e-01, -6.3596e-02],\n",
            "          [ 6.4365e-02,  2.4324e-01,  1.7775e-01,  ...,  5.9156e-03,\n",
            "           -8.6726e-02,  8.7312e-02]],\n",
            "\n",
            "         [[ 5.2671e-04, -5.9863e-02, -1.8659e-01,  ..., -7.6785e-02,\n",
            "            2.7973e-01, -5.1709e-02],\n",
            "          [ 1.8457e-01, -2.7387e-01, -1.9035e-01,  ..., -2.2548e-01,\n",
            "           -1.9696e-04,  1.4741e-02],\n",
            "          [-8.4971e-03, -1.8648e-01, -5.1463e-02,  ..., -2.0439e-01,\n",
            "           -3.3531e-02,  1.5973e-01],\n",
            "          ...,\n",
            "          [ 3.4827e-01, -4.5226e-01, -2.2361e-01,  ...,  1.5601e-02,\n",
            "           -1.4665e-02,  2.0024e-02],\n",
            "          [ 1.0520e-01,  3.7424e-02, -9.4057e-02,  ..., -1.6549e-02,\n",
            "           -6.6614e-02, -1.0151e-01],\n",
            "          [-4.8595e-02, -8.1966e-02, -5.1104e-02,  ...,  1.4386e-01,\n",
            "           -6.5339e-02,  7.7286e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-0.0234, -0.1012,  0.0983,  ...,  0.0782, -0.1314,  0.0513],\n",
            "          [-0.2524,  0.6837,  0.4543,  ..., -0.0429, -0.3743,  0.0344],\n",
            "          [-0.2023, -0.0905,  0.7066,  ...,  0.3542, -0.0830, -0.0684],\n",
            "          ...,\n",
            "          [-0.5726,  0.3645,  0.7897,  ..., -0.0451, -0.0435,  0.0167],\n",
            "          [-0.1494, -0.3696,  0.5620,  ...,  0.0289, -0.0278, -0.0448],\n",
            "          [-0.4187,  0.2490,  0.4733,  ..., -0.0498, -0.0208, -0.0117]],\n",
            "\n",
            "         [[-0.6443, -0.7380, -0.5632,  ...,  0.4433, -0.1530,  0.0285],\n",
            "          [-0.4036,  0.8202, -0.1050,  ..., -0.6528,  0.0639,  0.2897],\n",
            "          [ 0.3715, -0.2985, -0.3388,  ..., -0.4828, -0.3821,  0.1893],\n",
            "          ...,\n",
            "          [-0.3492,  0.2177, -0.0056,  ..., -0.0536,  0.0657,  0.0796],\n",
            "          [ 0.1566, -0.1667,  0.2826,  ...,  0.0456,  0.0443,  0.0413],\n",
            "          [-0.0496,  0.0935,  0.3361,  ...,  0.0086,  0.0561,  0.0289]],\n",
            "\n",
            "         [[-0.0639, -0.3905,  0.5233,  ...,  0.2132, -0.0268,  0.0116],\n",
            "          [ 0.8780,  0.6057,  0.0179,  ...,  0.7466, -0.4661,  0.2024],\n",
            "          [-0.2712, -0.2403,  0.2179,  ...,  0.4673, -0.2567, -0.1329],\n",
            "          ...,\n",
            "          [ 0.8849, -0.0935, -0.0231,  ...,  0.0867,  0.0165,  0.0804],\n",
            "          [-0.3371, -0.2040,  0.4419,  ...,  0.0710,  0.0043,  0.0216],\n",
            "          [ 0.2643, -1.2609,  0.1938,  ...,  0.0621,  0.0474,  0.0312]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0051,  0.3238,  0.0156,  ...,  0.1279, -0.1605, -0.0654],\n",
            "          [-0.2444,  1.1067,  0.1303,  ..., -0.0926,  0.2835,  0.1385],\n",
            "          [ 0.2980,  0.6073, -0.2561,  ..., -0.3126, -0.2299,  0.1109],\n",
            "          ...,\n",
            "          [-0.0596,  0.9425,  0.2189,  ...,  0.0182,  0.0856,  0.1011],\n",
            "          [ 0.2318,  0.3042,  0.2678,  ...,  0.0404,  0.0507,  0.1104],\n",
            "          [ 0.4757,  0.2554, -0.3467,  ...,  0.0435,  0.1056,  0.1105]],\n",
            "\n",
            "         [[ 0.1168,  0.7643,  0.1626,  ..., -0.8330,  0.0190,  0.3455],\n",
            "          [ 0.2848, -0.5204,  0.0092,  ..., -0.2394,  0.1745,  0.5572],\n",
            "          [-0.4287,  0.4432,  0.0549,  ...,  0.2857, -0.1350, -0.0582],\n",
            "          ...,\n",
            "          [ 0.3440, -0.3447,  0.1344,  ..., -0.0246,  0.0203,  0.0355],\n",
            "          [-0.2623,  0.5825,  0.2103,  ..., -0.0704, -0.0597,  0.0195],\n",
            "          [-0.2382,  0.2459,  0.2684,  ...,  0.0047, -0.0138, -0.0444]],\n",
            "\n",
            "         [[ 0.0571, -0.5494,  1.4174,  ...,  0.4877, -0.3953, -0.0355],\n",
            "          [ 0.5064,  0.1941,  0.3710,  ...,  0.2756, -0.2160,  0.4612],\n",
            "          [-0.1067,  0.0345,  0.8337,  ...,  0.2385, -0.1769,  0.0561],\n",
            "          ...,\n",
            "          [ 0.6486,  0.2334,  0.1146,  ...,  0.1327,  0.0437,  0.0838],\n",
            "          [-0.4087, -0.2887,  0.5632,  ...,  0.1111, -0.0093,  0.0531],\n",
            "          [ 0.0517, -0.3147,  0.2945,  ...,  0.1053,  0.0986,  0.0630]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 0.0941, -0.0810,  0.0350,  ..., -0.2457, -0.1790,  0.1178],\n",
            "          [ 0.2744, -0.4544,  0.1710,  ..., -0.7000,  0.1401,  0.3735],\n",
            "          [ 0.2260,  0.1846, -0.0205,  ...,  0.1380, -0.2695,  0.0983],\n",
            "          ...,\n",
            "          [ 0.2428, -0.7135,  0.2015,  ..., -0.0898,  0.0442,  0.0744],\n",
            "          [ 0.1598,  0.2849, -0.0038,  ...,  0.0147, -0.0333,  0.0054],\n",
            "          [ 0.1184, -0.0096,  0.5115,  ...,  0.0203,  0.0412, -0.0311]],\n",
            "\n",
            "         [[ 0.0999,  0.3426, -0.0855,  ...,  0.3783, -0.1822, -0.0236],\n",
            "          [ 0.3089,  0.1581,  0.0272,  ...,  0.8368, -0.3643, -0.0374],\n",
            "          [-0.1076,  0.8706,  0.3114,  ...,  0.3106, -0.1492,  0.0012],\n",
            "          ...,\n",
            "          [ 0.2898,  0.0031, -0.3239,  ...,  0.0624, -0.0849,  0.0249],\n",
            "          [-0.0783,  0.4374, -0.0362,  ...,  0.0445, -0.0033, -0.0036],\n",
            "          [ 0.0216,  0.2985,  0.0177,  ...,  0.0337,  0.0111, -0.0584]],\n",
            "\n",
            "         [[-0.2951, -0.2915,  0.2671,  ...,  0.0237,  0.1467, -0.1212],\n",
            "          [ 0.5068, -0.7974,  0.4433,  ..., -0.1775,  0.1380, -0.5038],\n",
            "          [ 0.2715, -0.8789, -0.0382,  ...,  0.0384, -0.0074, -0.1562],\n",
            "          ...,\n",
            "          [ 0.3525, -0.4412, -0.0553,  ..., -0.0601,  0.0267, -0.0461],\n",
            "          [ 0.0337, -0.3764,  0.0218,  ...,  0.0074,  0.0239, -0.0024],\n",
            "          [ 0.1480, -0.4360, -0.1460,  ...,  0.0216,  0.0170,  0.0514]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0731,  0.1871, -0.0052,  ..., -0.1605, -0.0247, -0.0953],\n",
            "          [ 0.1495,  0.1394, -0.1107,  ...,  0.2416,  0.3893, -0.6365],\n",
            "          [-0.2492,  0.3119,  0.0813,  ..., -0.0069, -0.3152, -0.3648],\n",
            "          ...,\n",
            "          [ 0.1513,  0.2653, -0.2088,  ..., -0.0500, -0.0486, -0.0721],\n",
            "          [-0.1013,  0.0933, -0.0818,  ...,  0.0040, -0.0171, -0.0453],\n",
            "          [-0.1919, -0.0380,  0.1610,  ..., -0.0466,  0.0329, -0.0158]],\n",
            "\n",
            "         [[-0.0580,  0.2086,  0.3186,  ...,  0.4072,  0.1529, -0.2242],\n",
            "          [ 0.2455, -0.3098, -0.1857,  ..., -0.0808,  0.1134,  0.0804],\n",
            "          [ 0.0231, -0.0972,  0.2185,  ...,  0.2157,  0.2079,  0.0037],\n",
            "          ...,\n",
            "          [ 0.1315, -0.0919,  0.0330,  ...,  0.0296,  0.0167,  0.0429],\n",
            "          [-0.0372,  0.0880,  0.3785,  ...,  0.0154,  0.0352,  0.0098],\n",
            "          [-0.0574,  0.1749,  0.0375,  ..., -0.0167, -0.0018,  0.0045]],\n",
            "\n",
            "         [[ 0.0157,  0.1048,  0.0315,  ..., -0.1065,  0.1198,  0.1514],\n",
            "          [-0.5217, -0.3116,  0.2534,  ...,  0.4702,  0.3501, -0.2708],\n",
            "          [ 0.1441,  0.3314,  0.1047,  ..., -0.2948,  0.2692,  0.3696],\n",
            "          ...,\n",
            "          [-0.3496, -0.1210,  0.3680,  ...,  0.0491,  0.1237,  0.1256],\n",
            "          [ 0.0826,  0.1613,  0.0144,  ...,  0.1006,  0.0792,  0.0838],\n",
            "          [-0.0018,  0.0830,  0.2474,  ...,  0.1062,  0.1078,  0.0873]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 6.0945e-02,  3.7227e-01, -1.4503e-01,  ..., -2.3441e-02,\n",
            "            2.6562e-03,  2.5709e-02],\n",
            "          [-4.9676e-01, -2.5052e-02, -2.2562e-01,  ...,  1.1883e-01,\n",
            "           -1.8110e-02,  3.1305e-02],\n",
            "          [ 2.8126e-01,  4.6108e-01,  3.0629e-01,  ...,  7.0059e-02,\n",
            "            1.6375e-01,  1.0291e-01],\n",
            "          ...,\n",
            "          [-4.9958e-01, -1.4019e-01,  2.9730e-02,  ...,  5.0598e-02,\n",
            "            1.5505e-01,  2.5498e-01],\n",
            "          [ 2.1477e-01,  2.5488e-01,  3.1270e-02,  ...,  1.3606e-02,\n",
            "            2.8018e-02, -7.3867e-02],\n",
            "          [ 1.0078e-01,  1.4048e-01,  5.7390e-02,  ..., -3.9434e-02,\n",
            "            1.7892e-01, -8.1269e-02]],\n",
            "\n",
            "         [[-3.4772e-02,  2.9053e-01,  5.6615e-02,  ...,  3.2184e-02,\n",
            "            1.0775e-02,  9.3914e-03],\n",
            "          [ 1.6834e-01, -3.5610e-01, -2.2236e-01,  ...,  1.4024e-01,\n",
            "           -1.2754e-02,  2.1163e-01],\n",
            "          [ 3.2239e-01, -3.1217e-01,  1.0815e-01,  ...,  6.0403e-02,\n",
            "            1.2190e-01,  7.2472e-02],\n",
            "          ...,\n",
            "          [-1.3713e-01, -5.0373e-01,  4.7963e-02,  ...,  3.4524e-01,\n",
            "           -1.2492e-02,  1.8147e-01],\n",
            "          [ 2.6343e-01,  1.6284e-01, -5.9967e-02,  ..., -1.5512e-02,\n",
            "            1.2598e-01,  1.2696e-01],\n",
            "          [-2.2852e-02,  7.7164e-02, -3.3034e-01,  ...,  1.2113e-03,\n",
            "            2.0676e-01, -1.0398e-01]],\n",
            "\n",
            "         [[-2.5357e-01,  4.0504e-02, -2.4331e-01,  ..., -1.3060e-01,\n",
            "           -7.9034e-02, -7.1764e-02],\n",
            "          [-1.2156e-01,  3.4847e-01, -2.5027e-01,  ..., -1.3105e-01,\n",
            "           -8.0836e-02, -1.9467e-01],\n",
            "          [-4.3492e-01,  2.9964e-01,  3.7902e-01,  ...,  7.9762e-02,\n",
            "            6.4164e-02, -9.2017e-02],\n",
            "          ...,\n",
            "          [-2.3620e-01,  1.6140e-01, -1.8250e-01,  ..., -1.2573e-01,\n",
            "            1.6319e-02, -1.6877e-01],\n",
            "          [-2.2840e-01,  2.2683e-01, -1.2212e-02,  ..., -1.1695e-01,\n",
            "            2.4974e-03, -1.1772e-01],\n",
            "          [-5.4810e-02,  1.6995e-01,  5.0260e-02,  ..., -2.5068e-01,\n",
            "           -5.8707e-02, -8.6095e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8408e-01,  3.1575e-01,  1.9712e-01,  ..., -1.7708e-02,\n",
            "            2.4545e-02, -2.3079e-02],\n",
            "          [-3.9107e-02, -2.7653e-01,  3.2296e-01,  ...,  5.9811e-02,\n",
            "           -4.4522e-02,  7.1059e-02],\n",
            "          [ 3.5022e-01, -5.5544e-01, -9.4285e-02,  ..., -1.9633e-01,\n",
            "           -6.9856e-02, -1.3834e-01],\n",
            "          ...,\n",
            "          [-1.1490e-01, -2.9171e-02,  3.8962e-01,  ..., -2.7270e-01,\n",
            "           -1.3963e-01, -2.5237e-02],\n",
            "          [ 3.8649e-02, -6.0709e-02,  9.3793e-02,  ..., -1.8862e-02,\n",
            "           -1.3358e-01, -1.2522e-01],\n",
            "          [ 1.2474e-01,  2.7488e-01, -2.3221e-02,  ..., -9.2896e-02,\n",
            "            3.5958e-02, -1.1730e-01]],\n",
            "\n",
            "         [[ 3.2261e-02, -5.6044e-02,  2.7891e-01,  ...,  8.2951e-02,\n",
            "            4.8600e-02,  4.6625e-02],\n",
            "          [ 8.6895e-02,  1.2243e+00, -4.7479e-02,  ...,  3.9934e-01,\n",
            "            9.9429e-02,  1.4818e-01],\n",
            "          [ 1.0340e-01, -9.9769e-01, -4.8358e-01,  ..., -1.2325e-01,\n",
            "           -3.7334e-02,  1.3334e-01],\n",
            "          ...,\n",
            "          [ 3.2392e-01,  6.6889e-01, -6.6274e-02,  ..., -6.0144e-02,\n",
            "            8.6185e-02,  8.8555e-02],\n",
            "          [ 2.4093e-01, -5.2990e-01, -6.1648e-02,  ...,  6.7218e-04,\n",
            "            1.0718e-01, -2.3063e-02],\n",
            "          [ 1.8656e-01, -4.4759e-01,  3.4530e-01,  ...,  2.8850e-01,\n",
            "           -6.4420e-02, -1.4376e-02]],\n",
            "\n",
            "         [[-2.2402e-01, -1.8322e-01,  9.3192e-02,  ..., -1.1382e-01,\n",
            "           -4.2398e-02, -7.5285e-02],\n",
            "          [-2.8095e-01,  2.6157e-01, -4.3879e-01,  ..., -5.8590e-02,\n",
            "           -1.1071e-01, -1.6260e-01],\n",
            "          [-1.5072e-01,  6.8663e-01,  1.1185e-01,  ..., -6.3643e-03,\n",
            "           -1.3570e-02, -4.5932e-02],\n",
            "          ...,\n",
            "          [-1.3520e-01,  1.6752e-01, -2.5895e-01,  ..., -1.3663e-01,\n",
            "            8.3346e-02, -1.9117e-01],\n",
            "          [-2.7833e-01,  2.9166e-01, -1.3312e-01,  ..., -2.3674e-01,\n",
            "            2.2235e-02, -7.6557e-02],\n",
            "          [ 1.2268e-01, -2.0022e-02, -3.1646e-01,  ...,  7.1983e-02,\n",
            "            4.4651e-02,  3.2307e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 0.0761,  0.1933,  0.1154,  ..., -0.0410, -0.0197,  0.1270],\n",
            "          [ 0.0588,  0.3302,  0.1198,  ...,  0.2590,  0.3187, -0.1354],\n",
            "          [ 0.1364, -0.0021,  0.1134,  ..., -0.2286,  0.1334,  0.1258],\n",
            "          ...,\n",
            "          [ 0.0202, -0.0302,  0.0225,  ...,  0.0401, -0.0611,  0.0685],\n",
            "          [ 0.1166,  0.1683,  0.0721,  ...,  0.0500,  0.1260,  0.1087],\n",
            "          [-0.0395,  0.0759,  0.0631,  ...,  0.1108,  0.0384,  0.1456]],\n",
            "\n",
            "         [[ 0.0291,  0.0183, -0.0133,  ..., -0.2393, -0.0007,  0.1047],\n",
            "          [-0.1119, -0.0200,  0.2255,  ...,  0.1561, -0.0301, -0.0997],\n",
            "          [ 0.0269, -0.0408, -0.0658,  ..., -0.1026, -0.1466, -0.2493],\n",
            "          ...,\n",
            "          [-0.0884,  0.0706, -0.0400,  ..., -0.0750,  0.0015,  0.0799],\n",
            "          [-0.1341, -0.1237, -0.0123,  ..., -0.0157, -0.0976,  0.0025],\n",
            "          [ 0.0481,  0.0966, -0.0860,  ..., -0.0942, -0.0115, -0.0409]],\n",
            "\n",
            "         [[-0.0345, -0.1453, -0.0074,  ..., -0.1235,  0.0793, -0.0713],\n",
            "          [-0.0584,  0.1889, -0.0677,  ...,  0.2039,  0.0852,  0.0628],\n",
            "          [-0.0313, -0.0033, -0.3539,  ...,  0.1699, -0.1199, -0.0039],\n",
            "          ...,\n",
            "          [-0.1102,  0.0582, -0.0046,  ..., -0.1372, -0.0814, -0.0564],\n",
            "          [-0.2412, -0.0164, -0.1132,  ..., -0.0840, -0.0691, -0.0822],\n",
            "          [-0.0012, -0.0131, -0.1282,  ..., -0.0973, -0.0515, -0.1118]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0303, -0.0109,  0.0247,  ...,  0.1121,  0.0342,  0.0719],\n",
            "          [ 0.0658,  0.0512,  0.0503,  ...,  0.3622, -0.1186,  0.2882],\n",
            "          [-0.1255, -0.3260,  0.1251,  ..., -0.3108, -0.1811, -0.1576],\n",
            "          ...,\n",
            "          [ 0.1176,  0.0410, -0.1160,  ..., -0.0378, -0.1006,  0.0417],\n",
            "          [-0.0688, -0.0912,  0.0770,  ...,  0.0568, -0.0248, -0.0780],\n",
            "          [-0.0202, -0.0094, -0.0095,  ...,  0.0680, -0.0398,  0.0655]],\n",
            "\n",
            "         [[ 0.0166, -0.0756, -0.1410,  ..., -0.1394,  0.1469,  0.1010],\n",
            "          [-0.1357, -0.0175, -0.0304,  ..., -0.0695, -0.1699, -0.1519],\n",
            "          [-0.0523, -0.2501,  0.1314,  ..., -0.2397, -0.0106,  0.1085],\n",
            "          ...,\n",
            "          [-0.2662, -0.0226,  0.0075,  ..., -0.2286, -0.1008,  0.0599],\n",
            "          [-0.0464, -0.1384, -0.0074,  ..., -0.0010, -0.0843, -0.0546],\n",
            "          [ 0.0217,  0.0862, -0.0285,  ..., -0.1619, -0.0328, -0.0183]],\n",
            "\n",
            "         [[-0.0789,  0.0833, -0.1166,  ...,  0.0619, -0.0757, -0.1002],\n",
            "          [ 0.0281, -0.2635,  0.0822,  ..., -0.6296,  0.4323,  0.2623],\n",
            "          [-0.0477, -0.1336,  0.0045,  ...,  0.2690,  0.2289,  0.1951],\n",
            "          ...,\n",
            "          [ 0.0628, -0.0319, -0.1169,  ..., -0.1509, -0.0363, -0.0430],\n",
            "          [ 0.0067, -0.0246, -0.0438,  ..., -0.0985, -0.0188, -0.0681],\n",
            "          [-0.0520, -0.0827, -0.1459,  ..., -0.0319, -0.0069, -0.0657]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 1.9438e-01,  1.7007e-01, -5.4776e-01,  ..., -1.7837e-02,\n",
            "           -1.9525e-01, -6.6772e-02],\n",
            "          [-1.6231e-01,  2.4250e-01, -7.3858e-02,  ..., -1.0465e-01,\n",
            "           -1.9676e-02, -1.2039e-01],\n",
            "          [-1.0571e-01,  2.1883e-01, -4.0654e-01,  ...,  8.8484e-02,\n",
            "           -2.1503e-01,  3.1318e-02],\n",
            "          ...,\n",
            "          [-1.2839e-01,  8.6218e-02,  2.1228e-01,  ..., -1.7147e-01,\n",
            "           -8.2441e-02, -1.8594e-02],\n",
            "          [-8.7912e-02,  3.7713e-02, -1.1300e-01,  ..., -4.5676e-02,\n",
            "           -1.0057e-01, -1.9528e-02],\n",
            "          [-2.2163e-01,  2.3532e-01,  4.1641e-01,  ..., -1.0416e-02,\n",
            "            4.8489e-04,  2.2789e-02]],\n",
            "\n",
            "         [[-1.5119e-01, -2.0403e-01,  4.9870e-01,  ...,  4.9303e-02,\n",
            "            1.4006e-01,  2.1018e-02],\n",
            "          [ 3.4312e-01, -6.3899e-01, -1.5527e+00,  ..., -1.9170e-01,\n",
            "           -1.9635e-01,  8.9459e-02],\n",
            "          [ 2.5762e-02,  7.4627e-01,  2.4594e-01,  ...,  2.4267e-01,\n",
            "            6.0298e-02,  6.7879e-02],\n",
            "          ...,\n",
            "          [ 3.4355e-01,  3.7972e-01, -1.4693e+00,  ...,  1.5434e-01,\n",
            "            1.7600e-01,  2.2232e-01],\n",
            "          [ 4.6237e-02,  5.4262e-01,  2.3722e-01,  ..., -6.4638e-02,\n",
            "            1.1579e-01,  4.3604e-02],\n",
            "          [ 2.4899e-03,  2.9027e-01,  2.7125e-01,  ..., -1.5541e-02,\n",
            "           -7.6680e-02,  9.6878e-04]],\n",
            "\n",
            "         [[ 4.5768e-02,  1.0183e-02,  4.5092e-02,  ...,  1.9301e-02,\n",
            "            9.8115e-02,  6.9399e-02],\n",
            "          [ 8.0550e-02, -1.3930e+00, -6.0524e-01,  ..., -4.6013e-01,\n",
            "            3.5137e-02,  1.2996e-01],\n",
            "          [ 2.4303e-01, -3.0166e-01,  8.3578e-01,  ..., -3.1719e-02,\n",
            "            2.8139e-01, -3.7870e-03],\n",
            "          ...,\n",
            "          [ 2.5561e-01, -1.1259e+00, -8.6802e-01,  ...,  4.7921e-01,\n",
            "            1.7386e-01,  5.2890e-02],\n",
            "          [ 2.5160e-01, -3.3778e-02,  2.3700e-01,  ...,  1.3309e-02,\n",
            "            3.2577e-02,  1.6283e-01],\n",
            "          [ 1.3958e-01, -3.1185e-01,  1.5077e-01,  ..., -5.6108e-02,\n",
            "           -4.2399e-03,  7.6690e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.8036e-02, -3.6508e-01, -3.3217e-01,  ..., -6.8758e-02,\n",
            "           -7.7648e-02,  9.0906e-03],\n",
            "          [-2.6202e-01,  2.1548e-01,  4.5710e-01,  ...,  2.0599e-01,\n",
            "           -1.1389e-01,  8.0699e-02],\n",
            "          [ 7.7977e-02,  1.5864e-01,  5.0233e-01,  ..., -1.4573e-01,\n",
            "            8.2817e-02, -1.2101e-01],\n",
            "          ...,\n",
            "          [-5.8404e-01, -4.2940e-01,  5.4848e-01,  ..., -1.9924e-01,\n",
            "           -1.2187e-02, -1.2310e-01],\n",
            "          [ 1.9030e-01,  3.5275e-01,  1.4925e-01,  ...,  2.4425e-03,\n",
            "           -4.8294e-02, -1.3052e-02],\n",
            "          [-3.0235e-02,  1.6421e-01, -6.3337e-01,  ..., -5.3241e-02,\n",
            "            7.7320e-02,  6.6912e-03]],\n",
            "\n",
            "         [[ 1.6757e-02,  4.3139e-02, -1.9301e-01,  ..., -4.1763e-03,\n",
            "           -1.8047e-02,  9.8540e-02],\n",
            "          [ 1.6068e-01,  1.5469e-01, -5.1944e-01,  ...,  4.0928e-02,\n",
            "           -8.2032e-02, -7.7962e-02],\n",
            "          [ 9.1935e-02, -9.4078e-01, -2.3052e-01,  ..., -2.5806e-01,\n",
            "            8.8379e-02,  1.6262e-01],\n",
            "          ...,\n",
            "          [ 4.7670e-01,  4.8759e-01, -3.1774e-01,  ...,  1.3165e-01,\n",
            "            2.0258e-01,  1.9965e-01],\n",
            "          [ 1.9657e-01, -4.2357e-01, -5.7249e-02,  ...,  5.1349e-02,\n",
            "            3.2077e-02,  8.5938e-02],\n",
            "          [ 2.5213e-01,  2.8156e-01,  4.8605e-02,  ...,  5.7892e-02,\n",
            "            9.3156e-04, -1.1664e-02]],\n",
            "\n",
            "         [[ 1.5091e-02, -1.3846e-01, -3.1635e-01,  ...,  2.5552e-02,\n",
            "           -8.4064e-02, -2.9260e-02],\n",
            "          [-2.3947e-01, -7.6841e-01, -2.7265e-01,  ..., -7.2229e-02,\n",
            "            3.2154e-02, -6.6351e-02],\n",
            "          [-6.0000e-02,  1.6890e-01, -2.1182e-01,  ...,  7.0729e-02,\n",
            "            4.0390e-02,  1.1804e-01],\n",
            "          ...,\n",
            "          [ 4.2154e-01, -9.6105e-01,  9.5218e-02,  ...,  5.8067e-02,\n",
            "            5.3652e-02,  1.1433e-02],\n",
            "          [ 7.7167e-02, -2.1988e-01, -2.7772e-01,  ..., -1.1072e-01,\n",
            "           -9.8888e-03, -1.4664e-03],\n",
            "          [-2.7570e-03, -1.3510e-01,  7.3304e-02,  ...,  6.3514e-02,\n",
            "            8.8310e-03,  7.4685e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-0.0510,  0.0564, -0.1470,  ...,  0.0227, -0.1419,  0.1464],\n",
            "          [-0.7374,  0.2404, -0.0538,  ...,  0.3617, -0.2869, -0.1482],\n",
            "          [-0.0169, -0.1568, -0.0091,  ...,  0.0683, -0.0364,  0.2124],\n",
            "          ...,\n",
            "          [-0.1963,  0.0254, -0.1393,  ..., -0.0472, -0.0185, -0.0992],\n",
            "          [-0.0501,  0.0110, -0.1780,  ..., -0.0997, -0.1220, -0.0328],\n",
            "          [-0.0432, -0.0721, -0.1238,  ..., -0.1060, -0.0737, -0.0747]],\n",
            "\n",
            "         [[-0.2450, -0.0749, -0.1478,  ..., -0.1628, -0.0832,  0.0711],\n",
            "          [-0.3099,  1.0194,  0.2455,  ...,  1.1171,  0.3654,  0.1227],\n",
            "          [-0.0677, -0.0926,  0.1632,  ...,  0.0142, -0.0268,  0.0019],\n",
            "          ...,\n",
            "          [ 0.1337, -0.1695, -0.1334,  ..., -0.1807, -0.1187, -0.0126],\n",
            "          [-0.0546, -0.0084, -0.0825,  ..., -0.0632, -0.0139, -0.0266],\n",
            "          [-0.0195, -0.1660,  0.1379,  ..., -0.0769,  0.0707, -0.0452]],\n",
            "\n",
            "         [[-0.0479, -0.2155, -0.1047,  ..., -0.3077, -0.1932, -0.0351],\n",
            "          [ 0.0915, -0.2050, -0.1247,  ..., -0.4464, -0.2805,  0.4423],\n",
            "          [ 0.1493,  0.3284, -0.1303,  ...,  0.3115, -0.1029,  0.0360],\n",
            "          ...,\n",
            "          [-0.0307,  0.1372, -0.0917,  ...,  0.2029,  0.0175, -0.0550],\n",
            "          [-0.0595, -0.1478,  0.0921,  ..., -0.0230,  0.0808,  0.0629],\n",
            "          [-0.0671,  0.1277,  0.0124,  ...,  0.0075,  0.0948,  0.0807]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1381,  0.1033, -0.0685,  ...,  0.1390, -0.0511, -0.2743],\n",
            "          [ 0.0468, -0.3571,  0.1988,  ..., -0.1815,  0.1597,  0.0554],\n",
            "          [-0.1005, -0.2337,  0.4324,  ..., -0.0338,  0.3004, -0.1923],\n",
            "          ...,\n",
            "          [ 0.0799, -0.0098,  0.2066,  ...,  0.0149,  0.0730,  0.0961],\n",
            "          [ 0.1662,  0.0963,  0.1714,  ...,  0.0928,  0.0659,  0.0635],\n",
            "          [-0.0073, -0.0024, -0.0356,  ...,  0.0538,  0.0299,  0.0956]],\n",
            "\n",
            "         [[-0.2352, -0.1589,  0.1843,  ..., -0.2193,  0.1274,  0.4173],\n",
            "          [ 0.1044,  0.0612,  0.1618,  ..., -0.3100,  0.2997, -0.1344],\n",
            "          [-0.4004, -0.3935, -0.2454,  ..., -0.3029, -0.2862, -0.1549],\n",
            "          ...,\n",
            "          [ 0.0394, -0.2826, -0.0462,  ..., -0.0640, -0.0831,  0.0088],\n",
            "          [-0.1583, -0.0164, -0.1061,  ..., -0.0459, -0.0469,  0.0117],\n",
            "          [-0.0765, -0.1073,  0.1457,  ..., -0.0687,  0.0525, -0.0071]],\n",
            "\n",
            "         [[ 0.0451,  0.0868, -0.1400,  ...,  0.1118, -0.2016,  0.3435],\n",
            "          [ 0.2193, -0.2436,  0.1822,  ..., -0.0604,  0.1377, -0.1520],\n",
            "          [ 0.0923,  0.7593, -0.0587,  ...,  0.4654, -0.1335,  0.1113],\n",
            "          ...,\n",
            "          [-0.0511,  0.2860, -0.0698,  ...,  0.1083,  0.0497,  0.0525],\n",
            "          [-0.0029, -0.0924, -0.1919,  ..., -0.0142, -0.0022,  0.0356],\n",
            "          [ 0.0315, -0.1854,  0.0971,  ..., -0.0227,  0.0362,  0.0713]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 1.6109e-02, -2.4560e-01, -2.2673e-01,  ..., -1.8649e-01,\n",
            "           -3.2916e-01, -7.9260e-02],\n",
            "          [-5.3225e-01, -1.4776e-01, -1.3357e-01,  ..., -2.9071e-01,\n",
            "           -3.0828e-02, -6.5967e-01],\n",
            "          [ 5.3084e-02, -1.1938e-02, -1.3523e-01,  ..., -8.1855e-02,\n",
            "           -2.9108e-01,  1.6717e-01],\n",
            "          ...,\n",
            "          [-2.4678e-01,  2.6772e-01, -2.5481e-01,  ...,  1.5645e-01,\n",
            "           -4.9340e-02, -3.0665e-02],\n",
            "          [-1.4250e-02, -3.5172e-01,  1.2952e-01,  ..., -1.5845e-01,\n",
            "            3.1083e-02,  9.0972e-03],\n",
            "          [ 1.0928e-01,  4.1358e-01, -6.0903e-02,  ...,  6.7889e-02,\n",
            "           -1.2420e-01,  5.1994e-02]],\n",
            "\n",
            "         [[ 3.6530e-01, -2.2496e-01,  2.8884e-01,  ..., -5.2468e-02,\n",
            "           -7.8754e-03, -2.1173e-01],\n",
            "          [-6.4821e-01,  6.9067e-01, -1.6125e-01,  ...,  2.4680e-01,\n",
            "            1.4293e-02,  6.5674e-02],\n",
            "          [ 1.0109e+00, -8.6462e-01,  3.9267e-01,  ..., -4.2918e-01,\n",
            "            1.1216e-01, -2.0711e-01],\n",
            "          ...,\n",
            "          [-1.4701e-01, -2.6162e-01, -3.1596e-01,  ..., -1.0076e-01,\n",
            "            5.1866e-02,  7.9445e-02],\n",
            "          [ 2.9801e-01, -5.7562e-02,  3.5638e-01,  ...,  1.1253e-01,\n",
            "            1.1417e-01,  8.7128e-02],\n",
            "          [ 1.0639e-01,  2.4976e-02,  2.7333e-01,  ...,  3.8307e-02,\n",
            "            8.8589e-02,  1.6066e-01]],\n",
            "\n",
            "         [[-3.5886e-03, -1.1276e-01,  3.0999e-02,  ..., -1.5565e-01,\n",
            "           -3.3716e-02,  6.5190e-03],\n",
            "          [-3.6970e-01,  1.5920e-01, -4.5656e-01,  ...,  5.0448e-02,\n",
            "           -8.4331e-02,  2.6476e-01],\n",
            "          [ 2.8791e-01, -6.3468e-01, -1.7451e-01,  ..., -4.3829e-01,\n",
            "            1.2253e-02, -4.3512e-01],\n",
            "          ...,\n",
            "          [-3.7833e-01,  4.3133e-02, -1.3583e-01,  ..., -2.1691e-01,\n",
            "            4.4950e-02, -6.4196e-02],\n",
            "          [-1.1310e-01,  4.3837e-01, -2.5704e-01,  ...,  2.3293e-01,\n",
            "           -4.0053e-02,  6.8961e-02],\n",
            "          [ 9.9288e-02, -5.0208e-01,  1.7864e-01,  ..., -1.7032e-01,\n",
            "            1.3735e-01, -2.0842e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.4708e-02, -1.6551e-01,  1.2559e-01,  ..., -1.0735e-01,\n",
            "           -1.9619e-02,  6.3584e-02],\n",
            "          [ 4.1411e-01, -1.5488e+00, -3.3415e-01,  ..., -7.8029e-01,\n",
            "           -2.5017e-01, -1.0389e-01],\n",
            "          [-1.5738e-02, -6.7888e-01, -3.0306e-01,  ..., -2.3296e-01,\n",
            "           -3.1166e-01, -7.4084e-02],\n",
            "          ...,\n",
            "          [ 1.7948e-01, -1.8696e-01, -1.1970e-01,  ...,  1.4949e-02,\n",
            "           -7.2527e-02, -1.8467e-01],\n",
            "          [ 3.0509e-01, -2.5912e-01,  1.2670e-01,  ..., -7.4978e-02,\n",
            "           -2.7021e-02, -2.2825e-01],\n",
            "          [-2.0127e-01,  3.1083e-01, -1.7863e-01,  ...,  1.6547e-03,\n",
            "           -1.7043e-01, -6.2819e-02]],\n",
            "\n",
            "         [[ 7.9339e-02, -8.8629e-02,  4.8308e-01,  ..., -1.3447e-01,\n",
            "            1.1465e-01,  5.2904e-02],\n",
            "          [-2.1005e-02,  8.6675e-01, -7.2259e-01,  ...,  6.3866e-02,\n",
            "           -9.2104e-02, -2.7099e-01],\n",
            "          [ 2.5644e-01,  1.9815e-01, -2.3945e-01,  ...,  1.7530e-01,\n",
            "            4.1966e-02, -1.3062e-01],\n",
            "          ...,\n",
            "          [-1.0884e-02,  8.2939e-01, -1.0290e+00,  ...,  5.8012e-02,\n",
            "           -8.2968e-02,  1.4293e-02],\n",
            "          [-1.2054e-01,  4.1451e-02, -3.6010e-01,  ...,  4.6176e-04,\n",
            "           -6.4752e-02, -1.6007e-01],\n",
            "          [ 2.6361e-01,  1.4147e-01,  2.4419e-01,  ..., -3.8550e-02,\n",
            "           -6.1647e-03, -1.9032e-02]],\n",
            "\n",
            "         [[ 1.8620e-01, -5.6795e-01, -4.6882e-02,  ..., -3.2878e-01,\n",
            "           -5.0186e-02,  1.4416e-01],\n",
            "          [-3.6643e-01,  1.2111e-01, -1.3891e+00,  ..., -6.3801e-02,\n",
            "           -5.4348e-01,  2.3430e-01],\n",
            "          [ 8.9828e-05, -8.8031e-02, -1.4726e-01,  ..., -2.1702e-01,\n",
            "           -1.9421e-03, -2.0866e-01],\n",
            "          ...,\n",
            "          [ 1.5853e-01, -1.1023e-01, -6.5804e-01,  ..., -4.1054e-02,\n",
            "           -6.5826e-02,  3.6030e-02],\n",
            "          [-2.0174e-01,  6.0861e-01, -2.8792e-01,  ...,  2.0999e-01,\n",
            "           -5.2080e-02, -2.3319e-02],\n",
            "          [-5.1512e-01, -5.0043e-01, -3.9968e-01,  ..., -1.6537e-01,\n",
            "           -2.0604e-01, -1.1550e-01]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-3.7213e-01, -6.9532e-01,  6.2451e-01,  ..., -2.7536e-01,\n",
            "            4.5450e-01,  1.3221e-01],\n",
            "          [ 2.5381e-01,  4.0046e-01,  3.6015e-01,  ...,  3.7263e-01,\n",
            "            1.5582e-01,  7.2789e-03],\n",
            "          [ 2.1342e-01, -3.7120e-01, -1.1867e-02,  ..., -1.8201e-01,\n",
            "           -1.9572e-02,  4.2772e-02],\n",
            "          ...,\n",
            "          [ 1.5624e-02, -8.4553e-02,  2.1330e-01,  ...,  6.9876e-03,\n",
            "            1.1246e-01, -1.2609e-02],\n",
            "          [-1.2252e-02, -2.8437e-01,  1.5037e-01,  ...,  1.9693e-02,\n",
            "            3.4670e-02,  6.6278e-02],\n",
            "          [ 1.4239e-01, -7.6001e-02, -7.2801e-02,  ...,  6.9071e-02,\n",
            "            4.6108e-02,  6.0764e-02]],\n",
            "\n",
            "         [[-1.3496e-01, -2.5467e-01, -3.0969e-01,  ..., -1.4229e-01,\n",
            "            9.4690e-02, -1.4691e-01],\n",
            "          [ 5.2164e-01,  5.6695e-01, -2.7018e-01,  ...,  6.0182e-01,\n",
            "           -2.1718e-01,  3.9947e-02],\n",
            "          [ 3.3851e-01, -5.8640e-01, -5.6841e-02,  ..., -6.1283e-01,\n",
            "            6.9704e-02, -3.4068e-02],\n",
            "          ...,\n",
            "          [ 7.9899e-02,  1.9130e-01, -5.6269e-03,  ..., -6.7191e-02,\n",
            "            1.9449e-02,  1.7933e-02],\n",
            "          [-7.3936e-03, -3.4329e-02,  4.5333e-01,  ..., -2.3966e-03,\n",
            "            3.5375e-02, -3.6678e-02],\n",
            "          [-1.5645e-02,  2.2843e-01, -2.0962e-01,  ..., -3.6302e-02,\n",
            "           -1.8076e-02, -1.2228e-02]],\n",
            "\n",
            "         [[-1.5549e-01,  1.7289e-01, -3.8552e-01,  ...,  3.4300e-01,\n",
            "           -1.5520e-01,  1.2422e-01],\n",
            "          [-3.4819e-01, -4.0319e-01, -3.1630e-01,  ...,  1.8432e-01,\n",
            "           -3.1537e-02,  2.6898e-01],\n",
            "          [-2.2958e-01,  8.8160e-01, -2.2336e-01,  ...,  1.1548e-01,\n",
            "           -1.6969e-01,  4.4135e-01],\n",
            "          ...,\n",
            "          [-9.9906e-02, -2.2326e-01, -4.4331e-01,  ..., -3.9623e-05,\n",
            "           -7.2833e-02, -1.3421e-02],\n",
            "          [ 2.9098e-02, -2.5023e-01, -6.3935e-03,  ..., -5.9838e-02,\n",
            "            1.7132e-02,  4.4328e-02],\n",
            "          [ 1.8995e-01,  2.1125e-01,  6.8661e-02,  ..., -2.2125e-03,\n",
            "           -2.1651e-02,  3.5627e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9459e-01, -2.0806e-01, -5.2361e-01,  ..., -9.0365e-02,\n",
            "           -9.6170e-02,  7.6837e-02],\n",
            "          [ 1.8773e-01, -5.8370e-02, -1.3332e-01,  ...,  2.1584e-01,\n",
            "            2.8871e-01, -1.8526e-02],\n",
            "          [-2.0125e-01, -1.2995e+00, -6.5624e-02,  ..., -7.4484e-01,\n",
            "           -2.4045e-01,  1.3003e-01],\n",
            "          ...,\n",
            "          [ 2.1345e-01,  2.4503e-01,  8.9559e-02,  ...,  4.2900e-02,\n",
            "            5.8090e-02,  3.7402e-02],\n",
            "          [ 4.2473e-02, -3.3176e-01,  6.8105e-02,  ...,  2.4395e-02,\n",
            "            3.3304e-02,  6.1636e-02],\n",
            "          [-1.3862e-01,  1.7027e-01,  1.1717e-01,  ...,  6.5495e-02,\n",
            "            4.4163e-02,  1.9669e-02]],\n",
            "\n",
            "         [[-1.8932e-01,  2.9356e-01,  6.9751e-01,  ...,  1.0488e-01,\n",
            "            1.5071e-01, -2.0082e-01],\n",
            "          [-5.9004e-01,  5.1040e-01, -2.8982e-01,  ...,  2.1111e-01,\n",
            "            2.5218e-01, -1.3319e-01],\n",
            "          [ 3.7818e-01,  6.8010e-01, -2.6146e-01,  ...,  1.5677e-01,\n",
            "           -3.2038e-02,  2.2964e-01],\n",
            "          ...,\n",
            "          [-5.9476e-02,  2.6180e-01, -2.3300e-01,  ...,  2.0190e-02,\n",
            "            2.0723e-02,  4.5961e-02],\n",
            "          [ 5.5857e-02, -1.9299e-01, -3.4525e-01,  ...,  8.2254e-03,\n",
            "           -4.8318e-02,  3.5419e-02],\n",
            "          [ 1.1059e-01, -1.6221e-01, -3.0453e-02,  ..., -1.1446e-02,\n",
            "           -3.1495e-02, -6.3520e-02]],\n",
            "\n",
            "         [[ 2.3912e-01,  5.2987e-01,  2.4077e-01,  ...,  5.0602e-03,\n",
            "           -1.0497e-01, -9.4120e-02],\n",
            "          [-1.1447e-01,  1.2286e+00,  6.9777e-01,  ...,  1.7117e-01,\n",
            "            6.8174e-02,  1.8409e-02],\n",
            "          [-6.3815e-01,  1.5383e-01,  2.4388e-02,  ...,  2.6553e-01,\n",
            "            8.3664e-02,  1.0716e-02],\n",
            "          ...,\n",
            "          [ 1.8320e-01,  8.0479e-02,  4.2932e-01,  ..., -4.1077e-02,\n",
            "            8.0658e-02,  5.1572e-02],\n",
            "          [-6.5494e-02, -1.1129e-03, -2.2463e-01,  ...,  7.7465e-02,\n",
            "            2.6226e-02,  5.1138e-02],\n",
            "          [-3.1859e-01, -8.4444e-02,  6.6515e-02,  ...,  9.3434e-02,\n",
            "            7.3992e-02,  3.2327e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 7.3474e-02, -3.1162e-01, -1.1844e-01,  ..., -4.4497e-01,\n",
            "            5.9240e-02, -6.1766e-02],\n",
            "          [ 7.8690e-02,  1.1881e+00,  5.6282e-01,  ..., -9.4498e-01,\n",
            "           -3.5727e-01,  5.0694e-01],\n",
            "          [ 1.5354e-01, -6.3780e-01, -1.3398e-02,  ...,  4.8632e-01,\n",
            "           -1.2918e-01, -3.2939e-01],\n",
            "          ...,\n",
            "          [-9.1580e-02,  1.5787e+00,  5.1292e-01,  ..., -1.1987e-01,\n",
            "           -2.3636e-02,  3.1364e-02],\n",
            "          [-8.2076e-02,  1.8782e-01,  1.9782e-02,  ..., -2.1417e-03,\n",
            "           -2.3949e-02, -3.8866e-02],\n",
            "          [ 4.7045e-01, -4.2283e-01, -3.3989e-01,  ...,  1.9741e-02,\n",
            "            1.2452e-02, -5.2561e-02]],\n",
            "\n",
            "         [[ 4.1175e-01, -5.6027e-02, -2.5499e-01,  ..., -8.9700e-02,\n",
            "           -2.2056e-01, -1.4473e-01],\n",
            "          [ 2.9495e-01, -3.3806e-01,  4.5024e-02,  ...,  8.6664e-02,\n",
            "           -5.3540e-01,  1.0560e-01],\n",
            "          [-1.3114e-01,  4.1787e-01,  2.2586e-01,  ..., -1.3955e-01,\n",
            "           -8.9342e-02,  3.5231e-02],\n",
            "          ...,\n",
            "          [ 2.5060e-01, -1.0291e-02, -8.5247e-01,  ...,  2.8401e-02,\n",
            "           -6.2681e-02, -1.0361e-02],\n",
            "          [-1.8971e-01,  3.4983e-01,  7.4535e-01,  ..., -4.8120e-02,\n",
            "           -3.1837e-02, -4.4012e-02],\n",
            "          [-3.0856e-01, -2.5996e-01,  1.1989e-01,  ..., -1.5812e-02,\n",
            "           -8.2746e-04, -4.7674e-02]],\n",
            "\n",
            "         [[ 1.1872e-01, -2.1266e-01, -2.5998e-01,  ..., -2.6957e-01,\n",
            "           -3.1375e-01, -2.7970e-01],\n",
            "          [ 1.4374e-01, -1.0845e-01, -6.2367e-02,  ...,  2.7682e-01,\n",
            "           -2.6016e-01, -4.7552e-01],\n",
            "          [ 8.6313e-03, -6.8767e-01,  1.1688e-01,  ...,  2.4628e-01,\n",
            "           -1.8682e-02,  1.8279e-01],\n",
            "          ...,\n",
            "          [ 1.1108e-02,  1.6731e-01, -3.2509e-01,  ..., -4.7156e-02,\n",
            "           -7.3896e-02, -9.0131e-02],\n",
            "          [ 2.8930e-02, -3.8763e-02,  6.0172e-01,  ...,  4.6410e-03,\n",
            "           -6.1971e-02, -2.8150e-02],\n",
            "          [-1.3965e-01, -5.3124e-01, -2.9191e-01,  ..., -1.2271e-02,\n",
            "           -5.7319e-02, -2.5751e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2812e-02,  2.5269e-01,  2.9225e-02,  ..., -9.0999e-02,\n",
            "           -1.1597e-01,  2.3912e-01],\n",
            "          [ 2.8496e-01,  7.9790e-01, -3.1951e-01,  ...,  2.9398e-02,\n",
            "            5.4708e-01, -7.0945e-01],\n",
            "          [-4.0802e-01,  4.1211e-01, -6.1347e-02,  ...,  1.1490e-01,\n",
            "            3.4424e-01, -2.6937e-01],\n",
            "          ...,\n",
            "          [ 3.3277e-01,  6.6005e-02, -1.0427e+00,  ...,  2.6568e-02,\n",
            "            7.4226e-02, -2.0827e-02],\n",
            "          [-9.6933e-02,  2.3352e-01,  8.5950e-02,  ...,  2.7026e-02,\n",
            "            6.6635e-02,  3.4483e-02],\n",
            "          [ 2.4744e-01,  2.8818e-01,  7.1274e-01,  ...,  3.8130e-02,\n",
            "            7.9013e-03,  3.1172e-02]],\n",
            "\n",
            "         [[ 7.7162e-02,  2.6265e-01, -1.1295e-01,  ..., -2.6290e-01,\n",
            "            4.0128e-01,  4.5690e-01],\n",
            "          [-7.3668e-02,  1.0870e-01, -3.4434e-01,  ...,  7.6278e-01,\n",
            "           -8.6251e-02, -2.1145e-01],\n",
            "          [ 4.2032e-01,  6.5324e-01, -1.9488e-02,  ..., -1.7459e-01,\n",
            "           -2.8512e-01, -4.3418e-01],\n",
            "          ...,\n",
            "          [-3.4162e-01,  3.4920e-01,  1.6857e-01,  ...,  4.6629e-02,\n",
            "            4.9664e-02,  2.6206e-02],\n",
            "          [ 1.4401e-01,  8.2080e-01, -1.4194e-01,  ...,  1.8059e-02,\n",
            "            2.6010e-02,  6.6525e-03],\n",
            "          [-2.0501e-01,  1.5156e-01, -6.0553e-02,  ...,  8.0970e-02,\n",
            "            4.3732e-02,  8.0917e-02]],\n",
            "\n",
            "         [[ 9.6843e-02, -4.7346e-01,  4.2713e-01,  ..., -1.9757e-01,\n",
            "            3.3909e-02,  4.0524e-02],\n",
            "          [ 2.1360e-01, -1.6739e-01,  2.1339e-02,  ..., -6.0672e-01,\n",
            "            2.1406e-01, -3.0090e-01],\n",
            "          [-6.6686e-02, -8.1553e-01,  2.3041e-01,  ..., -8.4170e-02,\n",
            "            1.0397e-01, -6.1894e-02],\n",
            "          ...,\n",
            "          [ 1.7244e-01,  1.7161e-01, -5.0597e-01,  ..., -5.5393e-02,\n",
            "           -8.8047e-03, -2.7894e-02],\n",
            "          [ 7.4869e-02, -1.4307e-01,  9.6135e-02,  ..., -2.1084e-02,\n",
            "           -1.7341e-02, -2.2030e-02],\n",
            "          [ 8.7161e-02, -3.4553e-01, -3.7402e-01,  ...,  1.9573e-02,\n",
            "           -2.0702e-02, -2.5362e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-3.2198e-01, -1.4066e-02,  2.6745e-01,  ...,  2.7950e-02,\n",
            "            2.1464e-01, -1.3580e-01],\n",
            "          [ 1.6630e-02, -5.3953e-01,  6.9421e-02,  ..., -7.4944e-01,\n",
            "           -2.0325e-01, -1.6565e-01],\n",
            "          [-1.9065e-01, -3.0221e-01, -2.1804e-01,  ..., -3.5105e-01,\n",
            "           -1.7671e-01, -3.6089e-01],\n",
            "          ...,\n",
            "          [-2.4059e-01, -1.9490e-02, -6.7804e-02,  ..., -1.3813e-01,\n",
            "           -8.5517e-02, -2.2661e-01],\n",
            "          [-1.3507e-01,  1.2966e-01, -2.1509e-01,  ..., -7.6895e-02,\n",
            "           -1.5439e-01, -1.0907e-01],\n",
            "          [ 3.1992e-03, -3.1104e-01,  7.3527e-02,  ..., -1.7245e-01,\n",
            "           -7.4680e-02, -1.2224e-01]],\n",
            "\n",
            "         [[-7.8104e-02, -1.9570e-01, -5.9539e-01,  ..., -1.8190e-01,\n",
            "           -3.7428e-01,  1.4833e-01],\n",
            "          [-6.2179e-02, -4.1315e-01,  2.3009e-01,  ..., -3.9710e-01,\n",
            "            2.2203e-03,  4.7844e-01],\n",
            "          [ 5.6568e-01,  2.9753e-01, -4.6706e-01,  ...,  1.2541e-01,\n",
            "            1.3082e-02, -1.4188e-01],\n",
            "          ...,\n",
            "          [ 2.5291e-01,  9.6299e-02,  9.7553e-02,  ..., -2.4340e-02,\n",
            "            9.4255e-03,  1.3591e-01],\n",
            "          [-5.6248e-02,  8.4526e-02,  5.4815e-02,  ..., -2.2067e-02,\n",
            "            7.3183e-02, -1.5691e-02],\n",
            "          [-5.3761e-02,  2.4271e-01, -9.7328e-02,  ...,  3.2502e-02,\n",
            "            8.7764e-02, -6.0578e-02]],\n",
            "\n",
            "         [[ 1.6637e-01, -2.5640e-01, -1.4899e-01,  ..., -1.8435e-01,\n",
            "           -1.3775e-01, -4.9746e-02],\n",
            "          [-3.6698e-02,  2.0972e-01,  3.6399e-01,  ..., -5.4104e-02,\n",
            "            5.5317e-01,  2.1919e-01],\n",
            "          [ 3.3520e-01,  4.3804e-01, -8.3417e-02,  ...,  1.0419e-01,\n",
            "            2.0272e-01, -2.2106e-01],\n",
            "          ...,\n",
            "          [ 5.9010e-02, -3.1339e-01,  1.0028e-01,  ..., -7.5938e-02,\n",
            "            1.2685e-01, -4.6413e-02],\n",
            "          [ 1.0915e-01, -8.0842e-02,  2.0382e-01,  ..., -3.1109e-02,\n",
            "            1.6000e-01, -2.2405e-02],\n",
            "          [-1.0640e-01, -5.7280e-02, -1.1047e-01,  ..., -1.2339e-02,\n",
            "           -4.2973e-02, -1.7750e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7082e-01,  3.5669e-01, -8.2995e-02,  ...,  3.7527e-01,\n",
            "           -9.4856e-02,  1.2721e-01],\n",
            "          [-6.8746e-01, -1.7152e-01, -1.8183e-03,  ..., -4.6348e-01,\n",
            "           -3.5187e-01,  2.5388e-01],\n",
            "          [ 2.5460e-01,  4.6121e-01,  4.8838e-02,  ...,  3.3213e-01,\n",
            "            2.1262e-01,  2.2724e-01],\n",
            "          ...,\n",
            "          [-1.1342e-01, -1.5519e-01, -1.7843e-01,  ..., -1.1585e-01,\n",
            "           -1.1084e-01, -5.9722e-02],\n",
            "          [ 1.1968e-01, -1.5235e-01,  2.3673e-01,  ...,  4.9922e-04,\n",
            "            1.2484e-01,  5.7481e-02],\n",
            "          [-1.4994e-01, -1.5940e-01, -3.6841e-02,  ..., -1.6314e-01,\n",
            "            1.1900e-02,  3.7402e-03]],\n",
            "\n",
            "         [[-3.6672e-01, -8.3054e-02, -1.6940e-02,  ..., -2.7658e-01,\n",
            "           -2.2761e-02, -3.1139e-02],\n",
            "          [ 4.2627e-01, -5.1251e-01, -5.7555e-01,  ..., -3.4240e-01,\n",
            "           -5.5178e-02, -6.1306e-01],\n",
            "          [-3.5715e-02, -2.9554e-01, -1.4782e-01,  ..., -4.2384e-01,\n",
            "           -1.5164e-01,  2.6956e-02],\n",
            "          ...,\n",
            "          [-2.6819e-01, -3.7036e-01,  1.4193e-01,  ..., -1.1145e-01,\n",
            "            1.8429e-01, -6.8131e-02],\n",
            "          [-3.1364e-01,  7.1267e-01, -9.7019e-02,  ...,  3.0059e-01,\n",
            "           -4.2257e-02,  6.2961e-02],\n",
            "          [ 2.7594e-01,  1.0621e-03,  1.0375e-01,  ...,  1.5511e-02,\n",
            "           -2.4074e-02, -7.9998e-02]],\n",
            "\n",
            "         [[-1.4227e-01,  4.1901e-01, -9.7422e-03,  ...,  3.2478e-01,\n",
            "           -6.9582e-03,  1.4753e-01],\n",
            "          [-2.7634e-01, -3.3562e-01, -2.7415e-01,  ..., -3.4734e-01,\n",
            "           -2.5177e-01,  7.1562e-01],\n",
            "          [ 4.4631e-03,  3.6750e-02, -3.8314e-01,  ..., -1.0403e-01,\n",
            "           -3.4044e-01,  1.5829e-01],\n",
            "          ...,\n",
            "          [-1.4440e-01, -3.5999e-01, -1.0471e-01,  ..., -2.5574e-01,\n",
            "           -1.2772e-02,  8.8450e-02],\n",
            "          [ 9.9333e-03,  8.5964e-02,  4.7435e-02,  ...,  1.2207e-01,\n",
            "           -1.0193e-03, -3.7384e-03],\n",
            "          [ 3.7113e-02, -1.1034e-01, -4.2721e-02,  ..., -2.9714e-02,\n",
            "            4.1619e-02,  9.5659e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-0.0531, -0.1608,  0.3246,  ..., -0.2044,  0.2619,  0.0628],\n",
            "          [-0.0263,  0.2804, -0.1018,  ...,  0.0880,  0.3366,  0.0024],\n",
            "          [ 0.0317,  0.1518,  0.2870,  ..., -0.1156,  0.3191,  0.2039],\n",
            "          ...,\n",
            "          [ 0.0080,  0.3043, -0.1825,  ...,  0.1125,  0.0439,  0.0823],\n",
            "          [ 0.0948,  0.1058,  0.1925,  ...,  0.1166,  0.0813,  0.0972],\n",
            "          [ 0.0221,  0.0969,  0.0734,  ...,  0.1168,  0.0239,  0.0726]],\n",
            "\n",
            "         [[ 0.0196, -0.7272,  0.1644,  ..., -0.5238,  0.0829,  0.0381],\n",
            "          [ 0.1116, -0.7305,  0.2968,  ..., -0.4905,  0.0835, -0.5937],\n",
            "          [-0.3514, -0.3127, -0.2225,  ..., -0.4334,  0.0402, -0.0466],\n",
            "          ...,\n",
            "          [ 0.0865, -0.1852, -0.0471,  ..., -0.0424, -0.0895,  0.0085],\n",
            "          [-0.0890, -0.0302, -0.0965,  ..., -0.0922, -0.0540, -0.0205],\n",
            "          [-0.0993, -0.1461, -0.2685,  ..., -0.0350, -0.0683, -0.0224]],\n",
            "\n",
            "         [[ 0.0478,  0.2256, -0.3011,  ...,  0.2102, -0.2916,  0.0437],\n",
            "          [ 0.0634, -0.1515, -0.3576,  ..., -0.1566, -0.5703,  0.0314],\n",
            "          [-0.1438, -0.4810, -0.3454,  ..., -0.3227, -0.0819,  0.2035],\n",
            "          ...,\n",
            "          [-0.0852, -0.3653, -0.2343,  ..., -0.1213, -0.0532, -0.1269],\n",
            "          [-0.1088, -0.1159, -0.0108,  ..., -0.0427, -0.0506, -0.0686],\n",
            "          [-0.0598, -0.0889,  0.0216,  ..., -0.0644, -0.0676, -0.0906]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2243,  0.0382, -0.1890,  ...,  0.2138, -0.0883,  0.1405],\n",
            "          [-0.1008,  0.3994,  0.2760,  ...,  0.2726,  0.0177, -0.4238],\n",
            "          [ 0.0395,  0.0406, -0.0230,  ...,  0.1269,  0.2750,  0.2106],\n",
            "          ...,\n",
            "          [ 0.0711,  0.1353,  0.0900,  ..., -0.0509, -0.0248,  0.0206],\n",
            "          [-0.0994, -0.0561,  0.1068,  ..., -0.0322, -0.0220, -0.0179],\n",
            "          [-0.0525, -0.0816,  0.1124,  ..., -0.0620,  0.0122,  0.0060]],\n",
            "\n",
            "         [[ 0.4409,  0.1601, -0.0652,  ...,  0.1976,  0.0318,  0.1692],\n",
            "          [ 0.0721, -0.1734,  0.2249,  ...,  0.0127, -0.0721,  0.5372],\n",
            "          [-0.0416, -0.5824,  0.0211,  ..., -0.3983,  0.3137,  0.3452],\n",
            "          ...,\n",
            "          [ 0.0640,  0.0113,  0.0023,  ..., -0.0338, -0.0340, -0.0683],\n",
            "          [-0.1793, -0.0800, -0.0497,  ..., -0.0467, -0.0842, -0.0718],\n",
            "          [-0.1233, -0.1996,  0.0358,  ..., -0.0394, -0.0431, -0.0077]],\n",
            "\n",
            "         [[-0.2481, -0.0842, -0.4097,  ..., -0.3907, -0.2422, -0.0669],\n",
            "          [-0.1117, -0.1208,  0.5894,  ..., -0.0492,  0.4814, -0.2404],\n",
            "          [-0.0375, -0.6595, -0.3486,  ..., -0.5560, -0.2159, -0.2802],\n",
            "          ...,\n",
            "          [-0.0860, -0.2421,  0.0093,  ..., -0.1249, -0.1561, -0.1027],\n",
            "          [ 0.0129,  0.2169, -0.0584,  ..., -0.0069, -0.0387, -0.0452],\n",
            "          [-0.0259,  0.0107, -0.1498,  ..., -0.0336, -0.0497, -0.0717]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-2.7184e-02, -1.1331e-02, -1.1190e-01,  ...,  1.1629e-03,\n",
            "            8.2696e-02,  1.5892e-01],\n",
            "          [-1.0583e-01, -3.7315e-01, -1.3812e-01,  ..., -2.9017e-01,\n",
            "            2.4451e-01, -1.4998e-02],\n",
            "          [-5.4106e-02,  1.2865e-01, -4.0561e-01,  ...,  1.4114e-01,\n",
            "           -1.4034e-01, -9.7991e-02],\n",
            "          ...,\n",
            "          [-3.0219e-02,  3.6138e-02, -7.6432e-02,  ..., -5.7081e-02,\n",
            "           -7.7906e-02, -1.2802e-01],\n",
            "          [-6.4020e-02, -6.3024e-02, -9.8078e-03,  ..., -4.6186e-02,\n",
            "           -4.7738e-02, -2.9766e-02],\n",
            "          [-5.0172e-02, -4.9926e-02,  2.4984e-02,  ..., -7.2079e-02,\n",
            "           -5.5091e-03, -5.9662e-02]],\n",
            "\n",
            "         [[-3.4085e-02,  8.8467e-02, -1.0733e-01,  ...,  3.8913e-02,\n",
            "            2.1076e-01, -4.5299e-02],\n",
            "          [-7.1824e-02,  5.3408e-01,  1.5954e-01,  ...,  2.0629e-01,\n",
            "            1.8374e-02, -8.2593e-01],\n",
            "          [-8.0662e-02,  9.2415e-02, -4.9680e-03,  ...,  4.3783e-01,\n",
            "           -2.0977e-01,  5.2244e-01],\n",
            "          ...,\n",
            "          [-3.9421e-02, -2.0472e-01, -8.9653e-02,  ..., -3.9642e-02,\n",
            "           -5.2038e-02, -5.1550e-02],\n",
            "          [ 1.8390e-02, -7.2426e-02, -5.7468e-03,  ..., -2.3436e-03,\n",
            "            4.6178e-03, -4.0566e-02],\n",
            "          [-4.3132e-02, -5.3991e-04, -7.3522e-02,  ..., -4.0168e-02,\n",
            "            8.3783e-03, -2.5699e-02]],\n",
            "\n",
            "         [[ 4.0868e-03,  1.4590e-01, -1.8012e-01,  ...,  1.3391e-01,\n",
            "            1.3370e-01, -2.1790e-03],\n",
            "          [ 2.6486e-01, -3.1992e-01,  1.7756e-01,  ..., -2.2351e-01,\n",
            "            2.7503e-01, -2.2746e-02],\n",
            "          [-4.5853e-02, -7.3462e-02, -4.4524e-01,  ...,  1.3476e-01,\n",
            "           -3.5221e-01, -2.6914e-02],\n",
            "          ...,\n",
            "          [-1.2724e-02,  2.1322e-01, -7.9916e-02,  ...,  6.9895e-02,\n",
            "           -2.3807e-02,  3.1704e-02],\n",
            "          [ 5.1735e-02, -5.0633e-03,  1.2706e-01,  ..., -2.6524e-02,\n",
            "            3.2116e-02, -9.6956e-03],\n",
            "          [ 3.0924e-02, -2.9343e-02, -4.3019e-02,  ..., -7.1810e-02,\n",
            "            6.4671e-03,  5.8808e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5914e-02, -8.9103e-02, -7.0895e-02,  ..., -3.5465e-01,\n",
            "           -3.8103e-02, -2.0303e-01],\n",
            "          [-4.5306e-02, -8.5580e-02, -2.9054e-01,  ..., -3.7340e-01,\n",
            "           -1.2462e-01, -5.3432e-01],\n",
            "          [ 7.3977e-03, -1.4514e-01, -2.4191e-01,  ..., -6.7040e-02,\n",
            "           -3.1644e-01, -4.3464e-01],\n",
            "          ...,\n",
            "          [-1.5989e-01, -8.9738e-02, -1.9511e-02,  ..., -9.1432e-02,\n",
            "           -7.6337e-02, -5.7423e-02],\n",
            "          [-3.3868e-02, -3.8620e-02, -2.2683e-02,  ..., -9.1424e-02,\n",
            "           -8.4087e-02, -8.3846e-02],\n",
            "          [-5.8598e-02, -5.8468e-02, -1.1320e-01,  ..., -3.8141e-02,\n",
            "           -9.4483e-02, -9.1230e-02]],\n",
            "\n",
            "         [[-4.6412e-02,  1.1550e-01,  7.6348e-02,  ...,  3.2850e-01,\n",
            "           -2.3658e-01,  9.7343e-02],\n",
            "          [ 1.1042e-01, -7.2811e-02, -1.8944e-01,  ..., -8.0243e-02,\n",
            "            1.9842e-01, -1.1413e-01],\n",
            "          [ 3.5286e-02, -6.4553e-02,  2.1932e-01,  ...,  6.7499e-01,\n",
            "           -1.9113e-01,  5.4195e-01],\n",
            "          ...,\n",
            "          [-2.2083e-02,  2.4657e-02,  1.4157e-01,  ...,  6.8663e-02,\n",
            "            7.4740e-02,  4.7597e-02],\n",
            "          [-1.5708e-03, -6.8050e-03,  3.3513e-02,  ...,  1.7082e-02,\n",
            "            4.1157e-02, -3.2262e-02],\n",
            "          [-3.6233e-03,  1.2319e-01,  2.3405e-02,  ...,  5.5463e-02,\n",
            "            1.0109e-02,  2.2635e-02]],\n",
            "\n",
            "         [[ 5.0277e-03,  2.4743e-02, -6.0387e-02,  ...,  3.7734e-01,\n",
            "           -2.7436e-01,  5.7470e-02],\n",
            "          [ 9.9266e-02,  2.5902e-01,  4.4798e-02,  ..., -4.9240e-02,\n",
            "            2.0152e-03,  2.8109e-01],\n",
            "          [-6.1536e-02, -2.3709e-01,  1.5131e-01,  ...,  2.3718e-01,\n",
            "           -2.8558e-01,  2.4286e-01],\n",
            "          ...,\n",
            "          [ 2.7850e-02, -1.8608e-01, -4.2588e-02,  ..., -7.8694e-02,\n",
            "            3.9457e-03,  3.3505e-02],\n",
            "          [ 6.5451e-02,  1.3975e-01, -1.3521e-02,  ...,  3.9017e-02,\n",
            "            1.8443e-02,  3.8871e-02],\n",
            "          [ 6.4798e-02, -1.4801e-01, -2.2190e-02,  ...,  8.1220e-03,\n",
            "            3.4777e-02,  1.8898e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 1.8917e-01,  2.5535e-02, -1.7415e-01,  ..., -3.2536e-03,\n",
            "           -1.2041e-01,  1.7119e-01],\n",
            "          [ 1.5554e-01,  3.4456e-01,  2.0781e-01,  ...,  8.4576e-01,\n",
            "            1.4896e-01,  1.1297e-01],\n",
            "          [-4.0533e-02,  2.5209e-01, -1.9613e-02,  ...,  2.4152e-01,\n",
            "           -2.7597e-01,  7.2726e-01],\n",
            "          ...,\n",
            "          [ 2.3488e-01,  2.7316e-01,  2.9666e-01,  ...,  1.2491e-01,\n",
            "            3.1782e-02,  3.7542e-02],\n",
            "          [ 1.3945e-01,  2.2384e-01, -2.3172e-02,  ...,  2.7196e-02,\n",
            "            5.0586e-02,  7.6072e-02],\n",
            "          [ 9.6944e-02,  2.2972e-01, -1.2456e-01,  ...,  6.0226e-02,\n",
            "            6.5935e-02,  2.1598e-02]],\n",
            "\n",
            "         [[ 9.6866e-02,  9.9328e-02, -9.2607e-02,  ...,  1.2965e-01,\n",
            "            3.5699e-03, -4.5971e-02],\n",
            "          [ 4.7818e-03, -1.8310e-01,  1.1098e-01,  ..., -2.9794e-01,\n",
            "            7.0954e-01, -4.8069e-01],\n",
            "          [-2.9342e-02, -3.7425e-01,  2.1399e-02,  ..., -7.3492e-01,\n",
            "           -1.1139e-01, -2.1249e-01],\n",
            "          ...,\n",
            "          [-4.8342e-02, -2.0590e-01,  2.0048e-02,  ...,  3.0954e-02,\n",
            "            5.5846e-02,  8.8659e-02],\n",
            "          [ 8.7444e-02, -1.2674e-01,  3.2554e-02,  ..., -1.8068e-06,\n",
            "            4.2520e-02,  6.6140e-02],\n",
            "          [-5.3806e-02, -7.4948e-02,  2.6802e-02,  ...,  5.0989e-02,\n",
            "            3.3725e-02,  4.4518e-02]],\n",
            "\n",
            "         [[ 2.9059e-01,  2.3381e-01,  1.5645e-01,  ...,  3.8417e-01,\n",
            "            1.2846e-01,  8.4963e-02],\n",
            "          [ 1.0479e-01,  5.0068e-01,  4.6432e-02,  ...,  4.4604e-01,\n",
            "           -4.0532e-01,  2.7105e-01],\n",
            "          [ 3.0416e-01, -1.4495e-01,  6.6801e-02,  ..., -5.2019e-02,\n",
            "            3.1809e-01,  2.9579e-01],\n",
            "          ...,\n",
            "          [ 1.3486e-01,  7.7260e-01,  1.7127e-01,  ...,  4.8117e-02,\n",
            "            7.8628e-02,  6.4556e-02],\n",
            "          [ 2.7248e-01,  1.6627e-01, -5.5616e-02,  ...,  4.3519e-02,\n",
            "            5.8897e-02,  3.4876e-02],\n",
            "          [ 1.5695e-01,  1.4253e-01,  3.8518e-02,  ...,  4.9118e-02,\n",
            "            6.1889e-02,  5.5763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1147e-01, -3.8572e-02, -1.9375e-03,  ..., -1.7718e-01,\n",
            "            2.1224e-01, -1.8841e-01],\n",
            "          [-1.2816e-01, -2.0200e-01,  3.3082e-01,  ..., -3.5802e-01,\n",
            "            3.2876e-01,  3.2935e-01],\n",
            "          [ 1.7927e-01,  2.9155e-01,  1.1392e-01,  ...,  3.2761e-01,\n",
            "            4.0289e-01,  1.6936e-01],\n",
            "          ...,\n",
            "          [-1.1620e-01, -3.8192e-01,  3.6676e-01,  ...,  5.8855e-02,\n",
            "            2.9611e-02, -1.1753e-02],\n",
            "          [ 2.6602e-01,  2.9937e-01,  1.9447e-01,  ...,  1.6986e-02,\n",
            "            3.1751e-02,  6.6420e-02],\n",
            "          [-4.7084e-02, -3.2428e-01, -4.9324e-02,  ...,  9.6139e-02,\n",
            "            8.1726e-02,  3.4275e-02]],\n",
            "\n",
            "         [[-2.7817e-02,  3.7175e-02,  2.8297e-02,  ...,  1.6254e-01,\n",
            "            2.3695e-02,  2.4348e-02],\n",
            "          [ 5.7640e-02, -2.6555e-02, -2.9791e-01,  ..., -1.6411e-01,\n",
            "            8.7500e-02, -3.5135e-01],\n",
            "          [ 3.5419e-03, -2.5698e-01, -4.0692e-01,  ..., -5.5781e-02,\n",
            "           -4.8672e-01,  1.6390e-02],\n",
            "          ...,\n",
            "          [ 3.1397e-02, -1.5926e-01, -3.2608e-01,  ..., -4.2486e-02,\n",
            "            1.2549e-02, -3.9407e-02],\n",
            "          [-1.1874e-01, -1.6476e-01, -2.9337e-01,  ..., -2.5592e-02,\n",
            "           -6.2977e-02, -5.4254e-02],\n",
            "          [ 9.3654e-02,  6.9389e-02,  8.8985e-02,  ..., -8.9755e-02,\n",
            "           -6.3531e-02, -5.5396e-02]],\n",
            "\n",
            "         [[-1.2284e-02, -1.2974e-01, -1.3290e-01,  ..., -1.3796e-01,\n",
            "           -2.6020e-01, -1.3280e-01],\n",
            "          [-2.2789e-01,  1.4541e-01, -1.4584e-01,  ...,  7.1751e-02,\n",
            "           -1.5859e-01,  1.5341e-02],\n",
            "          [-1.2042e-01, -2.6888e-01,  4.6232e-01,  ..., -5.0983e-01,\n",
            "            4.0656e-01, -5.0737e-02],\n",
            "          ...,\n",
            "          [-2.8764e-01, -5.1286e-02, -1.9323e-01,  ..., -6.2030e-02,\n",
            "           -5.5952e-02, -2.7238e-02],\n",
            "          [ 1.2576e-01, -3.7906e-01,  4.2782e-01,  ..., -7.4406e-02,\n",
            "           -5.7695e-02, -1.6497e-02],\n",
            "          [-2.7629e-01,  2.2190e-03, -3.4939e-02,  ..., -6.8973e-02,\n",
            "           -4.3757e-02, -5.9267e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 0.0642, -0.0964, -0.0769,  ..., -0.0506,  0.0692,  0.1434],\n",
            "          [ 0.1630,  0.1481, -0.2762,  ...,  0.8665, -0.9816,  0.2414],\n",
            "          [ 0.1393, -0.1308,  0.2827,  ...,  0.3771, -0.3452, -0.0338],\n",
            "          ...,\n",
            "          [-0.0633, -0.3207,  0.4216,  ..., -0.0051,  0.1450,  0.0504],\n",
            "          [ 0.0239, -0.1232,  0.2126,  ..., -0.0046,  0.1067,  0.0678],\n",
            "          [-0.0093, -0.1035,  0.1966,  ...,  0.0106,  0.0869,  0.0622]],\n",
            "\n",
            "         [[ 0.0680,  0.0352, -0.0841,  ..., -0.2098, -0.0358, -0.0302],\n",
            "          [-0.0357, -0.3821,  0.2241,  ...,  0.3616,  0.4295,  0.4514],\n",
            "          [ 0.0301, -0.2497, -0.0354,  ...,  0.0297, -0.0317,  0.7328],\n",
            "          ...,\n",
            "          [ 0.0858,  0.1303, -0.0432,  ...,  0.0291,  0.0161,  0.0297],\n",
            "          [ 0.1237,  0.1732, -0.0315,  ...,  0.0541,  0.0295,  0.0040],\n",
            "          [-0.0310,  0.1896, -0.0175,  ...,  0.0788,  0.0155,  0.0872]],\n",
            "\n",
            "         [[-0.0705,  0.1767, -0.0862,  ..., -0.1917, -0.2027,  0.0992],\n",
            "          [-0.0665,  0.1299,  0.0303,  ...,  0.0143, -0.4101,  0.5465],\n",
            "          [ 0.1371,  0.0739, -0.1126,  ..., -0.3650,  0.1408,  0.2808],\n",
            "          ...,\n",
            "          [-0.0818,  0.0873,  0.2037,  ...,  0.0653,  0.0819, -0.0047],\n",
            "          [ 0.0498,  0.2575,  0.0330,  ...,  0.1342,  0.0519,  0.0905],\n",
            "          [ 0.1398,  0.1002, -0.1263,  ...,  0.0538,  0.0131,  0.0344]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0611, -0.3183,  0.0203,  ..., -0.4761,  0.0422, -0.1001],\n",
            "          [ 0.2058,  0.3657, -0.3755,  ...,  0.1740,  0.6122, -0.1278],\n",
            "          [ 0.0938,  0.2619, -0.0346,  ..., -0.1542, -0.6513,  0.5183],\n",
            "          ...,\n",
            "          [-0.0700, -0.0143, -0.3635,  ...,  0.0224, -0.1255, -0.0085],\n",
            "          [-0.0063,  0.0237,  0.1213,  ...,  0.0111,  0.0029, -0.0623],\n",
            "          [-0.0460,  0.0601, -0.1384,  ...,  0.0099, -0.0420, -0.0280]],\n",
            "\n",
            "         [[-0.0319, -0.1030, -0.1465,  ...,  0.3971, -0.2006, -0.1819],\n",
            "          [-0.0349, -0.1229,  0.0756,  ...,  0.3998,  0.9474, -0.0329],\n",
            "          [-0.1579,  0.0205, -0.0475,  ...,  0.1214,  0.0196, -0.0253],\n",
            "          ...,\n",
            "          [ 0.2011, -0.0824, -0.2493,  ..., -0.0127, -0.0790, -0.0050],\n",
            "          [-0.0208,  0.0559,  0.0574,  ...,  0.0244,  0.0051, -0.0336],\n",
            "          [-0.1337,  0.0484, -0.0583,  ...,  0.0015, -0.0091,  0.0058]],\n",
            "\n",
            "         [[-0.1172,  0.1378,  0.0639,  ...,  0.1729, -0.1746,  0.1503],\n",
            "          [-0.1601,  0.1178, -0.2812,  ..., -0.0637, -0.0078, -0.1427],\n",
            "          [ 0.0198,  0.2811, -0.2756,  ...,  0.2096, -0.4626,  0.1863],\n",
            "          ...,\n",
            "          [ 0.1010, -0.0577, -0.0452,  ..., -0.0612, -0.0261, -0.0037],\n",
            "          [ 0.0113, -0.0117, -0.0034,  ..., -0.0104, -0.0284, -0.0095],\n",
            "          [-0.0544, -0.1743, -0.1839,  ..., -0.0395, -0.0683, -0.0065]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-0.0229,  0.1080,  0.0363,  ...,  0.0621,  0.0206,  0.0790],\n",
            "          [ 0.0894, -0.2060, -0.1991,  ...,  0.1177,  0.0720,  0.0269],\n",
            "          [ 0.0549, -0.1168, -0.0260,  ...,  0.1158,  0.0678,  0.0849],\n",
            "          ...,\n",
            "          [ 0.0995,  0.1001,  0.0489,  ..., -0.0635,  0.0637,  0.0265],\n",
            "          [ 0.0539,  0.0691,  0.0349,  ...,  0.1427,  0.0286, -0.0207],\n",
            "          [ 0.0468,  0.0655,  0.0427,  ..., -0.0207, -0.0619, -0.0273]],\n",
            "\n",
            "         [[ 0.0964,  0.4034, -0.2509,  ..., -0.1142,  0.0590,  0.0421],\n",
            "          [ 0.0283,  0.1895, -0.5688,  ..., -0.0206,  0.1707, -0.1517],\n",
            "          [-0.0462,  0.0704, -0.1261,  ...,  0.0486,  0.0051,  0.0597],\n",
            "          ...,\n",
            "          [-0.0228,  0.0089,  0.0834,  ...,  0.0190, -0.1064,  0.0764],\n",
            "          [ 0.0507,  0.0138,  0.0057,  ..., -0.0960,  0.0782, -0.0230],\n",
            "          [ 0.0447,  0.0427, -0.0162,  ...,  0.0378,  0.1316,  0.0526]],\n",
            "\n",
            "         [[-0.0107, -0.1651,  0.1112,  ...,  0.0296,  0.0098,  0.0048],\n",
            "          [-0.0437,  0.0837,  0.0936,  ...,  0.1430, -0.0344,  0.1262],\n",
            "          [ 0.0060,  0.0867, -0.0604,  ..., -0.0757,  0.0775,  0.0130],\n",
            "          ...,\n",
            "          [ 0.0727,  0.0931, -0.0602,  ..., -0.0759,  0.1052, -0.1147],\n",
            "          [-0.0067,  0.0706,  0.0350,  ..., -0.0085, -0.0367,  0.0652],\n",
            "          [ 0.0201,  0.1472,  0.0269,  ..., -0.0712, -0.0755,  0.0306]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1383, -0.0615, -0.0677,  ..., -0.0177,  0.1005, -0.0616],\n",
            "          [-0.1671, -0.1541, -0.1999,  ...,  0.0275,  0.0423, -0.1830],\n",
            "          [-0.0938, -0.0881, -0.6352,  ..., -0.0239,  0.2057, -0.0331],\n",
            "          ...,\n",
            "          [ 0.0102, -0.0620,  0.0158,  ..., -0.0406, -0.0114, -0.0127],\n",
            "          [-0.0543, -0.0226,  0.0613,  ..., -0.0639, -0.1352, -0.0416],\n",
            "          [-0.0476, -0.1027, -0.0428,  ..., -0.0523,  0.0515,  0.0752]],\n",
            "\n",
            "         [[ 0.1086,  0.0642,  0.2079,  ..., -0.0773,  0.0229, -0.0423],\n",
            "          [-0.0729, -0.0281,  0.3139,  ..., -0.0627, -0.2233,  0.0291],\n",
            "          [-0.0307, -0.1011, -0.1260,  ...,  0.0407,  0.0851, -0.0156],\n",
            "          ...,\n",
            "          [-0.0223, -0.0066, -0.0263,  ..., -0.1379,  0.1257, -0.0671],\n",
            "          [-0.0208,  0.0309,  0.0437,  ..., -0.0574, -0.1301, -0.0053],\n",
            "          [-0.0360, -0.0416, -0.0567,  ..., -0.0205,  0.1023,  0.0321]],\n",
            "\n",
            "         [[ 0.0014,  0.1491,  0.1442,  ...,  0.0920,  0.0153, -0.0571],\n",
            "          [ 0.0289,  0.0875, -0.2958,  ..., -0.1327,  0.1100, -0.2210],\n",
            "          [ 0.0196,  0.1045, -0.0706,  ...,  0.0661,  0.0938,  0.0375],\n",
            "          ...,\n",
            "          [ 0.0171,  0.0030,  0.0523,  ...,  0.0141, -0.0380,  0.1231],\n",
            "          [-0.0303,  0.0899,  0.0485,  ...,  0.0332, -0.0658, -0.1130],\n",
            "          [ 0.0059, -0.0675, -0.0371,  ..., -0.0125, -0.0101,  0.0098]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 1.0251e-02,  5.3120e-02, -6.3644e-03,  ..., -2.9203e-01,\n",
            "           -7.8226e-02,  2.6428e-02],\n",
            "          [ 2.2478e-02,  2.3831e-02,  8.9473e-02,  ..., -1.3400e-02,\n",
            "            9.9307e-02, -3.5312e-02],\n",
            "          [ 9.0722e-03, -4.6611e-02,  2.0499e-02,  ..., -1.0832e-01,\n",
            "            8.6591e-02,  6.2955e-02],\n",
            "          ...,\n",
            "          [ 7.8587e-02, -2.8759e-01,  3.8515e-01,  ..., -4.8061e-02,\n",
            "            9.5484e-03, -1.8829e-03],\n",
            "          [-2.4210e-02,  8.9960e-02, -4.0336e-01,  ...,  9.4402e-04,\n",
            "           -5.4045e-02, -4.1213e-02],\n",
            "          [ 1.4817e-01, -4.0304e-02, -2.5964e-01,  ..., -2.6924e-02,\n",
            "           -2.1240e-02,  1.0907e-02]],\n",
            "\n",
            "         [[ 1.0273e-02,  1.9197e-02,  3.9993e-02,  ..., -4.2215e-02,\n",
            "            1.8028e-01, -7.9325e-02],\n",
            "          [ 8.1846e-02, -9.3798e-02,  1.0308e-01,  ..., -1.6804e-01,\n",
            "            3.7601e-02,  1.1869e-02],\n",
            "          [ 6.4890e-02,  1.3797e-01,  3.6098e-02,  ...,  4.8961e-03,\n",
            "            3.1745e-02,  1.7756e-01],\n",
            "          ...,\n",
            "          [ 6.0810e-02, -6.8917e-01,  6.8387e-01,  ..., -8.8355e-03,\n",
            "            8.6754e-02,  2.6153e-02],\n",
            "          [ 9.7016e-02,  2.3682e-01, -2.2044e-02,  ...,  6.9410e-02,\n",
            "            8.1678e-02,  8.2379e-03],\n",
            "          [-8.7226e-02,  5.7102e-02,  3.1972e-01,  ..., -3.7220e-02,\n",
            "            9.2542e-02, -1.6783e-02]],\n",
            "\n",
            "         [[ 1.8730e-02,  6.4416e-02,  3.0818e-02,  ...,  6.5900e-02,\n",
            "           -3.3697e-02,  1.3652e-01],\n",
            "          [ 2.5112e-02, -2.0630e-02,  4.2412e-02,  ...,  2.9213e-01,\n",
            "            1.4105e-02, -7.6632e-02],\n",
            "          [ 8.9497e-03,  7.3864e-02, -2.2183e-02,  ...,  8.7438e-02,\n",
            "           -6.0459e-02,  3.8087e-02],\n",
            "          ...,\n",
            "          [-6.5944e-02, -1.8458e-01,  2.0476e-01,  ...,  3.3209e-02,\n",
            "            4.3616e-02,  5.6495e-02],\n",
            "          [ 7.0025e-02,  9.9618e-02,  2.8457e-01,  ...,  3.8726e-02,\n",
            "            6.3918e-02,  4.4590e-02],\n",
            "          [-1.0925e-01, -4.6610e-01,  1.2608e-01,  ..., -1.5455e-02,\n",
            "            3.9836e-02,  4.0106e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0581e-01,  1.6250e-01,  1.1295e-01,  ..., -1.4580e-02,\n",
            "            1.3323e-01, -4.8402e-02],\n",
            "          [ 1.5852e-01, -4.3526e-02,  7.2805e-02,  ...,  1.9395e-01,\n",
            "           -2.2250e-01,  2.8165e-01],\n",
            "          [ 1.1259e-01,  1.7266e-01,  1.1327e-01,  ...,  4.2754e-03,\n",
            "            1.3874e-01,  8.3646e-02],\n",
            "          ...,\n",
            "          [ 3.4490e-02, -6.4222e-01, -2.9129e-02,  ...,  5.1908e-02,\n",
            "            1.1191e-01,  5.1910e-02],\n",
            "          [ 4.6907e-02,  1.9397e-01, -4.3163e-02,  ...,  7.1667e-02,\n",
            "            5.2530e-02,  5.3454e-02],\n",
            "          [-1.5723e-02,  9.1165e-02,  3.5918e-01,  ...,  1.4152e-01,\n",
            "            9.1025e-02,  1.0652e-01]],\n",
            "\n",
            "         [[ 1.1233e-02, -4.0939e-02, -6.1166e-04,  ..., -1.9871e-02,\n",
            "           -4.6431e-02,  1.1123e-01],\n",
            "          [-3.6651e-02,  1.3680e-01, -1.8955e-02,  ..., -5.9670e-02,\n",
            "           -1.3808e-01, -1.4342e-01],\n",
            "          [-8.2752e-03, -9.6744e-02,  2.4487e-03,  ...,  2.0259e-01,\n",
            "           -8.7585e-02,  2.4342e-01],\n",
            "          ...,\n",
            "          [ 8.8746e-02,  2.6531e-01,  2.6946e-01,  ..., -2.8504e-02,\n",
            "            5.2352e-02,  1.5208e-02],\n",
            "          [-1.5580e-01, -4.2704e-01,  1.5223e-01,  ..., -7.0711e-03,\n",
            "           -1.1999e-02, -6.2373e-02],\n",
            "          [ 1.1387e-01, -3.7229e-02, -2.7868e-01,  ...,  7.2026e-03,\n",
            "           -3.0457e-02, -3.6552e-02]],\n",
            "\n",
            "         [[-1.2150e-02, -4.1026e-02,  4.7990e-03,  ...,  2.7208e-01,\n",
            "            1.4344e-01,  8.9387e-02],\n",
            "          [ 7.5266e-02,  6.4921e-02, -1.4885e-01,  ..., -2.3025e-01,\n",
            "           -1.9069e-01,  8.5192e-02],\n",
            "          [-1.8987e-02,  1.2911e-01,  1.8738e-02,  ..., -2.5092e-01,\n",
            "           -7.0198e-02, -3.8667e-03],\n",
            "          ...,\n",
            "          [ 1.5679e-01,  5.8296e-01, -6.6170e-02,  ...,  6.2603e-02,\n",
            "            1.0908e-02, -2.4384e-02],\n",
            "          [-1.1811e-01,  3.9950e-01,  1.9537e-01,  ...,  4.8186e-02,\n",
            "            3.2042e-03,  2.0566e-04],\n",
            "          [-2.3661e-01,  1.1079e-01,  1.5319e-01,  ...,  5.0207e-02,\n",
            "           -2.6883e-02, -6.2517e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 7.0573e-02,  1.1859e-01,  7.2089e-02,  ...,  5.5183e-02,\n",
            "            6.1878e-02,  1.3320e-02],\n",
            "          [ 1.2487e-01,  1.4145e-01,  1.7942e-01,  ..., -5.3134e-02,\n",
            "            1.4638e-01,  9.9770e-02],\n",
            "          [ 6.5595e-02, -5.2402e-02,  9.5207e-03,  ...,  6.7637e-03,\n",
            "            6.1981e-02,  2.9486e-02],\n",
            "          ...,\n",
            "          [-2.1138e-02,  9.8633e-02, -2.3280e-02,  ...,  1.1285e-01,\n",
            "            3.9827e-02,  1.1638e-01],\n",
            "          [ 1.8345e-01,  1.0433e-01,  3.3724e-02,  ...,  6.6608e-02,\n",
            "            6.6237e-02,  8.4186e-02],\n",
            "          [ 1.6282e-01,  1.7030e-01, -3.8500e-02,  ...,  9.0111e-02,\n",
            "            7.7079e-02,  6.7402e-02]],\n",
            "\n",
            "         [[ 1.4995e-02, -3.5243e-02, -1.4026e-04,  ...,  8.8151e-02,\n",
            "            5.6802e-02,  6.0439e-02],\n",
            "          [ 2.1559e-02,  3.0164e-02, -7.7321e-02,  ...,  2.3546e-01,\n",
            "            9.9296e-02,  9.4791e-02],\n",
            "          [ 2.1860e-02, -4.7339e-02, -1.1836e-03,  ..., -1.3309e-01,\n",
            "            7.2206e-02, -1.1050e-02],\n",
            "          ...,\n",
            "          [ 1.8260e-02,  6.1719e-01,  5.7113e-02,  ..., -5.9775e-02,\n",
            "           -6.0557e-03,  2.4356e-02],\n",
            "          [ 3.9958e-02,  2.0628e-02,  6.7335e-02,  ...,  1.2805e-02,\n",
            "           -1.0809e-03,  8.7488e-03],\n",
            "          [ 1.6528e-01, -6.5758e-02, -1.4227e-01,  ...,  3.4334e-02,\n",
            "            8.0758e-03,  1.7253e-02]],\n",
            "\n",
            "         [[ 4.2475e-02,  7.9149e-03,  2.9515e-03,  ...,  1.3233e-01,\n",
            "            8.1452e-02,  3.5085e-02],\n",
            "          [ 7.8480e-02,  7.4386e-02,  7.8580e-02,  ..., -4.8755e-02,\n",
            "            4.6026e-02,  1.3644e-01],\n",
            "          [ 8.5540e-02,  1.6776e-01,  1.2436e-01,  ..., -9.3601e-03,\n",
            "            9.6799e-02,  8.6654e-02],\n",
            "          ...,\n",
            "          [ 2.7660e-01,  1.0189e-01, -7.6066e-02,  ...,  6.2538e-02,\n",
            "            5.2442e-02,  2.8540e-02],\n",
            "          [-4.8471e-02,  1.7454e-01,  4.3414e-02,  ...,  4.6208e-02,\n",
            "            4.6867e-02,  3.7774e-02],\n",
            "          [ 1.2038e-01,  1.4355e-01,  4.4567e-02,  ...,  2.7318e-02,\n",
            "            5.6838e-02,  2.9360e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.2614e-02, -1.3958e-01,  3.9719e-03,  ..., -4.3175e-02,\n",
            "           -8.7060e-02, -7.1867e-02],\n",
            "          [-8.9534e-02, -1.6849e-02, -1.5527e-01,  ..., -2.3104e-01,\n",
            "           -1.6144e-01,  5.4305e-02],\n",
            "          [-6.7259e-02, -1.1393e-01, -4.3854e-02,  ..., -1.6501e-01,\n",
            "           -4.0390e-02, -1.9719e-01],\n",
            "          ...,\n",
            "          [-5.5496e-01,  4.7652e-01, -8.6843e-02,  ..., -1.4315e-01,\n",
            "           -3.4046e-02, -1.4424e-01],\n",
            "          [ 2.1806e-01, -1.7366e-01, -1.2491e-01,  ..., -3.0266e-02,\n",
            "           -7.8020e-02, -3.0800e-02],\n",
            "          [-2.0334e-01,  1.6189e-01, -3.2562e-02,  ..., -1.0133e-01,\n",
            "           -4.9550e-02, -9.7288e-02]],\n",
            "\n",
            "         [[ 1.9649e-02,  2.0981e-02,  6.2021e-02,  ..., -2.3031e-02,\n",
            "            5.0288e-03,  2.3836e-02],\n",
            "          [ 6.4944e-02, -1.2672e-02,  1.6244e-01,  ...,  4.5866e-02,\n",
            "           -1.0209e-01,  1.5701e-01],\n",
            "          [ 4.3989e-02,  7.9541e-02,  8.7723e-02,  ...,  9.4607e-02,\n",
            "           -1.0311e-02, -2.2926e-03],\n",
            "          ...,\n",
            "          [-1.9927e-01,  1.3614e-01, -3.3787e-01,  ...,  2.3487e-02,\n",
            "            5.6322e-02, -2.4226e-02],\n",
            "          [ 1.8563e-01,  8.0517e-02, -4.7713e-02,  ...,  2.1119e-02,\n",
            "            3.0255e-02,  4.3275e-02],\n",
            "          [ 1.9788e-03, -5.3885e-02, -9.4438e-02,  ...,  4.0133e-02,\n",
            "            3.7001e-02,  4.3033e-02]],\n",
            "\n",
            "         [[ 5.2211e-02,  1.5050e-01,  1.1857e-01,  ...,  1.0114e-02,\n",
            "            1.2810e-01,  7.5623e-02],\n",
            "          [ 4.9887e-02, -1.9714e-02,  7.3238e-02,  ...,  2.0253e-01,\n",
            "            7.0615e-02,  1.0644e-01],\n",
            "          [ 6.9697e-02,  1.6029e-01,  6.1886e-02,  ...,  1.7894e-01,\n",
            "            1.1999e-01,  1.1149e-01],\n",
            "          ...,\n",
            "          [ 1.5485e-01,  1.1691e-01,  1.5665e-02,  ...,  8.7559e-02,\n",
            "            4.5937e-02,  9.5395e-02],\n",
            "          [ 2.4017e-01,  1.1046e-01,  1.3879e-01,  ...,  4.1187e-02,\n",
            "            4.4982e-02,  6.8551e-02],\n",
            "          [-7.1652e-03, -1.7644e-01, -2.4072e-02,  ...,  1.0428e-01,\n",
            "            7.3466e-02,  6.2273e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[-6.5777e-02,  6.9373e-02,  2.2009e-01,  ..., -4.2622e-03,\n",
            "            2.4274e-01,  2.0338e-01],\n",
            "          [-2.6648e-01, -7.3739e-01, -2.4464e-01,  ..., -1.1632e+00,\n",
            "           -5.5923e-01, -5.2041e-01],\n",
            "          [-4.2036e-01, -4.1847e-03, -9.1700e-02,  ..., -3.3447e-01,\n",
            "           -5.1333e-01, -8.5775e-02],\n",
            "          ...,\n",
            "          [-4.2139e-02, -1.0275e-01, -3.2623e-01,  ..., -2.4961e-01,\n",
            "           -1.7164e-01, -1.4791e-01],\n",
            "          [ 1.8954e-03,  1.6759e-01,  1.5500e-01,  ..., -7.3778e-02,\n",
            "           -9.8888e-02,  3.1641e-02],\n",
            "          [ 1.2838e-01,  2.3224e-01, -2.0583e-01,  ...,  9.4796e-02,\n",
            "           -1.5529e-02,  5.7101e-02]],\n",
            "\n",
            "         [[-1.9401e-02, -1.0789e-01, -8.5414e-02,  ...,  7.4006e-02,\n",
            "           -3.7013e-02, -1.0416e-01],\n",
            "          [-5.7949e-01,  7.6041e-01,  2.9058e-01,  ...,  1.3271e-01,\n",
            "            3.6953e-01, -2.7369e-01],\n",
            "          [ 2.6889e-01,  4.1234e-01, -2.0755e-01,  ...,  6.2545e-01,\n",
            "            3.1798e-01,  3.2869e-01],\n",
            "          ...,\n",
            "          [-1.1339e-01,  4.7365e-02,  1.4222e-02,  ...,  1.3842e-02,\n",
            "            8.2605e-04, -2.4299e-02],\n",
            "          [ 1.6789e-01,  2.1111e-01, -7.7736e-02,  ...,  5.7482e-02,\n",
            "            9.4016e-02,  1.0741e-01],\n",
            "          [ 1.6776e-01,  5.0142e-02, -7.4410e-02,  ...,  1.0686e-01,\n",
            "           -7.8256e-02,  2.9703e-02]],\n",
            "\n",
            "         [[-1.0062e-01, -7.4720e-02,  2.2690e-01,  ..., -9.0322e-02,\n",
            "           -5.0890e-02, -9.2450e-02],\n",
            "          [ 1.2311e-01, -1.2532e-01,  6.4891e-01,  ...,  2.1876e-02,\n",
            "            3.1544e-01,  2.7644e-01],\n",
            "          [ 6.0064e-01, -1.8341e+00, -6.6868e-01,  ..., -9.6502e-01,\n",
            "           -2.7578e-01,  5.9189e-02],\n",
            "          ...,\n",
            "          [-1.0225e-01,  1.0411e-01, -1.6862e-01,  ...,  1.1882e-01,\n",
            "            1.0852e-02, -4.2156e-02],\n",
            "          [ 1.3395e-01, -7.2047e-02, -2.8068e-01,  ..., -1.9261e-01,\n",
            "           -4.8075e-02, -4.6302e-02],\n",
            "          [-7.3196e-02,  4.0786e-01, -1.0170e-01,  ...,  5.2467e-02,\n",
            "           -2.3182e-01, -9.8835e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.5361e-02, -4.0418e-01,  1.9131e-01,  ..., -2.3043e-01,\n",
            "           -4.7983e-02, -1.9928e-01],\n",
            "          [ 1.1955e-01,  4.9605e-01,  2.3408e-01,  ...,  6.2289e-02,\n",
            "            1.3129e-01, -1.0968e-01],\n",
            "          [ 6.7485e-01, -6.8580e-01,  1.9882e-01,  ..., -1.7925e-01,\n",
            "            4.4283e-01, -2.0798e-01],\n",
            "          ...,\n",
            "          [ 1.8253e-01,  5.9901e-02,  1.9045e-01,  ..., -4.9925e-02,\n",
            "            7.3532e-02,  8.1709e-02],\n",
            "          [ 1.3600e-01,  1.3414e-02,  4.6830e-02,  ...,  1.0151e-02,\n",
            "            1.6036e-01, -2.0249e-02],\n",
            "          [ 3.3725e-02, -4.9353e-02,  1.9038e-01,  ..., -9.2338e-02,\n",
            "            4.7770e-02,  1.1396e-02]],\n",
            "\n",
            "         [[ 3.7931e-01, -4.1799e-01,  1.2215e-02,  ..., -1.8853e-01,\n",
            "            2.0444e-02, -4.2011e-02],\n",
            "          [ 7.4440e-01, -2.1880e-02,  4.4876e-01,  ...,  1.5005e-01,\n",
            "            7.1586e-01, -2.2894e-01],\n",
            "          [ 3.2396e-02,  5.2251e-01,  6.4732e-01,  ..., -7.3941e-02,\n",
            "            5.4283e-01,  6.1959e-02],\n",
            "          ...,\n",
            "          [ 1.5988e-01, -2.0940e-01,  8.1986e-02,  ...,  4.3566e-02,\n",
            "            2.1716e-01,  6.3589e-02],\n",
            "          [-5.9429e-02, -1.3800e-01,  1.2951e-01,  ...,  1.6634e-02,\n",
            "            1.4645e-01, -1.5391e-02],\n",
            "          [-1.0976e-02, -2.4503e-01, -5.3896e-02,  ...,  3.2271e-02,\n",
            "           -1.7212e-02,  5.0324e-02]],\n",
            "\n",
            "         [[-8.8027e-02,  2.5427e-01, -5.9526e-02,  ...,  2.1733e-01,\n",
            "           -3.3280e-02,  1.5092e-01],\n",
            "          [-9.7675e-01,  1.9528e-01,  6.4068e-01,  ..., -6.7136e-01,\n",
            "            1.7222e-01,  5.4120e-01],\n",
            "          [-2.5967e-01, -9.1432e-01, -1.1553e-01,  ..., -4.3731e-01,\n",
            "           -9.8352e-03,  2.5863e-01],\n",
            "          ...,\n",
            "          [-4.6470e-01, -9.0552e-02, -1.4022e-02,  ..., -1.5962e-01,\n",
            "           -8.1349e-02,  1.3099e-01],\n",
            "          [-8.4806e-03, -4.3482e-01, -4.4490e-02,  ..., -1.4417e-01,\n",
            "           -4.5090e-02,  3.4308e-02],\n",
            "          [ 6.7601e-02, -2.7069e-01, -1.2784e-01,  ..., -1.6506e-01,\n",
            "           -1.5332e-01, -7.7609e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 1.1915e-01, -1.7254e-01,  1.1446e-01,  ..., -5.7492e-02,\n",
            "           -2.6710e-02, -1.5034e-02],\n",
            "          [ 2.3580e-01, -2.6002e-01, -1.1110e-01,  ..., -4.5563e-01,\n",
            "            2.5985e-01,  1.3574e-01],\n",
            "          [ 9.8035e-02,  3.8515e-01, -4.1457e-01,  ...,  1.6187e-02,\n",
            "            5.3012e-02, -4.8606e-02],\n",
            "          ...,\n",
            "          [-4.9422e-02, -2.3626e-01,  1.9214e-01,  ..., -1.3103e-01,\n",
            "           -1.6175e-02,  7.3538e-02],\n",
            "          [ 4.2154e-02,  1.7560e-01,  3.5519e-02,  ..., -7.5991e-02,\n",
            "           -7.7085e-02, -6.9413e-02],\n",
            "          [ 5.1571e-02, -9.0626e-02, -2.1243e-01,  ..., -1.3417e-02,\n",
            "           -1.4746e-02, -8.2233e-03]],\n",
            "\n",
            "         [[-1.6032e-01,  2.7374e-01, -1.6751e-01,  ..., -3.1144e-02,\n",
            "           -1.6272e-01,  1.9980e-02],\n",
            "          [ 2.3793e-01, -7.9724e-01,  5.3529e-01,  ..., -5.4917e-01,\n",
            "           -6.7786e-02,  1.0097e-02],\n",
            "          [ 5.6504e-02,  3.1901e-01, -8.1493e-01,  ...,  5.6779e-02,\n",
            "           -1.7250e-01, -4.6488e-02],\n",
            "          ...,\n",
            "          [-3.2449e-02, -1.1625e-01,  5.3149e-02,  ..., -4.3669e-01,\n",
            "           -3.7558e-03, -6.3948e-02],\n",
            "          [ 1.0108e-01, -5.6980e-02,  1.5055e-01,  ...,  2.7357e-02,\n",
            "           -1.6134e-01, -1.9752e-02],\n",
            "          [-2.4280e-01, -7.0039e-02,  5.4668e-02,  ..., -6.5928e-02,\n",
            "           -9.7912e-04, -4.0993e-02]],\n",
            "\n",
            "         [[-2.0219e-01, -2.8043e-01, -8.0951e-02,  ..., -2.0670e-01,\n",
            "           -8.9472e-02,  7.2665e-02],\n",
            "          [ 3.8359e-01,  3.9972e-01,  1.1570e-01,  ...,  9.0390e-02,\n",
            "            3.1613e-01, -1.0131e-01],\n",
            "          [ 2.1164e-01, -1.1272e+00, -1.7914e-01,  ..., -3.2253e-01,\n",
            "            4.5082e-02, -2.3101e-01],\n",
            "          ...,\n",
            "          [ 1.9447e-01, -4.0839e-01,  2.3379e-01,  ...,  2.9284e-01,\n",
            "            1.4163e-01,  1.8775e-02],\n",
            "          [ 3.1176e-01,  1.6886e-02,  4.2996e-01,  ..., -4.7572e-02,\n",
            "           -7.9278e-02, -9.8023e-02],\n",
            "          [ 2.1597e-01,  1.0859e-01,  3.1557e-01,  ..., -7.0586e-02,\n",
            "           -1.0002e-02, -4.2069e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9013e-01, -2.9669e-01,  2.1532e-01,  ..., -2.8092e-01,\n",
            "            6.1104e-02, -8.6519e-02],\n",
            "          [ 1.7118e-01, -9.5669e-02,  5.1492e-01,  ...,  1.7840e-01,\n",
            "            1.8989e-02, -2.0951e-02],\n",
            "          [-2.3654e-01, -1.2354e-01, -3.6512e-01,  ..., -4.9690e-02,\n",
            "           -1.3930e-01, -2.0656e-02],\n",
            "          ...,\n",
            "          [ 1.6285e-01, -2.7531e-01, -2.5969e-01,  ..., -1.1439e-01,\n",
            "            1.3769e-02, -2.4137e-01],\n",
            "          [-8.9658e-02, -3.9720e-02,  1.3612e-01,  ...,  4.4403e-03,\n",
            "           -6.0009e-02, -2.0014e-02],\n",
            "          [ 1.5331e-01, -5.0832e-01,  6.3346e-02,  ...,  7.4098e-02,\n",
            "           -2.7312e-02,  5.1440e-02]],\n",
            "\n",
            "         [[ 5.1109e-02, -1.4191e-01,  1.4066e-01,  ..., -6.9912e-02,\n",
            "            4.7377e-02, -9.1090e-02],\n",
            "          [ 1.6069e-01,  6.0966e-02,  5.7170e-03,  ...,  2.5783e-01,\n",
            "            2.0033e-01,  3.7048e-01],\n",
            "          [-1.8558e-01,  8.1282e-01,  4.2605e-03,  ...,  2.6407e-01,\n",
            "            4.1211e-02,  4.0645e-02],\n",
            "          ...,\n",
            "          [ 1.0729e-01,  6.0246e-01,  4.5967e-01,  ..., -1.9704e-01,\n",
            "           -3.5485e-02,  5.5405e-02],\n",
            "          [-1.0342e-01,  3.4908e-01, -2.6160e-01,  ..., -6.1146e-03,\n",
            "            2.6537e-02, -8.5425e-02],\n",
            "          [ 9.0749e-02, -4.3652e-01,  7.8735e-02,  ..., -2.1951e-01,\n",
            "           -1.6007e-01, -1.1962e-01]],\n",
            "\n",
            "         [[ 2.5580e-01,  3.9245e-01, -1.2183e-01,  ...,  1.9481e-01,\n",
            "           -5.6501e-03,  3.2038e-02],\n",
            "          [-7.4399e-01, -2.9552e-01,  4.8799e-01,  ...,  2.8097e-02,\n",
            "            1.0977e-01,  2.9658e-01],\n",
            "          [ 3.6329e-01,  5.5518e-01, -5.9803e-02,  ...,  2.2671e-01,\n",
            "            4.3250e-02,  1.6309e-02],\n",
            "          ...,\n",
            "          [-2.5180e-01,  2.4453e-01,  1.1378e-01,  ..., -2.8864e-02,\n",
            "            8.2884e-02,  1.8909e-01],\n",
            "          [ 1.9788e-01,  7.4614e-02, -1.2362e-01,  ..., -9.4752e-03,\n",
            "            9.6128e-02, -4.2538e-03],\n",
            "          [ 3.8322e-01, -1.6971e-03,  1.3955e-01,  ...,  2.8200e-02,\n",
            "           -1.6789e-02,  8.6853e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
            "tensor([[[[ 0.1208, -0.0214,  0.1312,  ..., -0.1240, -0.0476,  0.0125],\n",
            "          [ 0.1121,  0.0048,  0.2583,  ...,  0.0084,  0.3705, -0.1516],\n",
            "          [ 0.1648,  0.3784,  0.0964,  ...,  0.2533,  0.1925, -0.3077],\n",
            "          ...,\n",
            "          [-0.0489,  0.0615, -0.1457,  ..., -0.0054,  0.0719,  0.0351],\n",
            "          [ 0.1474,  0.1757,  0.1514,  ...,  0.0118,  0.0035,  0.0770],\n",
            "          [ 0.2204, -0.3524, -0.0457,  ...,  0.2052,  0.0773,  0.0155]],\n",
            "\n",
            "         [[-0.1135, -0.3438, -0.0356,  ..., -0.2446, -0.0565,  0.0307],\n",
            "          [-0.0975,  0.3114,  0.2277,  ..., -0.0690,  0.0999, -0.1267],\n",
            "          [ 0.1529, -0.1727, -0.0325,  ...,  0.0206,  0.0456, -0.1205],\n",
            "          ...,\n",
            "          [-0.0292, -0.2856, -0.1858,  ..., -0.0417,  0.0121, -0.0210],\n",
            "          [-0.1947,  0.1872, -0.1704,  ..., -0.0184,  0.0275,  0.0329],\n",
            "          [ 0.0097,  0.1792, -0.0697,  ..., -0.1481, -0.0221, -0.0387]],\n",
            "\n",
            "         [[-0.0161,  0.2448,  0.2015,  ...,  0.0936,  0.0943,  0.1863],\n",
            "          [-0.0294, -0.0554,  0.1258,  ...,  0.3995,  0.1440,  0.2541],\n",
            "          [-0.0145, -0.2842, -0.1945,  ..., -0.4135,  0.0517, -0.0103],\n",
            "          ...,\n",
            "          [ 0.0597,  0.0928, -0.0304,  ...,  0.0943, -0.0038, -0.0455],\n",
            "          [-0.0679, -0.0182,  0.0589,  ...,  0.0241,  0.0348,  0.0387],\n",
            "          [-0.0084,  0.3637, -0.0721,  ..., -0.1085,  0.0604, -0.0358]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0719,  0.2478,  0.0028,  ...,  0.1254, -0.0259, -0.1802],\n",
            "          [ 0.0455, -0.4769, -0.0182,  ..., -0.5415,  0.1810, -0.1121],\n",
            "          [ 0.0892,  0.1929,  0.2758,  ..., -0.0090,  0.0310,  0.0601],\n",
            "          ...,\n",
            "          [-0.0780,  0.3421, -0.0780,  ..., -0.1606,  0.0307, -0.0421],\n",
            "          [-0.1243, -0.3589, -0.3673,  ...,  0.1291,  0.0623, -0.0183],\n",
            "          [ 0.0298,  0.3223, -0.1688,  ..., -0.0591,  0.0218,  0.0075]],\n",
            "\n",
            "         [[-0.0655,  0.3540, -0.0936,  ...,  0.1381, -0.2107,  0.0317],\n",
            "          [-0.0298, -0.2258, -0.0469,  ..., -0.2164,  0.1570,  0.0408],\n",
            "          [ 0.1226,  0.0149, -0.0990,  ..., -0.1625,  0.0912, -0.0396],\n",
            "          ...,\n",
            "          [-0.2220, -0.0046,  0.1269,  ..., -0.1250, -0.1141,  0.0642],\n",
            "          [-0.1020, -0.2445, -0.0896,  ..., -0.0321, -0.0818,  0.0148],\n",
            "          [-0.1415, -0.3031, -0.1891,  ...,  0.0303, -0.0154,  0.0171]],\n",
            "\n",
            "         [[ 0.0312,  0.0215, -0.0151,  ...,  0.0817, -0.1227, -0.0568],\n",
            "          [ 0.1698,  0.1217,  0.0304,  ...,  0.1181,  0.0359,  0.0013],\n",
            "          [ 0.3741,  0.0781,  0.0101,  ..., -0.1475,  0.1247, -0.0278],\n",
            "          ...,\n",
            "          [ 0.0751, -0.0735,  0.0591,  ...,  0.0425, -0.0022,  0.0209],\n",
            "          [-0.0213,  0.0535,  0.0270,  ...,  0.0237,  0.0173,  0.0072],\n",
            "          [-0.0366,  0.2457, -0.2384,  ..., -0.1681,  0.0875, -0.0678]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-14166369cdbc>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#trainer(parameters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultiple_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-25fe0a372f86>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(parameters, multiple_epochs, epoch_index, tb_writer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmultiple_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_multiple_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-25fe0a372f86>\u001b[0m in \u001b[0;36mtrain_multiple_epoch\u001b[0;34m(parameters, EPOCHS)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Make sure gradient tracking is on, and do a pass over the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# We don't need gradients on to do reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-25fe0a372f86>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(parameters, epoch_index, tb_writer)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Make predictions for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Compute the loss and its gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-629a2aa15d0d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#    embed = torch.reshape(h,(h.shape[0],h.shape[1]*h.shape[2]*h.shape[3]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#    embeds.append(embed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         upsample = nn.Sequential(        \n\u001b[1;32m     30\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvTranspose2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_padding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic-segmentation/semseg/models/heads/segformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"self.linear_c{i+2}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3958\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsample_bilinear2d_aa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3960\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trilinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3961\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
        "training_set = train_loader\n",
        "validation_set = test_loader\n",
        "\n",
        "parameters = {\n",
        "    'model' : model,\n",
        "    'loss' : loss_fn,\n",
        "    'optimizer' : optimizer,\n",
        "    'training' : training_set,\n",
        "    'validation' : validation_set,\n",
        "    'device' : device\n",
        "}\n",
        "#trainer(parameters)\n",
        "trainer(parameters,multiple_epochs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FZzOcvNXLK19",
        "outputId": "62b91f41-7ce3-48bb-93f7-bc77765ccc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 224, 224, 3])\n",
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 224, 224, 3])\n",
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 224, 224, 3])\n",
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 224, 224, 3])\n",
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 224, 224, 3])\n",
            "torch.Size([1, 3, 224, 224])\n",
            "torch.Size([1, 224, 224, 3])\n",
            "torch.Size([1, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e4211f26401e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Forward pass to get the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m           \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#print(prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-dae345619f8b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m#y = self.decode(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic-segmentation/semseg/models/backbones/mit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic-segmentation/semseg/models/backbones/mit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/semantic-segmentation/semseg/models/backbones/mit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFnElEQVR4nO3ZMW4iQRBA0QJZIpoLILigD+QLYs0FiEiYjfwztAR4vat9L+0OKuqvmdpt27YNAMzM/qcHAODvIQoARBQAiCgAEFEAIKIAQEQBgLw9c+l+v8+6rrMsy+x2u++eCYAX27ZtrtfrHI/H2e8ffw88FYV1Xed8Pr9sOAB+xuVymdPp9PD8qSgsyzIzM+/v73M4HF4zGQB/zO12m4+Pj97zR56Kwtcvo8PhIAoA/7DfrQAsmgGIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAeXvm0rZtMzNzu92+dRgAvsfX+/31nj+y2353Y2Y+Pz/nfD6/ZjIAfszlcpnT6fTw/Kko3O/3Wdd1lmWZ3W730gEB+H7bts31ep3j8Tj7/ePNwVNRAOD/YNEMQEQBgIgCABEFACIKAEQUAIgoAJBfMZZJVdkEd/oAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from semseg.datasets import *\n",
        "\n",
        "#model = model.to(device)\n",
        "predictions = []\n",
        "start = time.time()\n",
        "#print('test')\n",
        "# Use torch.no_grad() to disable gradient computation during testing\n",
        "with torch.no_grad():\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # Move the data to the desired device\n",
        "        print(images.shape)\n",
        "        images = images.permute(0,3,1,2).to(device)\n",
        "        #images = images.permute(2,0,1).to(device)\n",
        "        #images = images [None, :, :, :]\n",
        "        print(images.shape)\n",
        "        \n",
        "        #print(images.shape)\n",
        "        #labels = labels.to(device)\n",
        "\n",
        "        # Forward pass to get the predictions\n",
        "        with torch.inference_mode():\n",
        "          prediction = model(images)\n",
        "        #print(prediction)\n",
        "        prediction = prediction.softmax(1).argmax(1).to(int)\n",
        "        #prediction = prediction.round().to(int)\n",
        "        #print(prediction.shape)\n",
        "        un = prediction.unique()\n",
        "        #print(un)\n",
        "        palette = eval('ADE20K').PALETTE.to(device)\n",
        "        prediction_map = palette[prediction].squeeze().to(torch.uint8)\n",
        "        #print(type(prediction_map))\n",
        "        show_image(prediction_map)\n",
        "        predictions.append(prediction_map)\n",
        "        \n",
        "end = time.time()\n",
        "print(end-start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
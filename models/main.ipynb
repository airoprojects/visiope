{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_aBmzhywXBjp"
   },
   "outputs": [],
   "source": [
    " try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "b5vQ0kHSCTjj"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB  :\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mrwBo-RKXULP"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB  :\n",
    "    !git clone https://github.com/sithu31296/semantic-segmentation\n",
    "    %pip install -U gdown\n",
    "    %pip install -e .\n",
    "    import gdown\n",
    "    from pathlib import Path\n",
    "\n",
    "    ckpt = Path('./checkpoints/pretrained/segformer')\n",
    "    ckpt.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    url = 'https://drive.google.com/uc?id=1-OmW3xRD3WAbJTzktPC-VMOF5WMsN8XT'\n",
    "    output = './checkpoints/pretrained/segformer/segformer.b3.ade.pth'\n",
    "\n",
    "    gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kytW-DGR_xaS",
    "outputId": "c3de695c-4155-461d-e626-862af302610d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "if not(IN_COLAB)  :\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import io\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import gc\n",
    "from typing import Tuple\n",
    "from torch.nn import functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%cd semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kwVFZJKgXULT"
   },
   "outputs": [],
   "source": [
    "test = False\n",
    "if test:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, nc):\n",
    "            self.nc = nc\n",
    "            super(Generator, self).__init__()\n",
    "\n",
    "\n",
    "        def forward(self, embeds):\n",
    "            ngf = 64\n",
    "            nz = [[None] *6]*4\n",
    "\n",
    "            j = 0\n",
    "            for embed in embeds:\n",
    "                nz[j][0] = embed.size()[1]\n",
    "                for i in range(1,6):\n",
    "                    if i < 4:\n",
    "                        nz[j][i] = nz[i-1]//2\n",
    "                    else:\n",
    "                        nz[j][i] = nz[i-1]//4\n",
    "                j = j+1\n",
    "                print(nz)\n",
    "            self.main = nn.Sequential(\n",
    "                #reduction of dimensionality To Be Changed in conv... maybe\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d( nz[6], ngf * 8, 4, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 8),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*8) x 4 x 4``\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 4),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*4) x 8 x 8``\n",
    "                nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf * 2),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf*2) x 16 x 16``\n",
    "                nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "                nn.BatchNorm2d(ngf),\n",
    "                nn.ReLU(True),\n",
    "                # state size. ``(ngf) x 32 x 32``\n",
    "                nn.ConvTranspose2d( ngf, self.nc, 4, 2, 1, bias=False),\n",
    "                nn.Tanh()\n",
    "                # state size. ``(nc) x 64 x 64``\n",
    "            )\n",
    "\n",
    "            return self.main(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        ngf = 64\n",
    "        nc = 1 \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PyC-nI41XULT"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class SegFormerHead(nn.Module):\n",
    "    def __init__(self, dims: list, embed_dim: int = 256, num_classes: int = 19):\n",
    "        super().__init__()\n",
    "        for i, dim in enumerate(dims):\n",
    "            self.add_module(f\"linear_c{i+1}\", MLP(dim, embed_dim))\n",
    "\n",
    "        self.linear_fuse = ConvModule(embed_dim*4, embed_dim)\n",
    "        self.linear_pred = nn.Conv2d(embed_dim, num_classes, 1)\n",
    "        self.dropout = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        B, _, H, W = features[0].shape\n",
    "        outs = [self.linear_c1(features[0]).permute(0, 2, 1).reshape(B, -1, *features[0].shape[-2:])]\n",
    "\n",
    "        for i, feature in enumerate(features[1:]):\n",
    "            cf = eval(f\"self.linear_c{i+2}\")(feature).permute(0, 2, 1).reshape(B, -1, *feature.shape[-2:])\n",
    "            outs.append(F.interpolate(cf, size=(H, W), mode='bilinear', align_corners=False))\n",
    "\n",
    "        seg = self.linear_fuse(torch.cat(outs[::-1], dim=1))\n",
    "        seg = self.linear_pred(self.dropout(seg))\n",
    "        return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.reshape(batch_size, -1)\n",
    "    \n",
    "class Conv2DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "    \n",
    "class Conv1DModule(nn.Module):\n",
    "    def __init__(self, cin, cout, ks, s):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(cin, cout, ks, stride=s, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(cout)        # use SyncBN in original\n",
    "        self.activate = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.activate(self.bn(self.conv(x)))\n",
    "    \n",
    "class downsample(nn.Module):\n",
    "    def __init__(self, C, H, W):\n",
    "        super().__init__()\n",
    "        self.downsample = nn.Sequential()\n",
    "        i = 0\n",
    "        alt = True\n",
    "        if H*W > 128:\n",
    "            while(C>4):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "                \n",
    "                if H//2<5 or W//2<5:\n",
    "                    print(\"H\", H)\n",
    "                    print(\"W\", W)\n",
    "                                     \n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    print(\"C\", C)  \n",
    "                    self.downsample.append(Conv1DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-1\n",
    "                    W = W-1\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2\n",
    "                    W = W//2\n",
    "\n",
    "        else:\n",
    "            while(C>16):\n",
    "\n",
    "                if H*W*C < 500:\n",
    "                    break\n",
    "                    \n",
    "                if H//2<5 or W//2<5:\n",
    "                    print(\"H\", H)\n",
    "                    print(\"W\", W)\n",
    "                    \n",
    "                    if alt:\n",
    "                        self.downsample.append(Flatten())\n",
    "                        C = C*H*W\n",
    "                        alt = False\n",
    "                    print(\"C\", C)\n",
    "                    self.downsample.append(Conv1DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                elif H//2<9 or W//2<9:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 1))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H-1\n",
    "                    W = W-1\n",
    "                else:\n",
    "                    self.downsample.append(Conv2DModule(C, C//2, 3, 2))\n",
    "                    C = C//2\n",
    "                    i = i+1\n",
    "                    H = H//2\n",
    "                    W = W//2\n",
    "\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.downsample(x)\n",
    "        \n",
    "class SegFormerHeadGen(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.G = Generator().to(device)\n",
    "    \n",
    "    def forward(self, features: Tuple[Tensor, Tensor, Tensor, Tensor]) -> Tensor:\n",
    "        downsamplers = []\n",
    "        for x in features:\n",
    "            down = downsample(x.shape[1],x.shape[2],x.shape[3]).to(device)\n",
    "            downsamplers.append(down)\n",
    "        \n",
    "        #downsamplers = [downsample(x.shape[0],x.shape[1],x.shape[2]) for x in features]\n",
    "\n",
    "        images = []\n",
    "        \n",
    "        for i, feature in enumerate(features):\n",
    "            print(downsamplers[i](feature).size())\n",
    "            #images.append(self.G(downsamplers[i](feature.flatten)))\n",
    "    \n",
    "        \n",
    "        return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cZsudwlzXULU"
   },
   "outputs": [],
   "source": [
    "from semseg.models.base import BaseModel\n",
    "from semseg.models.heads import SegFormerHead\n",
    "#from resDecode import ResDecode\n",
    "\n",
    "\n",
    "class SegFormerpp(BaseModel):\n",
    "    def __init__(self, backbone: str = 'MiT-B0', num_classes: int = 19, head: str = 'B0') -> None:\n",
    "        super().__init__(backbone, num_classes)\n",
    "        self.num_classes = num_classes\n",
    "        self.head = head\n",
    "        self.decode = SegFormerHead(self.backbone.channels, 256 if 'B0' in backbone or 'B1' in backbone else 768, 3)\n",
    "        self.newDecode = SegFormerHeadGen()\n",
    "        self.newDecode.to(device)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = self.backbone(x)\n",
    "        #y = self.decode(y)\n",
    "        #y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        #embeds = []\n",
    "        y = self.newDecode(y)\n",
    "        '''\n",
    "        y = self.decode(y)\n",
    "        self.upsample = nn.Sequential(        \n",
    "        torch.nn.ConvTranspose2d(y.shape[1],self.num_classes//2,3,stride=2,output_padding=1, padding=1),\n",
    "        torch.nn.ConvTranspose2d(self.num_classes//2,self.num_classes,3,stride=2,output_padding=1, padding=1),   \n",
    "                                )\n",
    "        y = self.upsample(y).to(device)\n",
    "        '''\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bglipAaW_xaY",
    "outputId": "0ef004ba-4063-469a-9535-3218505b913f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download a pretrained model's weights from the result table.\n",
      "Loaded Model\n"
     ]
    }
   ],
   "source": [
    "from semseg.models import *\n",
    "#from segFormerpp import SegFormerpp\n",
    "\n",
    "model = eval('SegFormerpp')(\n",
    "    backbone='MiT-B1',\n",
    "    num_classes=5\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('checkpointcheckpoints/pretrained/segformer/segformer.b3.ade.pth'))\n",
    "except:\n",
    "    print(\"Download a pretrained model's weights from the result table.\")\n",
    "model.eval()\n",
    "print('Loaded Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "L2H1x10FXULW",
    "outputId": "b8f671cc-a07d-4467-80a4-af7183d36381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/dataloader\n",
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "%cd ../../dataloader/\n",
    "from load import Ai4MarsData\n",
    "%cd ../models/semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "stv4_1XZXULW"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB  :\n",
    "    !git clone https://github.com/airoprojects/visiope\n",
    "    %cd visiope/dataloader/\n",
    "    from load import Ai4MarsData\n",
    "    %cd ../..\n",
    "    with open('/content/drive/MyDrive/Dataset/data_loader.pkl', 'rb') as f:\n",
    "        data_loader = pickle.load(f)\n",
    "\n",
    "\n",
    "    data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\n",
    "    data_loader['dataloader'].dataset.setDevice(device,0)\n",
    "    data_loader['dataloader'].dataset.setDevice(device,1)\n",
    "    #data_loader['dataloader'].dataset.setdevice(device)\n",
    "\n",
    "    train_loader, test_loader, validation_loader = data_loader['dataloader'].dataset.splitLoader(80,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "kUgDMrCLXULW",
    "outputId": "f49a2b12-bf3f-4522-8f9b-0c3680ce741d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.utils.data.dataset.Subset'>\n"
     ]
    }
   ],
   "source": [
    "#local\n",
    "with open('../../dataloader/data_loader.pkl', 'rb') as f:\n",
    "    data_loader = pickle.load(f)\n",
    "\n",
    "data_loader['dataloader'].dataset.setPermuteX((0,3,1,2))\n",
    "#data_loader['dataloader'].dataset.convertion(0)\n",
    "data_loader['dataloader'].dataset.setDevice(device,0)\n",
    "data_loader['dataloader'].dataset.setDevice(device,1)\n",
    "#data_loader['dataloader'].dataset.setdevice(device)\n",
    "\n",
    "train_loader, test_loader, validation_loader = data_loader['dataloader'].dataset.splitLoader(80,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "O3ytN-ugjHcW",
    "outputId": "b7707c4c-5282-431c-8663-1493ee0348ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  \\n  print(img.device)\\n  print(img.shape)\\n  if (img.device != 'cpu'):\\n    img.to('cpu')\\n    print('test')\\n  print(img.device)\\n  plt.imshow(img)\\n  plt.show()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "def show_image(imgs):\n",
    "    imgs = imgs.permute(2,0,1)\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "'''  \n",
    "  print(img.device)\n",
    "  print(img.shape)\n",
    "  if (img.device != 'cpu'):\n",
    "    img.to('cpu')\n",
    "    print('test')\n",
    "  print(img.device)\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "bCdsw7j2XULX",
    "outputId": "58e92eef-12f8-4004-c049-30657b509506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/loss\n",
      "/home/paolo/Downloads/magistrale/1 anno/visiope/visiope/models/semantic-segmentation\n"
     ]
    }
   ],
   "source": [
    "#local\n",
    "%cd ../../loss/\n",
    "from trainer_module import trainer\n",
    "%cd ../models/semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Bqlb9HnBYe54"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB  :\n",
    "    %cd visiope/loss/\n",
    "    from trainer_module import trainer\n",
    "    %cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3lU21D6nXULX"
   },
   "outputs": [],
   "source": [
    "\"\"\" Trainer module for MER-Segmentation \"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "if IN_COLAB  :\n",
    "    # Setup path for custom imports\n",
    "    import sys\n",
    "    sys.path.insert(0, '/content/drive/MyDrive/Github/visiope/loss')\n",
    "    from loss_functions import *\n",
    "\n",
    "# Main trainer function\n",
    "def trainer(parameters, multiple_epochs=False, epoch_index=0, tb_writer=0):\n",
    "    model = parameters['model']\n",
    "    device = parameters['device']\n",
    "    model.to(device)\n",
    "    if multiple_epochs: \n",
    "        train_multiple_epoch(parameters,  model, EPOCHS=100)\n",
    "\n",
    "    else:\n",
    "        train_one_epoch(parameters, epoch_index, tb_writer, model)\n",
    "    \n",
    "# IMPORTANT: FIND OUT ABOUT TB_WRITER\n",
    "def train_one_epoch(parameters, epoch_index, tb_writer, model):\n",
    "\n",
    "    # Initialization of training parameters\n",
    "    \n",
    "    loss_fn = parameters['loss']\n",
    "    optimizer = parameters['optimizer']\n",
    "    training_set = parameters['training']\n",
    "    device = parameters['device']\n",
    "    \n",
    "    # To keep track of the last loss when the function is executed through multiple epochs\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_set):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "        #inputs = inputs.permute(0,3,1,2).to(device)\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        #print(labels.type())\n",
    "        #print(outputs)\n",
    "        #labels = labels.type(torch.DoubleTensor)\n",
    "\n",
    "        #labels = labels.to(device)       \n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # IMPORTANT: UNCOMMENT THIS PART AFTER FINDING OUT ABOUT TB_WRITER\n",
    "        '''\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_set) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "        '''\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "def train_multiple_epoch(parameters, model, EPOCHS=100):\n",
    "\n",
    "    # Initialization of training parameters\n",
    "    loss_fn = parameters['loss']\n",
    "    #optimizer = parameters['optimizer']\n",
    "    #training_set = parameters['training']\n",
    "    validation_set = parameters['validation']\n",
    "\n",
    "    # Initialization of report parameters\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = 0 #SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "    epoch_number = 0 # just a counter\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        avg_loss = train_one_epoch(parameters, epoch_number, writer, model)\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"epoch time: \"+str(end-start)+\"s\")\n",
    "        \n",
    "        # We don't need gradients on to do reporting\n",
    "        model.train(False)\n",
    "\n",
    "        # Validation loss\n",
    "        running_vloss = 0.0\n",
    "        for i, vdata in enumerate(validation_set):\n",
    "            vinputs, vlabels = vdata\n",
    "            \n",
    "            voutputs = model(vinputs)    \n",
    "            \n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        # IMPORTANT: UNCOMMENT THIS PART AFTER FINDING OUT ABOUT TB_WRITER\n",
    "        '''\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        '''\n",
    "        #torch.cuda.memory_summary()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        #torch.cuda.memory_summary()\n",
    "        \n",
    "        epoch_number += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # This variable needs to be initialized with dummy values/data to test loss integration\n",
    "    '''\n",
    "    model = 0\n",
    "    optimizer = 0\n",
    "    loss_fn = 0\n",
    "    training_set = 0 \n",
    "    validation_set = 0\n",
    "\n",
    "    parameters = {\n",
    "                    'model' : model,\n",
    "                    'loss' : loss_fn,\n",
    "                    'optimizer' : optimizer,\n",
    "                    'training' : training_set,\n",
    "                    'validation': validation_set\n",
    "    }\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uVll-qRSXULY",
    "outputId": "b402c01b-8720-4765-a406-7d4d27840f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "H 9\n",
      "W 9\n",
      "C 810\n",
      "H 9\n",
      "W 9\n",
      "C 405\n",
      "H 9\n",
      "W 9\n",
      "C 202\n",
      "H 9\n",
      "W 9\n",
      "C 101\n",
      "H 9\n",
      "W 9\n",
      "C 50\n",
      "H 9\n",
      "W 9\n",
      "C 25\n",
      "H 9\n",
      "W 9\n",
      "C 12\n",
      "H 7\n",
      "W 7\n",
      "C 25088\n",
      "H 7\n",
      "W 7\n",
      "C 12544\n",
      "H 7\n",
      "W 7\n",
      "C 6272\n",
      "H 7\n",
      "W 7\n",
      "C 3136\n",
      "H 7\n",
      "W 7\n",
      "C 1568\n",
      "H 7\n",
      "W 7\n",
      "C 784\n",
      "H 7\n",
      "W 7\n",
      "C 392\n",
      "H 7\n",
      "W 7\n",
      "C 196\n",
      "H 7\n",
      "W 7\n",
      "C 98\n",
      "H 7\n",
      "W 7\n",
      "C 49\n",
      "H 7\n",
      "W 7\n",
      "C 24\n",
      "torch.Size([1, 4, 9, 9])\n",
      "torch.Size([1, 4, 5, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [405, 810, 3], expected input[1, 1, 160] to have 810 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m : model,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m : loss_fn,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m : device\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#trainer(parameters)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmultiple_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m, in \u001b[0;36mtrainer\u001b[0;34m(parameters, multiple_epochs, epoch_index, tb_writer)\u001b[0m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multiple_epochs: \n\u001b[0;32m---> 17\u001b[0m     \u001b[43mtrain_multiple_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     train_one_epoch(parameters, epoch_index, tb_writer, model)\n",
      "Cell \u001b[0;32mIn[17], line 99\u001b[0m, in \u001b[0;36mtrain_multiple_epoch\u001b[0;34m(parameters, model, EPOCHS)\u001b[0m\n\u001b[1;32m     95\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     97\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 99\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch time: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 47\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(parameters, epoch_index, tb_writer, model)\u001b[0m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Make predictions for this batch\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Compute the loss and its gradients\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#print(labels.type())\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#labels = labels.type(torch.DoubleTensor)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#labels = labels.to(device)       \u001b[39;00m\n\u001b[1;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m, in \u001b[0;36mSegFormerpp.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#y = self.decode(y)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#y = F.interpolate(y, size=x.shape[2:], mode='bilinear', align_corners=False)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#embeds = []\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewDecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03my = self.decode(y)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mself.upsample = nn.Sequential(        \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03my = self.upsample(y).to(device)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 127\u001b[0m, in \u001b[0;36mSegFormerHeadGen.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    124\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(features):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdownsamplers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m#images.append(self.G(downsamplers[i](feature.flatten)))\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 108\u001b[0m, in \u001b[0;36mdownsample.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m, in \u001b[0;36mConv1DModule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [405, 810, 3], expected input[1, 1, 160] to have 810 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "training_set = train_loader\n",
    "validation_set = test_loader\n",
    "\n",
    "parameters = {\n",
    "    'model' : model,\n",
    "    'loss' : loss_fn,\n",
    "    'optimizer' : optimizer,\n",
    "    'training' : training_set,\n",
    "    'validation' : validation_set,\n",
    "    'device' : device\n",
    "}\n",
    "#trainer(parameters)\n",
    "trainer(parameters,multiple_epochs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZzOcvNXLK19"
   },
   "outputs": [],
   "source": [
    "from semseg.datasets import *\n",
    "\n",
    "#model = model.to(device)\n",
    "predictions = []\n",
    "start = time.time()\n",
    "#print('test')\n",
    "# Use torch.no_grad() to disable gradient computation during testing\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move the data to the desired device\n",
    "        #print(images.shape)\n",
    "        #images = images.permute(0,3,1,2).to(device)\n",
    "        #images = images.permute(2,0,1).to(device)\n",
    "        #images = images [None, :, :, :]\n",
    "        #print(images.shape)\n",
    "        \n",
    "        #print(images.shape)\n",
    "        #labels = labels.to(device)\n",
    "\n",
    "        # Forward pass to get the predictions\n",
    "        with torch.inference_mode():\n",
    "          prediction = model(images)\n",
    "        #print(prediction)\n",
    "        prediction = prediction.softmax(1).argmax(1).to(int)\n",
    "        #prediction = prediction.round().to(int)\n",
    "        #print(prediction.shape)\n",
    "        un = prediction.unique()\n",
    "        #print(un)\n",
    "        palette = eval('ADE20K').PALETTE.to(device)\n",
    "        prediction_map = palette[prediction].squeeze().to(torch.uint8)\n",
    "        #print(type(prediction_map))\n",
    "        show_image(prediction_map)\n",
    "        predictions.append(prediction_map)\n",
    "        \n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKfyLsOXXBjx"
   },
   "outputs": [],
   "source": [
    "Flatten.__mro__"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
